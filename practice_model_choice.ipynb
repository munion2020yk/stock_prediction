{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas\n",
        "pip install torch\n",
        "pip install numpy\n",
        "pip install scikit-learn\n",
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "N9r_cTptNdZk",
        "outputId": "cdee69e9-b507-4f89-868c-edf61fac81d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-4199779277.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4199779277.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install pandas\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oayOqqqMfl3L",
        "outputId": "43b98686-7a6e-487d-9395-43d3a04f2663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMPKBBc9fo9T",
        "outputId": "8120246d-e1de-40c8-bb4e-c7944361e338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 코드"
      ],
      "metadata": {
        "id": "KimuLivVehDj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "JJxlbCUN1ow7",
        "outputId": "6c9ca8bd-9005-49cc-d094-dff44ba9861f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37; latest registration was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1153053535.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2680\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from torch._decomp import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0m_convert_out_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;31m# populate the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/decompositions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprim_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IMPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CompositeExplicitAutograd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprim_backend_select_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IMPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BackendSelect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         self.m: Optional[Any] = torch._C._dispatch_library(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37; latest registration was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- 1. 설정 (Configuration) ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-27\",\n",
        "    \"test_start_date\": \"2025-11-24\", # 이 시점부터 테스트 데이터\n",
        "\n",
        "    \"seq_length\": 5,          # 시퀀스 길이\n",
        "    \"predict_horizon\": 5,     # 며칠 뒤를 예측할 것인가\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,         # 출력 차원 (Close Price)\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 100,\n",
        "    \"learning_rate\": 0.001,   # [수정] 학습률을 조금 낮춰 안정화 (0.005 -> 0.001)\n",
        "    \"patience\": 10,           # Early Stopping\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. 데이터 전처리 ---\n",
        "def load_and_process_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {config['data_file']}\")\n",
        "\n",
        "    # 인코딩 자동 감지 로직\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin1']\n",
        "    df = None\n",
        "\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            # 탭(\\t)으로 분리 시도\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> 성공: 인코딩 '{enc}', 구분자 '탭(\\\\t)'\")\n",
        "                break\n",
        "\n",
        "            # 쉼표(,)로 분리 재시도\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> 성공: 인코딩 '{enc}', 구분자 '쉼표(,)'\")\n",
        "                break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if df is None:\n",
        "        raise ValueError(\"파일을 읽을 수 없습니다.\")\n",
        "\n",
        "    print(f\"로드된 데이터 크기: {df.shape}\")\n",
        "    print(f\"컬럼 목록: {df.columns.tolist()}\")\n",
        "\n",
        "    # [수정] 데이터 타입 강제 변환 및 결측치 처리 강화\n",
        "    # 1. 모든 컬럼을 숫자형(float)으로 변환 (오류 발생 시 NaN으로 처리)\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # 2. 날짜 필터링\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "\n",
        "    # 3. 결측치(NaN) 처리 - 경고 해결을 위해 ffill(), bfill() 사용\n",
        "    df = df.ffill()\n",
        "    df = df.bfill()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"유효한 데이터가 없습니다. 날짜 범위나 데이터 내용을 확인해주세요.\")\n",
        "\n",
        "    # 4. 무한대 값(inf) 처리\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    print(f\"전처리 후 데이터 크기: {df.shape}\")\n",
        "\n",
        "    # Feature와 Target 분리\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    target_col = \"KOSPI_Close\"\n",
        "\n",
        "    if target_col not in df.columns:\n",
        "         possible_cols = [c for c in df.columns if \"Close\" in c and \"KOSPI\" in c]\n",
        "         if possible_cols:\n",
        "             target_col = possible_cols[0]\n",
        "             print(f\"주의: '{target_col}'를 Target 컬럼으로 사용합니다.\")\n",
        "         else:\n",
        "             raise KeyError(f\"Target 컬럼 '{target_col}'을 찾을 수 없습니다.\")\n",
        "\n",
        "    feature_cols = df.columns.tolist()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "    # Target 컬럼 인덱스\n",
        "    target_idx = feature_cols.index(target_col)\n",
        "\n",
        "    # 시퀀스 데이터 생성\n",
        "    X, y = [], []\n",
        "    seq_len = config[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_data) - seq_len):\n",
        "        X.append(scaled_data[i : i + seq_len])\n",
        "        y.append(scaled_data[i + seq_len, target_idx])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # [추가] 시퀀스 생성 후에도 NaN이 있는지 최종 확인\n",
        "    if np.isnan(X).any() or np.isnan(y).any():\n",
        "        print(\"경고: 전처리 후 데이터에 NaN이 발견되었습니다. 제거합니다.\")\n",
        "        valid_idx = ~np.isnan(X).any(axis=(1, 2)) & ~np.isnan(y)\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "    # 학습/테스트 분리\n",
        "    dates = df.index[seq_len:]\n",
        "    # 데이터 포인트 제거로 인해 dates 길이도 맞춰줘야 할 수 있음\n",
        "    if len(dates) != len(X):\n",
        "        dates = dates[:len(X)]\n",
        "\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "\n",
        "    train_mask = dates < test_start\n",
        "    test_mask = dates >= test_start\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "\n",
        "    if len(X_train) == 0 or len(X_test) == 0:\n",
        "        raise ValueError(\"학습 또는 테스트 데이터가 비어있습니다. 날짜 설정이나 데이터 기간을 확인해주세요.\")\n",
        "\n",
        "    # Tensor 변환\n",
        "    X_train = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_train = torch.FloatTensor(y_train).unsqueeze(1).to(config['device'])\n",
        "    X_test = torch.FloatTensor(X_test).to(config['device'])\n",
        "    y_test = torch.FloatTensor(y_test).unsqueeze(1).to(config['device'])\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler, target_idx\n",
        "\n",
        "# --- 3. 모델 정의 ---\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. 학습 및 평가 함수 ---\n",
        "def train_model(model, train_loader, config):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            # [추가] Loss가 NaN이면 중단\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"  경고: Epoch {epoch+1}에서 Loss가 NaN입니다. 학습을 중단합니다.\")\n",
        "                return model, loss_history\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # [추가] Gradient Clipping (기울기 폭주 방지)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        loss_history.append(avg_loss)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"  Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "        if config[\"patience\"]:\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= config[\"patience\"]:\n",
        "                    print(f\"  Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "    return model, loss_history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, scaler, target_idx, config):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test).cpu().numpy()\n",
        "        y_true = y_test.cpu().numpy()\n",
        "\n",
        "    def inverse_scale(data_1d):\n",
        "        dummy = np.zeros((len(data_1d), scaler.n_features_in_))\n",
        "        dummy[:, target_idx] = data_1d.flatten()\n",
        "        return scaler.inverse_transform(dummy)[:, target_idx]\n",
        "\n",
        "    pred_inverse = inverse_scale(predictions)\n",
        "    true_inverse = inverse_scale(y_true)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(true_inverse, pred_inverse))\n",
        "    return rmse, true_inverse, pred_inverse\n",
        "\n",
        "# --- 5. 메인 실행 ---\n",
        "def main():\n",
        "    print(\"1. 데이터 로드 및 전처리...\")\n",
        "    try:\n",
        "        X_train, y_train, X_test, y_test, scaler, target_idx = load_and_process_data(CONFIG)\n",
        "    except Exception as e:\n",
        "        print(f\"데이터 로드 중 오류 발생: {e}\")\n",
        "        return\n",
        "\n",
        "    input_size = X_train.shape[2]\n",
        "    print(f\"   Input Features: {input_size}, Train Size: {len(X_train)}, Test Size: {len(X_test)}\")\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    models = {\n",
        "        \"LSTM\": LSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"]),\n",
        "        \"CNN + LSTM\": CNNLSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"], CONFIG[\"num_filters\"], CONFIG[\"kernel_size\"]),\n",
        "        \"LSTM (Attention)\": LSTMAttentionModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"])\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    print(\"\\n2. 모델 학습 시작...\")\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n[{name}] Training...\")\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        trained_model, _ = train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        rmse, y_true, y_pred = evaluate_model(trained_model, X_test, y_test, scaler, target_idx, CONFIG)\n",
        "        results[name] = rmse\n",
        "        print(f\"  >> {name} RMSE: {rmse:.4f}\")\n",
        "\n",
        "    print(\"\\n3. 최종 결과 비교 (RMSE)\")\n",
        "    df_results = pd.DataFrame(list(results.items()), columns=[\"Model\", \"RMSE\"])\n",
        "    df_results = df_results.sort_values(by=\"RMSE\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(df_results)\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    df_results.to_csv(\"model_rmse_comparison.csv\", index=False)\n",
        "    print(\"결과가 'model_rmse_comparison.csv'로 저장되었습니다.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 한글 폰트 설정 (그래프용)\n",
        "try:\n",
        "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "except:\n",
        "    plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. 설정 (Configuration) ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\", # [수정] 11월 28일까지 확인하기 위해 연장\n",
        "    \"test_start_date\": \"2025-11-24\", # 이 시점부터 테스트 데이터\n",
        "\n",
        "    # [추가] Feature 선택 (원하는 Feature만 리스트에 남기세요. 비워두거나 None이면 전체 사용)\n",
        "    \"selected_features\": [\n",
        "        'KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume',\n",
        "        'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown',\n",
        "        'NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change',\n",
        "        'USD_KRW', 'EUR_KRW', 'Rate',\n",
        "        'VKOSPI_Close', 'VKOSPI_Change',\n",
        "        'Future_Close', 'Future_Change',\n",
        "        'WTI_Close', 'WTI_Change',\n",
        "        'Foreign_MarketCap_Ratio', 'Foreign_MarketCap'\n",
        "    ],\n",
        "    # \"selected_features\": None, # 전체 Feature 사용 시 주석 해제\n",
        "\n",
        "    \"seq_length\": 5,          # 시퀀스 길이\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 10,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. 데이터 전처리 ---\n",
        "def load_and_process_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {config['data_file']}\")\n",
        "\n",
        "    # 인코딩 자동 감지 로직\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin1']\n",
        "    df = None\n",
        "\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> 성공: 인코딩 '{enc}', 구분자 '탭(\\\\t)'\")\n",
        "                break\n",
        "\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> 성공: 인코딩 '{enc}', 구분자 '쉼표(,)'\")\n",
        "                break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if df is None:\n",
        "        raise ValueError(\"파일을 읽을 수 없습니다.\")\n",
        "\n",
        "    print(f\"로드된 전체 데이터 크기: {df.shape}\")\n",
        "\n",
        "    # 데이터 타입 강제 변환\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # 날짜 필터링\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "\n",
        "    # 결측치 처리\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"유효한 데이터가 없습니다.\")\n",
        "\n",
        "    # 컬럼 공백 제거\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    # Target 설정\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    if target_col not in df.columns:\n",
        "         possible_cols = [c for c in df.columns if \"Close\" in c and \"KOSPI\" in c]\n",
        "         if possible_cols:\n",
        "             target_col = possible_cols[0]\n",
        "         else:\n",
        "             raise KeyError(f\"Target 컬럼 '{target_col}'을 찾을 수 없습니다.\")\n",
        "\n",
        "    # [수정] Feature Selection 적용\n",
        "    if config.get(\"selected_features\"):\n",
        "        selected = config[\"selected_features\"]\n",
        "        # Target 컬럼은 반드시 포함되어야 함\n",
        "        if target_col not in selected:\n",
        "            selected.append(target_col)\n",
        "\n",
        "        # 실제 데이터프레임에 존재하는 컬럼만 선택\n",
        "        available_cols = [c for c in selected if c in df.columns]\n",
        "        missing_cols = set(selected) - set(available_cols)\n",
        "        if missing_cols:\n",
        "            print(f\"[경고] 다음 Feature는 데이터에 없어 제외됩니다: {missing_cols}\")\n",
        "\n",
        "        df = df[available_cols]\n",
        "        print(f\"-> Feature 선택 적용 완료: {len(df.columns)}개 사용\")\n",
        "    else:\n",
        "        print(f\"-> 전체 Feature 사용: {len(df.columns)}개\")\n",
        "\n",
        "    feature_cols = df.columns.tolist()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "    # Target 컬럼 인덱스\n",
        "    target_idx = feature_cols.index(target_col)\n",
        "\n",
        "    # 시퀀스 데이터 생성\n",
        "    X, y = [], []\n",
        "    seq_len = config[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_data) - seq_len):\n",
        "        X.append(scaled_data[i : i + seq_len])\n",
        "        y.append(scaled_data[i + seq_len, target_idx])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # NaN 확인 및 제거\n",
        "    if np.isnan(X).any() or np.isnan(y).any():\n",
        "        valid_idx = ~np.isnan(X).any(axis=(1, 2)) & ~np.isnan(y)\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "    # 학습/테스트 분리\n",
        "    dates = df.index[seq_len:]\n",
        "    if len(dates) != len(X):\n",
        "        dates = dates[:len(X)]\n",
        "\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "\n",
        "    train_mask = dates < test_start\n",
        "    test_mask = dates >= test_start\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "\n",
        "    # 테스트 데이터의 날짜 인덱스 저장 (그래프 그리기용)\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    if len(X_train) == 0 or len(X_test) == 0:\n",
        "        raise ValueError(\"학습 또는 테스트 데이터가 비어있습니다.\")\n",
        "\n",
        "    # Tensor 변환\n",
        "    X_train = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_train = torch.FloatTensor(y_train).unsqueeze(1).to(config['device'])\n",
        "    X_test = torch.FloatTensor(X_test).to(config['device'])\n",
        "    y_test = torch.FloatTensor(y_test).unsqueeze(1).to(config['device'])\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler, target_idx, test_dates\n",
        "\n",
        "# --- 3. 모델 정의 ---\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. 학습 및 평가 함수 ---\n",
        "def train_model(model, train_loader, config):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"  경고: Epoch {epoch+1}에서 Loss가 NaN입니다.\")\n",
        "                return model, loss_history\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        loss_history.append(avg_loss)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"  Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "        if config[\"patience\"]:\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= config[\"patience\"]:\n",
        "                    print(f\"  Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "    return model, loss_history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, scaler, target_idx, config):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test).cpu().numpy()\n",
        "        y_true = y_test.cpu().numpy()\n",
        "\n",
        "    def inverse_scale(data_1d):\n",
        "        dummy = np.zeros((len(data_1d), scaler.n_features_in_))\n",
        "        dummy[:, target_idx] = data_1d.flatten()\n",
        "        return scaler.inverse_transform(dummy)[:, target_idx]\n",
        "\n",
        "    pred_inverse = inverse_scale(predictions)\n",
        "    true_inverse = inverse_scale(y_true)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(true_inverse, pred_inverse))\n",
        "    return rmse, true_inverse, pred_inverse\n",
        "\n",
        "# [추가] 그래프 그리기 함수\n",
        "def plot_results(model_name, dates, y_true, y_pred):\n",
        "    # 날짜와 예측값을 매핑\n",
        "    df_plot = pd.DataFrame({'Actual': y_true, 'Predicted': y_pred}, index=dates)\n",
        "\n",
        "    # 11월 24일 ~ 11월 28일 데이터 필터링\n",
        "    # 데이터가 해당 기간을 포함하는지 확인 후 슬라이싱\n",
        "    target_start = \"2025-11-24\"\n",
        "    target_end = \"2025-11-28\"\n",
        "    mask = (df_plot.index >= target_start) & (df_plot.index <= target_end)\n",
        "    df_subset = df_plot.loc[mask]\n",
        "\n",
        "    if df_subset.empty:\n",
        "        print(f\"경고: {target_start} ~ {target_end} 기간의 데이터가 없습니다. 전체 테스트 기간을 출력합니다.\")\n",
        "        df_subset = df_plot.tail(20) # 데이터가 없으면 마지막 20일치 출력\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 실제값 (파란색 선)\n",
        "    plt.plot(df_subset.index, df_subset['Actual'], label='Actual (KOSPI)', color='blue', marker='o', linewidth=2)\n",
        "\n",
        "    # 예측값 (빨간색 선)\n",
        "    plt.plot(df_subset.index, df_subset['Predicted'], label=f'Predicted ({model_name})', color='red', linestyle='--', marker='x', linewidth=2)\n",
        "\n",
        "    plt.title(f\"{model_name}: KOSPI Closing price prediction  ({target_start} ~ {target_end})\", fontsize=15)\n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Price (KRW)', fontsize=12)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # 값 표시\n",
        "    for i in range(len(df_subset)):\n",
        "        date = df_subset.index[i]\n",
        "        act = df_subset['Actual'].iloc[i]\n",
        "        pred = df_subset['Predicted'].iloc[i]\n",
        "        # 텍스트가 겹치지 않게 위치 조정\n",
        "        plt.text(date, act, f\"{act:.0f}\", ha='center', va='bottom', color='blue', fontsize=9)\n",
        "        plt.text(date, pred, f\"{pred:.0f}\", ha='center', va='top', color='red', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = f\"prediction_plot_{model_name.replace(' ', '_').replace('+', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"그래프 저장 완료: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 5. 메인 실행 ---\n",
        "def main():\n",
        "    print(\"1. 데이터 로드 및 전처리...\")\n",
        "    try:\n",
        "        # [수정] test_dates도 반환받음\n",
        "        X_train, y_train, X_test, y_test, scaler, target_idx, test_dates = load_and_process_data(CONFIG)\n",
        "    except Exception as e:\n",
        "        print(f\"데이터 로드 중 오류 발생: {e}\")\n",
        "        return\n",
        "\n",
        "    input_size = X_train.shape[2]\n",
        "    print(f\"   Input Features: {input_size}, Train Size: {len(X_train)}, Test Size: {len(X_test)}\")\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    models = {\n",
        "        \"LSTM\": LSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"]),\n",
        "        \"CNN + LSTM\": CNNLSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"], CONFIG[\"num_filters\"], CONFIG[\"kernel_size\"]),\n",
        "        \"LSTM (Attention)\": LSTMAttentionModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"])\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    print(\"\\n2. 모델 학습 시작...\")\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n[{name}] Training...\")\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        trained_model, _ = train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        rmse, y_true, y_pred = evaluate_model(trained_model, X_test, y_test, scaler, target_idx, CONFIG)\n",
        "        results[name] = rmse\n",
        "        print(f\"  >> {name} RMSE: {rmse:.4f}\")\n",
        "\n",
        "        # [추가] 그래프 그리기 호출\n",
        "        plot_results(name, test_dates, y_true, y_pred)\n",
        "\n",
        "    print(\"\\n3. 최종 결과 비교 (RMSE)\")\n",
        "    df_results = pd.DataFrame(list(results.items()), columns=[\"Model\", \"RMSE\"])\n",
        "    df_results = df_results.sort_values(by=\"RMSE\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(df_results)\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    df_results.to_csv(\"model_rmse_comparison.csv\", index=False)\n",
        "    print(\"결과가 'model_rmse_comparison.csv'로 저장되었습니다.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "GKe7ray2Ud-K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "a8976e3a-7989-4b6c-ed73-b6b322a32b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37; latest registration was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1428897996.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2680\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from torch._decomp import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0m_convert_out_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;31m# populate the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/decompositions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprim_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IMPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CompositeExplicitAutograd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprim_backend_select_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IMPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BackendSelect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         self.m: Optional[Any] = torch._C._dispatch_library(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37; latest registration was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\", # Extended to check until Nov 28\n",
        "    \"test_start_date\": \"2025-11-24\", # Test start date\n",
        "\n",
        "    # Feature Selection (Leave specific features in the list, or set to None to use all)\n",
        "    \"selected_features\": [\n",
        "        'KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume',\n",
        "        'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown',\n",
        "        'NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change',\n",
        "        'USD_KRW', 'EUR_KRW', 'Rate',\n",
        "        'VKOSPI_Close', 'VKOSPI_Change',\n",
        "        'Future_Close', 'Future_Change',\n",
        "        'WTI_Close', 'WTI_Change',\n",
        "        'Foreign_MarketCap_Ratio', 'Foreign_MarketCap'\n",
        "    ],\n",
        "    # \"selected_features\": None, # Uncomment to use all features\n",
        "\n",
        "    \"seq_length\": 5,          # Sequence length\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 10,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_and_process_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    # Automatic encoding detection\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin1']\n",
        "    df = None\n",
        "\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            # Try tab separator\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> Success: Loaded with encoding '{enc}', separator 'Tab(\\\\t)'\")\n",
        "                break\n",
        "\n",
        "            # Try comma separator\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> Success: Loaded with encoding '{enc}', separator 'Comma(,)'\")\n",
        "                break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if df is None:\n",
        "        raise ValueError(\"Failed to read file. Please check encoding or separator.\")\n",
        "\n",
        "    print(f\"Total data shape: {df.shape}\")\n",
        "\n",
        "    # Force numeric conversion\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Date filtering\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "\n",
        "    # Missing value handling\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"No valid data available.\")\n",
        "\n",
        "    # Strip column whitespace\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    # Target setup\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    if target_col not in df.columns:\n",
        "         possible_cols = [c for c in df.columns if \"Close\" in c and \"KOSPI\" in c]\n",
        "         if possible_cols:\n",
        "             target_col = possible_cols[0]\n",
        "         else:\n",
        "             raise KeyError(f\"Target column '{target_col}' not found.\")\n",
        "\n",
        "    # Feature Selection\n",
        "    if config.get(\"selected_features\"):\n",
        "        selected = config[\"selected_features\"]\n",
        "        if target_col not in selected:\n",
        "            selected.append(target_col)\n",
        "\n",
        "        available_cols = [c for c in selected if c in df.columns]\n",
        "        missing_cols = set(selected) - set(available_cols)\n",
        "        if missing_cols:\n",
        "            print(f\"[Warning] Missing features in data: {missing_cols}\")\n",
        "\n",
        "        df = df[available_cols]\n",
        "        print(f\"-> Feature Selection Applied: {len(df.columns)} features used\")\n",
        "    else:\n",
        "        print(f\"-> Using All Features: {len(df.columns)} features\")\n",
        "\n",
        "    feature_cols = df.columns.tolist()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "    # Target column index\n",
        "    target_idx = feature_cols.index(target_col)\n",
        "\n",
        "    # Sequence generation\n",
        "    X, y = [], []\n",
        "    seq_len = config[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_data) - seq_len):\n",
        "        X.append(scaled_data[i : i + seq_len])\n",
        "        y.append(scaled_data[i + seq_len, target_idx])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # NaN check\n",
        "    if np.isnan(X).any() or np.isnan(y).any():\n",
        "        valid_idx = ~np.isnan(X).any(axis=(1, 2)) & ~np.isnan(y)\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "    # Train/Test Split\n",
        "    dates = df.index[seq_len:]\n",
        "    if len(dates) != len(X):\n",
        "        dates = dates[:len(X)]\n",
        "\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "\n",
        "    train_mask = dates < test_start\n",
        "    test_mask = dates >= test_start\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "\n",
        "    # Save test dates for plotting\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    if len(X_train) == 0 or len(X_test) == 0:\n",
        "        raise ValueError(\"Train or Test set is empty.\")\n",
        "\n",
        "    # Convert to Tensor\n",
        "    X_train = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_train = torch.FloatTensor(y_train).unsqueeze(1).to(config['device'])\n",
        "    X_test = torch.FloatTensor(X_test).to(config['device'])\n",
        "    y_test = torch.FloatTensor(y_test).unsqueeze(1).to(config['device'])\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler, target_idx, test_dates\n",
        "\n",
        "# --- 3. Model Definitions ---\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # Conv1d: (Batch, Input_Channels, Seq_Len)\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Calculate size after pooling: floor(seq_len / 2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (Batch, Seq, Feat) -> (Batch, Feat, Seq) for Conv1d\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.flatten(1) # Flatten for FC\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training & Evaluation ---\n",
        "def train_model(model, train_loader, config):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"  Warning: Loss is NaN at Epoch {epoch+1}.\")\n",
        "                return model, loss_history\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        loss_history.append(avg_loss)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"  Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "        if config[\"patience\"]:\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= config[\"patience\"]:\n",
        "                    print(f\"  Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "    return model, loss_history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, scaler, target_idx, config):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test).cpu().numpy()\n",
        "        y_true = y_test.cpu().numpy()\n",
        "\n",
        "    def inverse_scale(data_1d):\n",
        "        dummy = np.zeros((len(data_1d), scaler.n_features_in_))\n",
        "        dummy[:, target_idx] = data_1d.flatten()\n",
        "        return scaler.inverse_transform(dummy)[:, target_idx]\n",
        "\n",
        "    pred_inverse = inverse_scale(predictions)\n",
        "    true_inverse = inverse_scale(y_true)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(true_inverse, pred_inverse))\n",
        "    return rmse, true_inverse, pred_inverse\n",
        "\n",
        "# Plotting Function\n",
        "def plot_results(model_name, dates, y_true, y_pred):\n",
        "    df_plot = pd.DataFrame({'Actual': y_true, 'Predicted': y_pred}, index=dates)\n",
        "\n",
        "    # Target period for visualization\n",
        "    target_start = \"2025-11-24\"\n",
        "    target_end = \"2025-11-28\"\n",
        "    mask = (df_plot.index >= target_start) & (df_plot.index <= target_end)\n",
        "    df_subset = df_plot.loc[mask]\n",
        "\n",
        "    if df_subset.empty:\n",
        "        print(f\"Warning: No data for {target_start} ~ {target_end}. Showing last 20 days.\")\n",
        "        df_subset = df_plot.tail(20)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Actual (Blue)\n",
        "    plt.plot(df_subset.index, df_subset['Actual'], label='Actual (KOSPI)', color='blue', marker='o', linewidth=2)\n",
        "\n",
        "    # Predicted (Red)\n",
        "    plt.plot(df_subset.index, df_subset['Predicted'], label=f'Predicted ({model_name})', color='red', linestyle='--', marker='x', linewidth=2)\n",
        "\n",
        "    plt.title(f\"{model_name}: KOSPI Comparison ({target_start} ~ {target_end})\", fontsize=15)\n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Price (KRW)', fontsize=12)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Annotate Values\n",
        "    for i in range(len(df_subset)):\n",
        "        date = df_subset.index[i]\n",
        "        act = df_subset['Actual'].iloc[i]\n",
        "        pred = df_subset['Predicted'].iloc[i]\n",
        "        plt.text(date, act, f\"{act:.0f}\", ha='center', va='bottom', color='blue', fontsize=9)\n",
        "        plt.text(date, pred, f\"{pred:.0f}\", ha='center', va='top', color='red', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = f\"prediction_plot_{model_name.replace(' ', '_').replace('+', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 5. Main Execution ---\n",
        "def main():\n",
        "    print(\"1. Loading and Preprocessing Data...\")\n",
        "    try:\n",
        "        X_train, y_train, X_test, y_test, scaler, target_idx, test_dates = load_and_process_data(CONFIG)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data loading: {e}\")\n",
        "        return\n",
        "\n",
        "    input_size = X_train.shape[2]\n",
        "    print(f\"   Input Features: {input_size}, Train Size: {len(X_train)}, Test Size: {len(X_test)}\")\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # Model Dictionary\n",
        "    models = {\n",
        "        \"CNN\": CNNModel(input_size, CONFIG[\"num_classes\"], CONFIG[\"num_filters\"], CONFIG[\"kernel_size\"], CONFIG[\"seq_length\"]),\n",
        "        \"LSTM\": LSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"]),\n",
        "        \"CNN + LSTM\": CNNLSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"], CONFIG[\"num_filters\"], CONFIG[\"kernel_size\"]),\n",
        "        \"LSTM (Attention)\": LSTMAttentionModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"])\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    print(\"\\n2. Starting Model Training...\")\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n[{name}] Training...\")\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        trained_model, _ = train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        rmse, y_true, y_pred = evaluate_model(trained_model, X_test, y_test, scaler, target_idx, CONFIG)\n",
        "        results[name] = rmse\n",
        "        print(f\"  >> {name} RMSE: {rmse:.4f}\")\n",
        "\n",
        "        plot_results(name, test_dates, y_true, y_pred)\n",
        "\n",
        "    print(\"\\n3. Final RMSE Comparison\")\n",
        "    df_results = pd.DataFrame(list(results.items()), columns=[\"Model\", \"RMSE\"])\n",
        "    df_results = df_results.sort_values(by=\"RMSE\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(df_results)\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    df_results.to_csv(\"model_rmse_comparison.csv\", index=False)\n",
        "    print(\"Results saved to 'model_rmse_comparison.csv'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "66bm2Lt8bg1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# [수정] 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 강제 지정하여 에러 방지\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False # 마이너스 기호 깨짐 방지\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\", # Extended to check until Nov 28\n",
        "    \"test_start_date\": \"2025-11-24\", # Test start date\n",
        "\n",
        "    # Feature Selection (Leave specific features in the list, or set to None to use all)\n",
        "    \"selected_features\": [\n",
        "        'KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume',\n",
        "        'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown',\n",
        "        'NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change',\n",
        "        'USD_KRW', 'EUR_KRW', 'Rate',\n",
        "        'VKOSPI_Close', 'VKOSPI_Change',\n",
        "        'Future_Close', 'Future_Change',\n",
        "        'WTI_Close', 'WTI_Change',\n",
        "        'Foreign_MarketCap_Ratio', 'Foreign_MarketCap'\n",
        "    ],\n",
        "    # \"selected_features\": None, # Uncomment to use all features\n",
        "\n",
        "    \"seq_length\": 5,          # Sequence length\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 10,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_and_process_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    # Automatic encoding detection\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin1']\n",
        "    df = None\n",
        "\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            # Try tab separator\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> Success: Loaded with encoding '{enc}', separator 'Tab(\\\\t)'\")\n",
        "                break\n",
        "\n",
        "            # Try comma separator\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1:\n",
        "                df = temp_df\n",
        "                print(f\"-> Success: Loaded with encoding '{enc}', separator 'Comma(,)'\")\n",
        "                break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if df is None:\n",
        "        raise ValueError(\"Failed to read file. Please check encoding or separator.\")\n",
        "\n",
        "    print(f\"Total data shape: {df.shape}\")\n",
        "\n",
        "    # Force numeric conversion\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Date filtering\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "\n",
        "    # Missing value handling\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"No valid data available.\")\n",
        "\n",
        "    # Strip column whitespace\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    # Target setup\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    if target_col not in df.columns:\n",
        "         possible_cols = [c for c in df.columns if \"Close\" in c and \"KOSPI\" in c]\n",
        "         if possible_cols:\n",
        "             target_col = possible_cols[0]\n",
        "         else:\n",
        "             raise KeyError(f\"Target column '{target_col}' not found.\")\n",
        "\n",
        "    # Feature Selection\n",
        "    if config.get(\"selected_features\"):\n",
        "        selected = config[\"selected_features\"]\n",
        "        if target_col not in selected:\n",
        "            selected.append(target_col)\n",
        "\n",
        "        available_cols = [c for c in selected if c in df.columns]\n",
        "        missing_cols = set(selected) - set(available_cols)\n",
        "        if missing_cols:\n",
        "            print(f\"[Warning] Missing features in data: {missing_cols}\")\n",
        "\n",
        "        df = df[available_cols]\n",
        "        print(f\"-> Feature Selection Applied: {len(df.columns)} features used\")\n",
        "    else:\n",
        "        print(f\"-> Using All Features: {len(df.columns)} features\")\n",
        "\n",
        "    feature_cols = df.columns.tolist()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "    # Target column index\n",
        "    target_idx = feature_cols.index(target_col)\n",
        "\n",
        "    # Sequence generation\n",
        "    X, y = [], []\n",
        "    seq_len = config[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_data) - seq_len):\n",
        "        X.append(scaled_data[i : i + seq_len])\n",
        "        y.append(scaled_data[i + seq_len, target_idx])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # NaN check\n",
        "    if np.isnan(X).any() or np.isnan(y).any():\n",
        "        valid_idx = ~np.isnan(X).any(axis=(1, 2)) & ~np.isnan(y)\n",
        "        X = X[valid_idx]\n",
        "        y = y[valid_idx]\n",
        "\n",
        "    # Train/Test Split\n",
        "    dates = df.index[seq_len:]\n",
        "    if len(dates) != len(X):\n",
        "        dates = dates[:len(X)]\n",
        "\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "\n",
        "    train_mask = dates < test_start\n",
        "    test_mask = dates >= test_start\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "\n",
        "    # Save test dates for plotting\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    if len(X_train) == 0 or len(X_test) == 0:\n",
        "        raise ValueError(\"Train or Test set is empty.\")\n",
        "\n",
        "    # Convert to Tensor\n",
        "    X_train = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_train = torch.FloatTensor(y_train).unsqueeze(1).to(config['device'])\n",
        "    X_test = torch.FloatTensor(X_test).to(config['device'])\n",
        "    y_test = torch.FloatTensor(y_test).unsqueeze(1).to(config['device'])\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler, target_idx, test_dates\n",
        "\n",
        "# --- 3. Model Definitions ---\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # Conv1d: (Batch, Input_Channels, Seq_Len)\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Calculate size after pooling: floor(seq_len / 2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (Batch, Seq, Feat) -> (Batch, Feat, Seq) for Conv1d\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.flatten(1) # Flatten for FC\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training & Evaluation ---\n",
        "def train_model(model, train_loader, config):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"  Warning: Loss is NaN at Epoch {epoch+1}.\")\n",
        "                return model, loss_history\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        loss_history.append(avg_loss)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"  Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "        if config[\"patience\"]:\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= config[\"patience\"]:\n",
        "                    print(f\"  Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "    return model, loss_history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, scaler, target_idx, config):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test).cpu().numpy()\n",
        "        y_true = y_test.cpu().numpy()\n",
        "\n",
        "    def inverse_scale(data_1d):\n",
        "        dummy = np.zeros((len(data_1d), scaler.n_features_in_))\n",
        "        dummy[:, target_idx] = data_1d.flatten()\n",
        "        return scaler.inverse_transform(dummy)[:, target_idx]\n",
        "\n",
        "    pred_inverse = inverse_scale(predictions)\n",
        "    true_inverse = inverse_scale(y_true)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(true_inverse, pred_inverse))\n",
        "    return rmse, true_inverse, pred_inverse\n",
        "\n",
        "# Plotting Function\n",
        "def plot_results(model_name, dates, y_true, y_pred):\n",
        "    df_plot = pd.DataFrame({'Actual': y_true, 'Predicted': y_pred}, index=dates)\n",
        "\n",
        "    # Target period for visualization\n",
        "    target_start = \"2025-11-24\"\n",
        "    target_end = \"2025-11-28\"\n",
        "    mask = (df_plot.index >= target_start) & (df_plot.index <= target_end)\n",
        "    df_subset = df_plot.loc[mask]\n",
        "\n",
        "    if df_subset.empty:\n",
        "        print(f\"Warning: No data for {target_start} ~ {target_end}. Showing last 20 days.\")\n",
        "        df_subset = df_plot.tail(20)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Actual (Blue)\n",
        "    plt.plot(df_subset.index, df_subset['Actual'], label='Actual (KOSPI)', color='blue', marker='o', linewidth=2)\n",
        "\n",
        "    # Predicted (Red)\n",
        "    plt.plot(df_subset.index, df_subset['Predicted'], label=f'Predicted ({model_name})', color='red', linestyle='--', marker='x', linewidth=2)\n",
        "\n",
        "    plt.title(f\"{model_name}: KOSPI Comparison ({target_start} ~ {target_end})\", fontsize=15)\n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Price (KRW)', fontsize=12)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Annotate Values\n",
        "    for i in range(len(df_subset)):\n",
        "        date = df_subset.index[i]\n",
        "        act = df_subset['Actual'].iloc[i]\n",
        "        pred = df_subset['Predicted'].iloc[i]\n",
        "        plt.text(date, act, f\"{act:.0f}\", ha='center', va='bottom', color='blue', fontsize=9)\n",
        "        plt.text(date, pred, f\"{pred:.0f}\", ha='center', va='top', color='red', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = f\"prediction_plot_{model_name.replace(' ', '_').replace('+', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 5. Main Execution ---\n",
        "def main():\n",
        "    print(\"1. Loading and Preprocessing Data...\")\n",
        "    try:\n",
        "        X_train, y_train, X_test, y_test, scaler, target_idx, test_dates = load_and_process_data(CONFIG)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data loading: {e}\")\n",
        "        return\n",
        "\n",
        "    input_size = X_train.shape[2]\n",
        "    print(f\"   Input Features: {input_size}, Train Size: {len(X_train)}, Test Size: {len(X_test)}\")\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # Model Dictionary\n",
        "    models = {\n",
        "        \"CNN\": CNNModel(input_size, CONFIG[\"num_classes\"], CONFIG[\"num_filters\"], CONFIG[\"kernel_size\"], CONFIG[\"seq_length\"]),\n",
        "        \"LSTM\": LSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"]),\n",
        "        \"CNN + LSTM\": CNNLSTMModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"], CONFIG[\"num_filters\"], CONFIG[\"kernel_size\"]),\n",
        "        \"LSTM (Attention)\": LSTMAttentionModel(input_size, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"])\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    print(\"\\n2. Starting Model Training...\")\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n[{name}] Training...\")\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        trained_model, _ = train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        rmse, y_true, y_pred = evaluate_model(trained_model, X_test, y_test, scaler, target_idx, CONFIG)\n",
        "        results[name] = rmse\n",
        "        print(f\"  >> {name} RMSE: {rmse:.4f}\")\n",
        "\n",
        "        plot_results(name, test_dates, y_true, y_pred)\n",
        "\n",
        "    print(\"\\n3. Final RMSE Comparison\")\n",
        "    df_results = pd.DataFrame(list(results.items()), columns=[\"Model\", \"RMSE\"])\n",
        "    df_results = df_results.sort_values(by=\"RMSE\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(df_results)\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    df_results.to_csv(\"model_rmse_comparison.csv\", index=False)\n",
        "    print(\"Results saved to 'model_rmse_comparison.csv'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "BVclIPZwjghj",
        "outputId": "6886eafa-704e-4dc4-c13a-f08e2bdb8bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37; latest registration was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1608115773.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2680\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from torch._decomp import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0m_convert_out_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;31m# populate the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/decompositions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprim_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IMPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CompositeExplicitAutograd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprim_backend_select_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IMPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BackendSelect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         self.m: Optional[Any] = torch._C._dispatch_library(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace prims; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37; latest registration was registered at /usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py:37"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##피처 제거 test"
      ],
      "metadata": {
        "id": "1gX2gnnXyW0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# [수정] 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 강제 지정하여 에러 방지\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\", # 학습용 데이터 끝나는 날짜\n",
        "    \"test_start_date\": \"2025-11-24\",   # RMSE 평가 시작 날짜\n",
        "    \"test_end_date\": \"2025-11-28\",     # RMSE 평가 종료 날짜\n",
        "\n",
        "    \"plot_start_date\": \"2023-04-01\",   # 그래프 그릴 시작 날짜\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50, # 실험 속도를 위해 50으로 설정 (필요시 100으로 증가)\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups Definition ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'], # Foreign_Rate는 csv 컬럼명 확인 필요\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    \"\"\"특정 피처 그룹을 제거하고 데이터셋을 준비함\"\"\"\n",
        "\n",
        "    target_col = \"KOSPI_Close\"\n",
        "\n",
        "    # 전체 사용 가능한 피처 식별\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    # 제거할 피처 목록 결정\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        # 실제 데이터에 있는 것만 필터링\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "\n",
        "    # [중요] 타겟 컬럼(KOSPI_Close)은 y생성을 위해 제거하면 안 됨.\n",
        "    # 하지만 X(입력)에서는 제거 실험을 할 수 있음.\n",
        "    # 여기서는 y데이터를 먼저 뽑고, X데이터프레임에서 제거하는 방식을 사용.\n",
        "\n",
        "    # 1. Target Data 추출 (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input Features 구성 (X)\n",
        "    # drop_group에 target_col이 포함되어 있어도 X에서는 제거, y는 유지\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    # Scaler\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    # Sequence Generation\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0]) # Next step prediction\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Dates alignment\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    # Split based on date\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "\n",
        "    train_mask = dates <= train_end\n",
        "    # Test data: Evaluation period (Nov 24 ~ Nov 28)\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "    test_end = pd.Timestamp(config[\"test_end_date\"])\n",
        "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    # For long-term plotting\n",
        "    plot_start = pd.Timestamp(config[\"plot_start_date\"])\n",
        "    plot_mask = dates >= plot_start\n",
        "    X_plot = X[plot_mask]\n",
        "    y_plot = y[plot_mask]\n",
        "    plot_dates = dates[plot_mask]\n",
        "\n",
        "    # To Tensor\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
        "    y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
        "    X_test_t = torch.FloatTensor(X_test).to(device)\n",
        "    y_test_t = torch.FloatTensor(y_test).unsqueeze(1).to(device)\n",
        "    X_plot_t = torch.FloatTensor(X_plot).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_test_t, y_test_t, test_dates), (X_plot_t, y_plot, plot_dates)\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            if torch.isnan(loss): return model # Fail safe\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "# --- 5. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "    print(f\"Data range: {full_df.index.min()} ~ {full_df.index.max()}\")\n",
        "\n",
        "    # 1. Ablation Study Scenarios\n",
        "    scenarios = [\"Base (All Features)\"] + [f\"Remove {g}\" for g in FEATURE_GROUPS.keys()]\n",
        "\n",
        "    results = [] # Store RMSE results\n",
        "    best_rmse = float('inf')\n",
        "    best_scenario = \"Base (All Features)\"\n",
        "\n",
        "    # Store long-term predictions for plotting (only for base or best)\n",
        "    long_term_preds = {}\n",
        "\n",
        "    print(\"\\n[Start Ablation Study]\")\n",
        "\n",
        "    for scenario in scenarios:\n",
        "        drop_group = scenario.replace(\"Remove \", \"\") if \"Remove\" in scenario else None\n",
        "        print(f\"\\n>> Experiment: {scenario}\")\n",
        "\n",
        "        # Prepare Data\n",
        "        X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group)\n",
        "        train_data, test_data, plot_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        # Define Models [수정: LSTM Attention 추가]\n",
        "        models = {\n",
        "            \"CNN\": CNNModel(input_dim, 1, 32, 5, CONFIG[\"seq_length\"]),\n",
        "            \"LSTM\": LSTMModel(input_dim, 256, 1, 1),\n",
        "            \"CNN+LSTM\": CNNLSTMModel(input_dim, 256, 1, 1, 32, 5),\n",
        "            \"LSTM(Attn)\": LSTMAttentionModel(input_dim, 256, 1, 1)\n",
        "        }\n",
        "\n",
        "        scenario_rmse = {}\n",
        "\n",
        "        for name, model in models.items():\n",
        "            model.to(CONFIG['device'])\n",
        "            train_model(model, train_loader, CONFIG)\n",
        "\n",
        "            # Evaluate on Test (Nov 24 ~ Nov 28)\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                pred_scaled = model(test_data[0]).cpu().numpy()\n",
        "                y_true_scaled = test_data[1].cpu().numpy()\n",
        "\n",
        "            pred_inv = scaler_y.inverse_transform(pred_scaled)\n",
        "            y_true_inv = scaler_y.inverse_transform(y_true_scaled)\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(y_true_inv, pred_inv))\n",
        "            scenario_rmse[name] = rmse\n",
        "            print(f\"   [{name}] RMSE: {rmse:.4f}\")\n",
        "\n",
        "            # Save predictions for Base scenario (to plot long term graph)\n",
        "            if scenario == \"Base (All Features)\":\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    plot_pred_scaled = model(plot_data[0]).cpu().numpy()\n",
        "                plot_pred_inv = scaler_y.inverse_transform(plot_pred_scaled)\n",
        "                long_term_preds[name] = pd.Series(plot_pred_inv.flatten(), index=plot_data[2])\n",
        "\n",
        "                # Save Actuals once\n",
        "                if \"Actual\" not in long_term_preds:\n",
        "                    y_plot_inv = scaler_y.inverse_transform(plot_data[1].reshape(-1,1))\n",
        "                    long_term_preds[\"Actual\"] = pd.Series(y_plot_inv.flatten(), index=plot_data[2])\n",
        "\n",
        "        # Record Results\n",
        "        row = {\"Scenario\": scenario}\n",
        "        row.update(scenario_rmse)\n",
        "        results.append(row)\n",
        "\n",
        "    # --- 6. Results & Plotting ---\n",
        "    print(\"\\n[Ablation Study Results]\")\n",
        "    df_res = pd.DataFrame(results)\n",
        "    print(df_res)\n",
        "    df_res.to_csv(\"ablation_study_results.csv\", index=False)\n",
        "\n",
        "    # 2. Long-term Plotting (2023-04 ~ 2025-11-28)\n",
        "    print(\"\\n[Drawing Long-term Comparison Plot...]\")\n",
        "    plt.figure(figsize=(14, 7))\n",
        "\n",
        "    # Actual\n",
        "    plt.plot(long_term_preds[\"Actual\"].index, long_term_preds[\"Actual\"], label='Actual (KOSPI)', color='black', alpha=0.6, linewidth=1.5)\n",
        "\n",
        "    # Models [수정: LSTM(Attn) 색상 추가]\n",
        "    colors = {'CNN': 'green', 'LSTM': 'blue', 'CNN+LSTM': 'red', 'LSTM(Attn)': 'purple'}\n",
        "    for name, pred_series in long_term_preds.items():\n",
        "        if name == \"Actual\": continue\n",
        "        plt.plot(pred_series.index, pred_series, label=name, color=colors.get(name, 'orange'), alpha=0.8, linewidth=1)\n",
        "\n",
        "    plt.title(f\"Long-term KOSPI Prediction ({CONFIG['plot_start_date']} ~ {CONFIG['data_end']})\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.savefig(\"long_term_prediction_comparison.png\", dpi=300)\n",
        "    print(\"Graph Saved: long_term_prediction_comparison.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ooVJdFjDwyCw",
        "outputId": "13d41cbb-1855-4fae-e292-a7b9f351a836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Loading Data...\n",
            "Data range: 2013-08-06 00:00:00 ~ 2025-11-28 00:00:00\n",
            "\n",
            "[Start Ablation Study]\n",
            "\n",
            ">> Experiment: Base (All Features)\n",
            "   [CNN] RMSE: 62.1052\n",
            "   [LSTM] RMSE: 47.7212\n",
            "   [CNN+LSTM] RMSE: 60.5714\n",
            "   [LSTM(Attn)] RMSE: 59.7727\n",
            "\n",
            ">> Experiment: Remove KOSPI\n",
            "   [CNN] RMSE: 71.8171\n",
            "   [LSTM] RMSE: 63.4383\n",
            "   [CNN+LSTM] RMSE: 38.4365\n",
            "   [LSTM(Attn)] RMSE: 79.5687\n",
            "\n",
            ">> Experiment: Remove NASDAQ\n",
            "   [CNN] RMSE: 64.7363\n",
            "   [LSTM] RMSE: 47.9368\n",
            "   [CNN+LSTM] RMSE: 50.9935\n",
            "   [LSTM(Attn)] RMSE: 64.5198\n",
            "\n",
            ">> Experiment: Remove VKOSPI\n",
            "   [CNN] RMSE: 67.3551\n",
            "   [LSTM] RMSE: 48.8313\n",
            "   [CNN+LSTM] RMSE: 68.8342\n",
            "   [LSTM(Attn)] RMSE: 61.5121\n",
            "\n",
            ">> Experiment: Remove Rate_FX\n",
            "   [CNN] RMSE: 68.4393\n",
            "   [LSTM] RMSE: 51.6339\n",
            "   [CNN+LSTM] RMSE: 40.2895\n",
            "   [LSTM(Attn)] RMSE: 70.8658\n",
            "\n",
            ">> Experiment: Remove Foreign\n",
            "   [CNN] RMSE: 21.6330\n",
            "   [LSTM] RMSE: 51.1194\n",
            "   [CNN+LSTM] RMSE: 70.1717\n",
            "   [LSTM(Attn)] RMSE: 58.7029\n",
            "\n",
            ">> Experiment: Remove Future\n",
            "   [CNN] RMSE: 72.2914\n",
            "   [LSTM] RMSE: 60.6330\n",
            "   [CNN+LSTM] RMSE: 68.3136\n",
            "   [LSTM(Attn)] RMSE: 65.7375\n",
            "\n",
            ">> Experiment: Remove Oil\n",
            "   [CNN] RMSE: 51.9548\n",
            "   [LSTM] RMSE: 49.0387\n",
            "   [CNN+LSTM] RMSE: 64.3904\n",
            "   [LSTM(Attn)] RMSE: 62.0196\n",
            "\n",
            "[Ablation Study Results]\n",
            "              Scenario        CNN       LSTM   CNN+LSTM  LSTM(Attn)\n",
            "0  Base (All Features)  62.105234  47.721211  60.571396   59.772659\n",
            "1         Remove KOSPI  71.817093  63.438295  38.436454   79.568710\n",
            "2        Remove NASDAQ  64.736293  47.936812  50.993506   64.519778\n",
            "3        Remove VKOSPI  67.355078  48.831327  68.834203   61.512067\n",
            "4       Remove Rate_FX  68.439266  51.633942  40.289465   70.865761\n",
            "5       Remove Foreign  21.633048  51.119360  70.171675   58.702873\n",
            "6        Remove Future  72.291355  60.633009  68.313597   65.737523\n",
            "7           Remove Oil  51.954798  49.038703  64.390361   62.019632\n",
            "\n",
            "[Drawing Long-term Comparison Plot...]\n",
            "Graph Saved: long_term_prediction_comparison.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN feature remove graph"
      ],
      "metadata": {
        "id": "awxuhWZEyhEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 사용\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\",\n",
        "    \"test_start_date\": \"2025-11-24\",\n",
        "    \"test_end_date\": \"2025-11-28\",\n",
        "\n",
        "    \"plot_start_date\": \"2023-04-01\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    # CNN Hyperparameters\n",
        "    \"num_classes\": 1,\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups Definition ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'], # 외인보유 묶음\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change'],                                          # WTI 묶음\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'] # 나스닥 묶음\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    # 제거할 피처 목록 결정\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "\n",
        "    # 1. Target Data (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input Features (X) - Drop specific group\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "\n",
        "    train_mask = dates <= train_end\n",
        "\n",
        "    # Long-term plotting data\n",
        "    plot_start = pd.Timestamp(config[\"plot_start_date\"])\n",
        "    plot_mask = dates >= plot_start\n",
        "    X_plot = X[plot_mask]\n",
        "    y_plot = y[plot_mask]\n",
        "    plot_dates = dates[plot_mask]\n",
        "\n",
        "    # Tensor conversion\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X[train_mask]).to(device)\n",
        "    y_train_t = torch.FloatTensor(y[train_mask]).unsqueeze(1).to(device)\n",
        "    X_plot_t = torch.FloatTensor(X_plot).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_plot_t, y_plot, plot_dates)\n",
        "\n",
        "# --- 3. CNN Model ---\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "# --- 5. Plotting Function ---\n",
        "def plot_individual_graph(scenario_name, dates, y_true, y_pred):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Actual\n",
        "    plt.plot(dates, y_true, label='Actual (KOSPI)', color='black', alpha=0.5, linewidth=1.5)\n",
        "\n",
        "    # Predicted\n",
        "    plt.plot(dates, y_pred, label=f'CNN Prediction ({scenario_name})', color='red', alpha=0.8, linewidth=1.5)\n",
        "\n",
        "    plt.title(f\"CNN Analysis: {scenario_name} ({CONFIG['plot_start_date']} ~ {CONFIG['data_end']})\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Save file\n",
        "    filename = f\"CNN_Analysis_{scenario_name.replace(' ', '_')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Target Scenarios\n",
        "    scenarios_to_analyze = [\"Foreign\", \"Oil\", \"NASDAQ\"]\n",
        "\n",
        "    print(\"\\n[Start CNN Analysis by Feature Group]\")\n",
        "\n",
        "    for group_name in scenarios_to_analyze:\n",
        "        scenario_label = f\"Remove {group_name}\"\n",
        "        print(f\"\\n>> Analyzing Scenario: {scenario_label}\")\n",
        "\n",
        "        # 1. Process Data (Remove specific group)\n",
        "        X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group_name=group_name)\n",
        "        train_data, plot_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        # 2. Initialize CNN Model\n",
        "        model = CNNModel(input_dim, 1, CONFIG[\"num_filters\"], CONFIG[\"kernel_size\"], CONFIG[\"seq_length\"])\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. Train\n",
        "        train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        # 4. Predict Long-term\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(plot_data[0]).cpu().numpy()\n",
        "            y_true_scaled = plot_data[1].reshape(-1, 1)\n",
        "\n",
        "        pred_inv = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "        y_true_inv = scaler_y.inverse_transform(y_true_scaled).flatten()\n",
        "\n",
        "        # 5. Plot & Save\n",
        "        plot_dates = plot_data[2]\n",
        "        plot_individual_graph(scenario_label, plot_dates, y_true_inv, pred_inv)\n",
        "\n",
        "    print(\"\\nAll graphs generated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE945d_l2E6N",
        "outputId": "24de0cbf-6cd0-49fe-dbba-272e0d51fe47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Loading Data...\n",
            "\n",
            "[Start CNN Analysis by Feature Group]\n",
            "\n",
            ">> Analyzing Scenario: Remove Foreign\n",
            "Graph Saved: CNN_Analysis_Remove_Foreign.png\n",
            "\n",
            ">> Analyzing Scenario: Remove Oil\n",
            "Graph Saved: CNN_Analysis_Remove_Oil.png\n",
            "\n",
            ">> Analyzing Scenario: Remove NASDAQ\n",
            "Graph Saved: CNN_Analysis_Remove_NASDAQ.png\n",
            "\n",
            "All graphs generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM feature remove graph"
      ],
      "metadata": {
        "id": "O3tN29g5y044"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 사용\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\",\n",
        "\n",
        "    # 그래프를 그릴 시작 날짜 (장기 추세 확인용)\n",
        "    \"plot_start_date\": \"2023-04-01\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    # LSTM Hyperparameters\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups Definition ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'], # 나스닥 묶음\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change']                                             # VKOSPI 묶음\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    # 제거할 피처 목록 결정\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "\n",
        "    # 1. Target Data (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input Features (X) - Drop specific group\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "\n",
        "    train_mask = dates <= train_end\n",
        "\n",
        "    # Long-term plotting data\n",
        "    plot_start = pd.Timestamp(config[\"plot_start_date\"])\n",
        "    plot_mask = dates >= plot_start\n",
        "    X_plot = X[plot_mask]\n",
        "    y_plot = y[plot_mask]\n",
        "    plot_dates = dates[plot_mask]\n",
        "\n",
        "    # Tensor conversion\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X[train_mask]).to(device)\n",
        "    y_train_t = torch.FloatTensor(y[train_mask]).unsqueeze(1).to(device)\n",
        "    X_plot_t = torch.FloatTensor(X_plot).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_plot_t, y_plot, plot_dates)\n",
        "\n",
        "# --- 3. LSTM Model ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "# --- 5. Plotting Function ---\n",
        "def plot_individual_graph(scenario_label, dates, y_true, y_pred):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Actual\n",
        "    plt.plot(dates, y_true, label='Actual (KOSPI)', color='blue', alpha=0.5, linewidth=1.5)\n",
        "\n",
        "    # Predicted\n",
        "    plt.plot(dates, y_pred, label=f'LSTM Prediction ({scenario_label})', color='red', alpha=0.8, linewidth=1.5)\n",
        "\n",
        "    plt.title(f\"LSTM Analysis: {scenario_label} ({CONFIG['plot_start_date']} ~ {CONFIG['data_end']})\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Save file\n",
        "    filename = f\"LSTM_Analysis_{scenario_label.replace(' ', '_').replace('(', '').replace(')', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Target Scenarios for LSTM\n",
        "    # (Label Name, Drop Group Name)\n",
        "    scenarios = [\n",
        "        (\"Base (All Features)\", None),      # 1순위: All Features\n",
        "        (\"Remove NASDAQ\", \"NASDAQ\"),        # 2순위: Remove NASDAQ\n",
        "        (\"Remove VKOSPI\", \"VKOSPI\")         # 3순위: Remove VKOSPI\n",
        "    ]\n",
        "\n",
        "    print(\"\\n[Start LSTM Analysis by Feature Group]\")\n",
        "\n",
        "    for label, drop_group in scenarios:\n",
        "        print(f\"\\n>> Analyzing Scenario: {label}\")\n",
        "\n",
        "        # 1. Process Data (Remove specific group)\n",
        "        X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group_name=drop_group)\n",
        "        train_data, plot_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        # 2. Initialize LSTM Model\n",
        "        model = LSTMModel(input_dim, CONFIG[\"hidden_size\"], CONFIG[\"num_layers\"], CONFIG[\"num_classes\"])\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. Train\n",
        "        train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        # 4. Predict Long-term\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(plot_data[0]).cpu().numpy()\n",
        "            y_true_scaled = plot_data[1].reshape(-1, 1)\n",
        "\n",
        "        pred_inv = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "        y_true_inv = scaler_y.inverse_transform(y_true_scaled).flatten()\n",
        "\n",
        "        # 5. Plot & Save\n",
        "        plot_dates = plot_data[2]\n",
        "        plot_individual_graph(label, plot_dates, y_true_inv, pred_inv)\n",
        "\n",
        "    print(\"\\nAll LSTM graphs generated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "716oc2oky0P9",
        "outputId": "34388ab5-3598-4a4d-8d41-8fc4841342bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n",
            "Loading Data...\n",
            "\n",
            "[Start LSTM Analysis by Feature Group]\n",
            "\n",
            ">> Analyzing Scenario: Base (All Features)\n",
            "Graph Saved: LSTM_Analysis_Base_All_Features.png\n",
            "\n",
            ">> Analyzing Scenario: Remove NASDAQ\n",
            "Graph Saved: LSTM_Analysis_Remove_NASDAQ.png\n",
            "\n",
            ">> Analyzing Scenario: Remove VKOSPI\n",
            "Graph Saved: LSTM_Analysis_Remove_VKOSPI.png\n",
            "\n",
            "All LSTM graphs generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN+LSTM feature remove test"
      ],
      "metadata": {
        "id": "SlFLFDWI17ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 사용\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. 설정 (Configuration) ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\",\n",
        "\n",
        "    \"plot_start_date\": \"2023-04-01\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    # CNN+LSTM 하이퍼파라미터\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "    \"num_filters\": 32,   # CNN 필터 수\n",
        "    \"kernel_size\": 5,    # CNN 커널 크기\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- 피처 그룹 정의 ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],                                   # 금리/환율 묶음\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'] # 나스닥 묶음\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. 데이터 처리 함수 ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        # 타겟 컬럼(KOSPI_Close)은 y데이터 생성을 위해 필요하므로 cols_to_drop에서 제외\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    raw_y = df[[target_col]].values\n",
        "    # 입력 데이터(X)에서는 해당 그룹 피처를 모두 제거 (타겟 컬럼 제외)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "    train_mask = dates <= train_end\n",
        "\n",
        "    plot_start = pd.Timestamp(config[\"plot_start_date\"])\n",
        "    plot_mask = dates >= plot_start\n",
        "    X_plot = X[plot_mask]\n",
        "    y_plot = y[plot_mask]\n",
        "    plot_dates = dates[plot_mask]\n",
        "\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X[train_mask]).to(device)\n",
        "    y_train_t = torch.FloatTensor(y[train_mask]).unsqueeze(1).to(device)\n",
        "    X_plot_t = torch.FloatTensor(X_plot).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_plot_t, y_plot, plot_dates)\n",
        "\n",
        "# --- 3. CNN+LSTM 모델 정의 ---\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        # CNN Layer\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        # LSTM Layer\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (Batch, Seq, Feat)\n",
        "        # Conv1d expects: (Batch, Channel/Feat, Seq)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        # LSTM expects: (Batch, Seq, Feat)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "# --- 4. 학습 함수 ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "# --- 5. 그래프 그리기 함수 ---\n",
        "def plot_individual_graph(scenario_label, dates, y_true, y_pred):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 실제값\n",
        "    plt.plot(dates, y_true, label='Actual (KOSPI)', color='blue', alpha=0.5, linewidth=1.5)\n",
        "\n",
        "    # 예측값 (CNN+LSTM)\n",
        "    plt.plot(dates, y_pred, label=f'CNN+LSTM Prediction ({scenario_label})', color='red', alpha=0.8, linewidth=1.5)\n",
        "\n",
        "    plt.title(f\"CNN+LSTM Analysis: {scenario_label} ({CONFIG['plot_start_date']} ~ {CONFIG['data_end']})\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 파일 저장\n",
        "    filename = f\"CNNLSTM_Analysis_{scenario_label.replace(' ', '_').replace('(', '').replace(')', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. 메인 실행 ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # 분석 시나리오 설정 (Label Name, Drop Group Name)\n",
        "    scenarios = [\n",
        "        (\"Remove KOSPI\", \"KOSPI\"),          # 1순위: KOSPI 제거\n",
        "        (\"Remove Rate & FX\", \"Rate_FX\"),    # 2순위: 금리/환율 제거\n",
        "        (\"Remove NASDAQ\", \"NASDAQ\")         # 3순위: 나스닥 제거\n",
        "    ]\n",
        "\n",
        "    print(\"\\n[Start CNN+LSTM Analysis by Feature Group]\")\n",
        "\n",
        "    for label, drop_group in scenarios:\n",
        "        print(f\"\\n>> Analyzing Scenario: {label}\")\n",
        "\n",
        "        # 1. 데이터 준비\n",
        "        X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group_name=drop_group)\n",
        "        train_data, plot_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        # 2. 모델 초기화 (CNN+LSTM)\n",
        "        model = CNNLSTMModel(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=CONFIG[\"hidden_size\"],\n",
        "            num_layers=CONFIG[\"num_layers\"],\n",
        "            output_size=CONFIG[\"num_classes\"],\n",
        "            num_filters=CONFIG[\"num_filters\"],\n",
        "            kernel_size=CONFIG[\"kernel_size\"]\n",
        "        )\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. 학습\n",
        "        train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        # 4. 장기 예측\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(plot_data[0]).cpu().numpy()\n",
        "            y_true_scaled = plot_data[1].reshape(-1, 1)\n",
        "\n",
        "        pred_inv = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "        y_true_inv = scaler_y.inverse_transform(y_true_scaled).flatten()\n",
        "\n",
        "        # 5. 그래프 저장\n",
        "        plot_dates = plot_data[2]\n",
        "        plot_individual_graph(label, plot_dates, y_true_inv, pred_inv)\n",
        "\n",
        "    print(\"\\nAll CNN+LSTM graphs generated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OunKh5Ws1_y2",
        "outputId": "43e10049-9fa8-4579-ad42-2cb68dd577f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n",
            "Loading Data...\n",
            "\n",
            "[Start CNN+LSTM Analysis by Feature Group]\n",
            "\n",
            ">> Analyzing Scenario: Remove KOSPI\n",
            "Graph Saved: CNNLSTM_Analysis_Remove_KOSPI.png\n",
            "\n",
            ">> Analyzing Scenario: Remove Rate & FX\n",
            "Graph Saved: CNNLSTM_Analysis_Remove_Rate_&_FX.png\n",
            "\n",
            ">> Analyzing Scenario: Remove NASDAQ\n",
            "Graph Saved: CNNLSTM_Analysis_Remove_NASDAQ.png\n",
            "\n",
            "All CNN+LSTM graphs generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attention 적용 모델"
      ],
      "metadata": {
        "id": "3YPU0H6qF8Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 사용\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. 설정 (Configuration) ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\",\n",
        "\n",
        "    \"plot_start_date\": \"2023-04-01\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    # LSTM Attention 하이퍼파라미터\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- 피처 그룹 정의 ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'], # 외인 비율/자본 묶음\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],                                 # VKOSPI 묶음\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'] # (참고용)\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. 데이터 처리 함수 ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "\n",
        "    raw_y = df[[target_col]].values\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "    train_mask = dates <= train_end\n",
        "\n",
        "    plot_start = pd.Timestamp(config[\"plot_start_date\"])\n",
        "    plot_mask = dates >= plot_start\n",
        "    X_plot = X[plot_mask]\n",
        "    y_plot = y[plot_mask]\n",
        "    plot_dates = dates[plot_mask]\n",
        "\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X[train_mask]).to(device)\n",
        "    y_train_t = torch.FloatTensor(y[train_mask]).unsqueeze(1).to(device)\n",
        "    X_plot_t = torch.FloatTensor(X_plot).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_plot_t, y_plot, plot_dates)\n",
        "\n",
        "# --- 3. LSTM Attention 모델 정의 ---\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # Attention Layer\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (Batch, Seq, Feat)\n",
        "        out, _ = self.lstm(x) # out: (Batch, Seq, Hidden)\n",
        "\n",
        "        # Attention Score\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1) # (Batch, Seq, 1)\n",
        "\n",
        "        # Context Vector (Weighted Sum)\n",
        "        context = torch.sum(attn_weights * out, dim=1) # (Batch, Hidden)\n",
        "\n",
        "        output = self.fc(context)\n",
        "        return output\n",
        "\n",
        "# --- 4. 학습 함수 ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "# --- 5. 그래프 그리기 함수 ---\n",
        "def plot_individual_graph(scenario_label, dates, y_true, y_pred):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 실제값\n",
        "    plt.plot(dates, y_true, label='Actual (KOSPI)', color='blue', alpha=0.5, linewidth=1.5)\n",
        "\n",
        "    # 예측값 (LSTM Attention - 보라색)\n",
        "    plt.plot(dates, y_pred, label=f'LSTM(Attn) Prediction ({scenario_label})', color='red', alpha=0.8, linewidth=1.5)\n",
        "\n",
        "    plt.title(f\"LSTM Attention Analysis: {scenario_label} ({CONFIG['plot_start_date']} ~ {CONFIG['data_end']})\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 파일 저장\n",
        "    filename = f\"LSTMAttn_Analysis_{scenario_label.replace(' ', '_').replace('(', '').replace(')', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. 메인 실행 ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # 분석 시나리오 설정 (Label Name, Drop Group Name)\n",
        "    scenarios = [\n",
        "        (\"Remove Foreign\", \"Foreign\"),      # 1순위: 외인 제거\n",
        "        (\"Base (All Features)\", None),      # 2순위: 전체 피처\n",
        "        (\"Remove VKOSPI\", \"VKOSPI\")         # 3순위: VKOSPI 제거\n",
        "    ]\n",
        "\n",
        "    print(\"\\n[Start LSTM Attention Analysis by Feature Group]\")\n",
        "\n",
        "    for label, drop_group in scenarios:\n",
        "        print(f\"\\n>> Analyzing Scenario: {label}\")\n",
        "\n",
        "        # 1. 데이터 준비\n",
        "        X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group_name=drop_group)\n",
        "        train_data, plot_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        # 2. 모델 초기화 (LSTM Attention)\n",
        "        model = LSTMAttentionModel(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=CONFIG[\"hidden_size\"],\n",
        "            num_layers=CONFIG[\"num_layers\"],\n",
        "            output_size=CONFIG[\"num_classes\"]\n",
        "        )\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. 학습\n",
        "        train_model(model, train_loader, CONFIG)\n",
        "\n",
        "        # 4. 장기 예측\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(plot_data[0]).cpu().numpy()\n",
        "            y_true_scaled = plot_data[1].reshape(-1, 1)\n",
        "\n",
        "        pred_inv = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "        y_true_inv = scaler_y.inverse_transform(y_true_scaled).flatten()\n",
        "\n",
        "        # 5. 그래프 저장\n",
        "        plot_dates = plot_data[2]\n",
        "        plot_individual_graph(label, plot_dates, y_true_inv, pred_inv)\n",
        "\n",
        "    print(\"\\nAll LSTM Attention graphs generated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKYedN9LF_Hv",
        "outputId": "c66e3c97-6638-4004-b1d0-ceb2b56b61fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n",
            "Loading Data...\n",
            "\n",
            "[Start LSTM Attention Analysis by Feature Group]\n",
            "\n",
            ">> Analyzing Scenario: Remove Foreign\n",
            "Graph Saved: LSTMAttn_Analysis_Remove_Foreign.png\n",
            "\n",
            ">> Analyzing Scenario: Base (All Features)\n",
            "Graph Saved: LSTMAttn_Analysis_Base_All_Features.png\n",
            "\n",
            ">> Analyzing Scenario: Remove VKOSPI\n",
            "Graph Saved: LSTMAttn_Analysis_Remove_VKOSPI.png\n",
            "\n",
            "All LSTM Attention graphs generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4가지 모델 all feature RMSE"
      ],
      "metadata": {
        "id": "f4zZs4ju8b_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 강제 지정\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\",\n",
        "    \"test_start_date\": \"2025-11-24\",\n",
        "    \"test_end_date\": \"2025-11-28\",\n",
        "\n",
        "    \"plot_start_date\": \"2023-04-01\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups Definition ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "\n",
        "    raw_y = df[[target_col]].values\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "    train_mask = dates <= train_end\n",
        "\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "    test_end = pd.Timestamp(config[\"test_end_date\"])\n",
        "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    plot_start = pd.Timestamp(config[\"plot_start_date\"])\n",
        "    plot_mask = dates >= plot_start\n",
        "    X_plot = X[plot_mask]\n",
        "    y_plot = y[plot_mask]\n",
        "    plot_dates = dates[plot_mask]\n",
        "\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
        "    y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
        "    X_test_t = torch.FloatTensor(X_test).to(device)\n",
        "    y_test_t = torch.FloatTensor(y_test).unsqueeze(1).to(device)\n",
        "    X_plot_t = torch.FloatTensor(X_plot).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_test_t, y_test_t, test_dates), (X_plot_t, y_plot, plot_dates)\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            if torch.isnan(loss): return model\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "# --- 5. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "    print(f\"Data range: {full_df.index.min()} ~ {full_df.index.max()}\")\n",
        "\n",
        "    # [설정] 그래프를 그리기 위해 'Base (All Features)' 시나리오만 기본 실행\n",
        "    # (전체 Ablation 실험을 원하면 아래 주석을 해제하고 scenarios 리스트를 확장하세요)\n",
        "    scenarios = [\"Base (All Features)\"]\n",
        "    # scenarios = [\"Base (All Features)\"] + [f\"Remove {g}\" for g in FEATURE_GROUPS.keys()]\n",
        "\n",
        "    results = []\n",
        "    long_term_preds = {}\n",
        "\n",
        "    print(\"\\n[Start Training & Prediction]\")\n",
        "\n",
        "    for scenario in scenarios:\n",
        "        drop_group = scenario.replace(\"Remove \", \"\") if \"Remove\" in scenario else None\n",
        "        print(f\"\\n>> Scenario: {scenario}\")\n",
        "\n",
        "        X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group)\n",
        "        train_data, test_data, plot_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "        train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        models = {\n",
        "            \"CNN\": CNNModel(input_dim, 1, 32, 5, CONFIG[\"seq_length\"]),\n",
        "            \"LSTM\": LSTMModel(input_dim, 256, 1, 1),\n",
        "            \"CNN+LSTM\": CNNLSTMModel(input_dim, 256, 1, 1, 32, 5),\n",
        "            \"LSTM(Attn)\": LSTMAttentionModel(input_dim, 256, 1, 1)\n",
        "        }\n",
        "\n",
        "        scenario_rmse = {}\n",
        "\n",
        "        for name, model in models.items():\n",
        "            print(f\"   Training {name}...\")\n",
        "            model.to(CONFIG['device'])\n",
        "            train_model(model, train_loader, CONFIG)\n",
        "\n",
        "            # 1. Test RMSE Calculation\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                pred_scaled = model(test_data[0]).cpu().numpy()\n",
        "                y_true_scaled = test_data[1].cpu().numpy()\n",
        "\n",
        "            pred_inv = scaler_y.inverse_transform(pred_scaled)\n",
        "            y_true_inv = scaler_y.inverse_transform(y_true_scaled)\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(y_true_inv, pred_inv))\n",
        "            scenario_rmse[name] = rmse\n",
        "            print(f\"     -> RMSE: {rmse:.4f}\")\n",
        "\n",
        "            # 2. Long-term Prediction (Only for Base scenario)\n",
        "            if scenario == \"Base (All Features)\":\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    plot_pred_scaled = model(plot_data[0]).cpu().numpy()\n",
        "                plot_pred_inv = scaler_y.inverse_transform(plot_pred_scaled)\n",
        "                long_term_preds[name] = pd.Series(plot_pred_inv.flatten(), index=plot_data[2])\n",
        "\n",
        "                if \"Actual\" not in long_term_preds:\n",
        "                    y_plot_inv = scaler_y.inverse_transform(plot_data[1].reshape(-1,1))\n",
        "                    long_term_preds[\"Actual\"] = pd.Series(y_plot_inv.flatten(), index=plot_data[2])\n",
        "\n",
        "        row = {\"Scenario\": scenario}\n",
        "        row.update(scenario_rmse)\n",
        "        results.append(row)\n",
        "\n",
        "    # --- 6. Results & Individual Plotting ---\n",
        "    print(\"\\n[Results Summary]\")\n",
        "    df_res = pd.DataFrame(results)\n",
        "    print(df_res)\n",
        "    df_res.to_csv(\"ablation_study_results.csv\", index=False)\n",
        "\n",
        "    # [수정] 모델별 개별 그래프 그리기\n",
        "    print(\"\\n[Drawing Individual Graphs for Base Scenario...]\")\n",
        "\n",
        "    if \"Actual\" in long_term_preds:\n",
        "        actual_data = long_term_preds[\"Actual\"]\n",
        "\n",
        "        for name, pred_series in long_term_preds.items():\n",
        "            if name == \"Actual\": continue\n",
        "\n",
        "            plt.figure(figsize=(14, 7))\n",
        "\n",
        "            # Actual (Black line)\n",
        "            plt.plot(actual_data.index, actual_data, label='Actual (KOSPI)', color='black', alpha=0.5, linewidth=1.5)\n",
        "\n",
        "            # Predicted (Red line)\n",
        "            plt.plot(pred_series.index, pred_series, label=f'Predicted ({name})', color='red', alpha=0.8, linewidth=1.5)\n",
        "\n",
        "            plt.title(f\"Long-term Prediction: {name} (All Features)\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Price\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # Filename formatting\n",
        "            safe_name = name.replace('(', '').replace(')', '').replace('+', '_')\n",
        "            fname = f\"LongTerm_Prediction_{safe_name}.png\"\n",
        "\n",
        "            plt.savefig(fname, dpi=300)\n",
        "            print(f\"Saved graph: {fname}\")\n",
        "            plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGmjDBLs571G",
        "outputId": "21740b75-cd56-43f7-9aeb-9e436ea1cd02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Loading Data...\n",
            "Data range: 2013-08-06 00:00:00 ~ 2025-11-28 00:00:00\n",
            "\n",
            "[Start Training & Prediction]\n",
            "\n",
            ">> Scenario: Base (All Features)\n",
            "   Training CNN...\n",
            "     -> RMSE: 49.0156\n",
            "   Training LSTM...\n",
            "     -> RMSE: 51.9183\n",
            "   Training CNN+LSTM...\n",
            "     -> RMSE: 62.3512\n",
            "   Training LSTM(Attn)...\n",
            "     -> RMSE: 62.5916\n",
            "\n",
            "[Results Summary]\n",
            "              Scenario        CNN       LSTM   CNN+LSTM  LSTM(Attn)\n",
            "0  Base (All Features)  49.015583  51.918318  62.351239   62.591593\n",
            "\n",
            "[Drawing Individual Graphs for Base Scenario...]\n",
            "Saved graph: LongTerm_Prediction_CNN.png\n",
            "Saved graph: LongTerm_Prediction_LSTM.png\n",
            "Saved graph: LongTerm_Prediction_CNN_LSTM.png\n",
            "Saved graph: LongTerm_Prediction_LSTMAttn.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Each optimized model plotting"
      ],
      "metadata": {
        "id": "lUoAMvIgJbfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import os\n",
        "\n",
        "# 폰트 설정 (코랩/영문 환경 호환)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "\n",
        "    # 검증 대상 기간 (Actual vs Predicted 비교용)\n",
        "    \"test_start_date\": \"2025-11-24\",\n",
        "    \"test_end_date\": \"2025-11-28\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing Utils ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def process_features_and_split(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    # 1. Target (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input (X)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    # 시퀀스 데이터 생성\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0]) # 다음 스텝(1일 뒤) 예측 학습용\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # 날짜 매핑 (예측 대상 날짜 기준)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    # Split Train/Test based on Date\n",
        "    test_start = pd.Timestamp(CONFIG[\"test_start_date\"])\n",
        "    test_end = pd.Timestamp(CONFIG[\"test_end_date\"])\n",
        "\n",
        "    # 학습 데이터: 테스트 시작일 이전\n",
        "    train_mask = dates < test_start\n",
        "    # 테스트 데이터: 지정된 기간 (11/24 ~ 11/28)\n",
        "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
        "\n",
        "    X_train = X[train_mask]\n",
        "    y_train = y[train_mask]\n",
        "\n",
        "    X_test = X[test_mask]\n",
        "    # 실제값 (Graph용)\n",
        "    y_test_raw = raw_y[seq_len:][test_mask]\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test_raw, test_dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, X_train, y_train, config):\n",
        "    X_t = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_t = torch.FloatTensor(y_train).unsqueeze(1).to(config['device'])\n",
        "\n",
        "    dataset = TensorDataset(X_t, y_t)\n",
        "    loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        for X_b, y_b in loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "# --- 5. Plotting Function (No numbers, Date only) ---\n",
        "def plot_comparison(model_name, drop_group, dates, y_true, y_pred):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Actual (Blue, Solid)\n",
        "    plt.plot(dates, y_true, label='Actual', color='blue', marker='o', linewidth=2)\n",
        "\n",
        "    # Predicted (Red, Dashed)\n",
        "    plt.plot(dates, y_pred, label='Predicted', color='red', linestyle='--', marker='x', linewidth=2)\n",
        "\n",
        "    # Styling\n",
        "    title_str = f\"{model_name} Prediction (Optimized: Drop {drop_group if drop_group else 'None'})\"\n",
        "    plt.title(title_str, fontsize=14)\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.ylabel(\"KOSPI Index\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # [수정] X축 날짜 포맷 설정 (YYYY-MM-DD, 시간 제거)\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "    plt.gca().xaxis.set_major_locator(mdates.DayLocator()) # 매일 표시\n",
        "    plt.gcf().autofmt_xdate() # 날짜 겹침 방지 (회전)\n",
        "\n",
        "    # [수정] 숫자 어노테이션 제거됨 (No plt.text)\n",
        "\n",
        "    # Save\n",
        "    safe_name = model_name.replace('+', '_').replace('(', '').replace(')', '')\n",
        "    filename = f\"Evaluation_{safe_name}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"   [Graph Saved] {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Optimized Scenarios\n",
        "    scenarios = [\n",
        "        (\"CNN\", \"Foreign\", CNNModel),\n",
        "        (\"LSTM\", None, LSTMModel),\n",
        "        (\"CNN+LSTM\", \"KOSPI\", CNNLSTMModel),\n",
        "        (\"LSTM(Attn)\", \"Foreign\", LSTMAttentionModel)\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n[Start Evaluation] Target Period: {CONFIG['test_start_date']} ~ {CONFIG['test_end_date']}\")\n",
        "\n",
        "    for model_name, drop_group, ModelClass in scenarios:\n",
        "        print(f\"\\n>> Processing {model_name} (Drop: {drop_group})...\")\n",
        "\n",
        "        # 1. Prepare Data & Split\n",
        "        X_train, y_train, X_test, y_test_raw, test_dates, scaler_y, input_dim = \\\n",
        "            process_features_and_split(full_df, drop_group)\n",
        "\n",
        "        if len(X_test) == 0:\n",
        "            print(\"   [Error] No test data found. Check date range.\")\n",
        "            continue\n",
        "\n",
        "        # 2. Init Model\n",
        "        if model_name == \"CNN\":\n",
        "            model = ModelClass(input_dim, 1, 32, 5, CONFIG[\"seq_length\"])\n",
        "        elif model_name == \"CNN+LSTM\":\n",
        "            model = ModelClass(input_dim, 256, 1, 1, 32, 5)\n",
        "        else:\n",
        "            model = ModelClass(input_dim, 256, 1, 1)\n",
        "\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. Train\n",
        "        model = train_model(model, X_train, y_train, CONFIG)\n",
        "\n",
        "        # 4. Predict\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_tensor = torch.FloatTensor(X_test).to(CONFIG['device'])\n",
        "            pred_scaled = model(input_tensor).cpu().numpy()\n",
        "\n",
        "        # 5. Inverse Transform\n",
        "        pred_prices = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "        y_true_prices = y_test_raw.flatten()\n",
        "\n",
        "        # 6. Draw & Save Graph (Clean version)\n",
        "        plot_comparison(model_name, drop_group, test_dates, y_true_prices, pred_prices)\n",
        "\n",
        "    print(\"\\nAll evaluation graphs generated.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtRsX67VK0U4",
        "outputId": "25860118-8473-4eb6-b6a3-336af7340609"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n",
            "Loading Data...\n",
            "\n",
            "[Start Evaluation] Target Period: 2025-11-24 ~ 2025-11-28\n",
            "\n",
            ">> Processing CNN (Drop: Foreign)...\n",
            "   [Graph Saved] Evaluation_CNN.png\n",
            "\n",
            ">> Processing LSTM (Drop: None)...\n",
            "   [Graph Saved] Evaluation_LSTM.png\n",
            "\n",
            ">> Processing CNN+LSTM (Drop: KOSPI)...\n",
            "   [Graph Saved] Evaluation_CNN_LSTM.png\n",
            "\n",
            ">> Processing LSTM(Attn) (Drop: Foreign)...\n",
            "   [Graph Saved] Evaluation_LSTMAttn.png\n",
            "\n",
            "All evaluation graphs generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import os\n",
        "\n",
        "# 폰트 설정 (코랩/영문 환경 호환)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "\n",
        "    # 검증 대상 기간 (Actual vs Predicted 비교용)\n",
        "    \"test_start_date\": \"2025-11-24\",\n",
        "    \"test_end_date\": \"2025-11-28\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing Utils ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def process_features_and_split(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    # 1. Target (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input (X)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    # 시퀀스 데이터 생성\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0]) # 다음 스텝(1일 뒤) 예측 학습용\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # 날짜 매핑 (예측 대상 날짜 기준)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    # Split Train/Test based on Date\n",
        "    test_start = pd.Timestamp(CONFIG[\"test_start_date\"])\n",
        "    test_end = pd.Timestamp(CONFIG[\"test_end_date\"])\n",
        "\n",
        "    # 학습 데이터: 테스트 시작일 이전\n",
        "    train_mask = dates < test_start\n",
        "    # 테스트 데이터: 지정된 기간 (11/24 ~ 11/28)\n",
        "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
        "\n",
        "    X_train = X[train_mask]\n",
        "    y_train = y[train_mask]\n",
        "\n",
        "    X_test = X[test_mask]\n",
        "    # 실제값 (Graph용)\n",
        "    y_test_raw = raw_y[seq_len:][test_mask]\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test_raw, test_dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, X_train, y_train, config):\n",
        "    X_t = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_t = torch.FloatTensor(y_train).unsqueeze(1).to(config['device'])\n",
        "\n",
        "    dataset = TensorDataset(X_t, y_t)\n",
        "    loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        for X_b, y_b in loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "# --- 5. Plotting Function (Modified) ---\n",
        "def plot_comparison(model_name, drop_group, dates, y_true, y_pred, rmse):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Actual (Blue, Solid)\n",
        "    plt.plot(dates, y_true, label='Actual', color='blue', marker='o', linewidth=2)\n",
        "\n",
        "    # Predicted (Red, Dashed)\n",
        "    plt.plot(dates, y_pred, label='Predicted', color='red', linestyle='--', marker='x', linewidth=2)\n",
        "\n",
        "    # Styling - Clean Look + RMSE in title\n",
        "    title_str = f\"{model_name} Prediction (Optimized: Drop {drop_group if drop_group else 'None'})\\nRMSE: {rmse:.4f}\"\n",
        "    plt.title(title_str, fontsize=14)\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.ylabel(\"KOSPI Index\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # X축 날짜 포맷 설정 (YYYY-MM-DD, 시간 제거)\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "    plt.gca().xaxis.set_major_locator(mdates.DayLocator()) # 매일 표시\n",
        "    plt.gcf().autofmt_xdate() # 날짜 겹침 방지 (회전)\n",
        "\n",
        "    # Save\n",
        "    safe_name = model_name.replace('+', '_').replace('(', '').replace(')', '')\n",
        "    filename = f\"Evaluation_{safe_name}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"   [Graph Saved] {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Optimized Scenarios\n",
        "    scenarios = [\n",
        "        (\"CNN\", \"Foreign\", CNNModel),\n",
        "        (\"LSTM\", None, LSTMModel),\n",
        "        (\"CNN+LSTM\", \"KOSPI\", CNNLSTMModel),\n",
        "        (\"LSTM(Attn)\", \"Foreign\", LSTMAttentionModel)\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n[Start Evaluation] Target Period: {CONFIG['test_start_date']} ~ {CONFIG['test_end_date']}\")\n",
        "\n",
        "    rmse_results = []\n",
        "\n",
        "    for model_name, drop_group, ModelClass in scenarios:\n",
        "        print(f\"\\n>> Processing {model_name} (Drop: {drop_group})...\")\n",
        "\n",
        "        # 1. Prepare Data & Split\n",
        "        X_train, y_train, X_test, y_test_raw, test_dates, scaler_y, input_dim = \\\n",
        "            process_features_and_split(full_df, drop_group)\n",
        "\n",
        "        if len(X_test) == 0:\n",
        "            print(\"   [Error] No test data found. Check date range.\")\n",
        "            continue\n",
        "\n",
        "        # 2. Init Model\n",
        "        if model_name == \"CNN\":\n",
        "            model = ModelClass(input_dim, 1, 32, 5, CONFIG[\"seq_length\"])\n",
        "        elif model_name == \"CNN+LSTM\":\n",
        "            model = ModelClass(input_dim, 256, 1, 1, 32, 5)\n",
        "        else:\n",
        "            model = ModelClass(input_dim, 256, 1, 1)\n",
        "\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. Train\n",
        "        model = train_model(model, X_train, y_train, CONFIG)\n",
        "\n",
        "        # 4. Predict\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_tensor = torch.FloatTensor(X_test).to(CONFIG['device'])\n",
        "            pred_scaled = model(input_tensor).cpu().numpy()\n",
        "\n",
        "        # 5. Inverse Transform & RMSE Calc\n",
        "        pred_prices = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "        y_true_prices = y_test_raw.flatten()\n",
        "\n",
        "        # RMSE 계산 (scikit-learn의 mean_squared_error 사용 없이 직접 계산)\n",
        "        rmse = np.sqrt(np.mean((y_true_prices - pred_prices) ** 2))\n",
        "        rmse_results.append({\"Model\": model_name, \"RMSE\": rmse})\n",
        "        print(f\"   [Result] RMSE: {rmse:.4f}\")\n",
        "\n",
        "        # 6. Draw & Save Graph (Clean version with RMSE in title)\n",
        "        plot_comparison(model_name, drop_group, test_dates, y_true_prices, pred_prices, rmse)\n",
        "\n",
        "    print(\"\\n[RMSE Summary]\")\n",
        "    rmse_df = pd.DataFrame(rmse_results)\n",
        "    print(rmse_df)\n",
        "\n",
        "    print(\"\\nAll evaluation graphs generated.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TvF9FJQNAFo",
        "outputId": "c0824a1f-0275-40e1-9826-ad725d5e2ed1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n",
            "Loading Data...\n",
            "\n",
            "[Start Evaluation] Target Period: 2025-11-24 ~ 2025-11-28\n",
            "\n",
            ">> Processing CNN (Drop: Foreign)...\n",
            "   [Result] RMSE: 72.8049\n",
            "   [Graph Saved] Evaluation_CNN.png\n",
            "\n",
            ">> Processing LSTM (Drop: None)...\n",
            "   [Result] RMSE: 47.8446\n",
            "   [Graph Saved] Evaluation_LSTM.png\n",
            "\n",
            ">> Processing CNN+LSTM (Drop: KOSPI)...\n",
            "   [Result] RMSE: 48.5979\n",
            "   [Graph Saved] Evaluation_CNN_LSTM.png\n",
            "\n",
            ">> Processing LSTM(Attn) (Drop: Foreign)...\n",
            "   [Result] RMSE: 71.2455\n",
            "   [Graph Saved] Evaluation_LSTMAttn.png\n",
            "\n",
            "[RMSE Summary]\n",
            "        Model       RMSE\n",
            "0         CNN  72.804859\n",
            "1        LSTM  47.844604\n",
            "2    CNN+LSTM  48.597881\n",
            "3  LSTM(Attn)  71.245487\n",
            "\n",
            "All evaluation graphs generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 컬럼 수정본 11/28일부터 그래프 그려서 실패\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정 (코랩/영문 환경 호환)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    # 11월 28일까지 데이터를 꽉 채워서 학습\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "\n",
        "    # 예측 대상 (12월 1일 ~ 5일)\n",
        "    \"future_start_date\": \"2025-12-01\",\n",
        "    \"future_days\": 5,\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing Utils ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        # Target column must be kept for prediction (Autoregression)\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    # 1. Target (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input (X)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    # Last sequence for prediction (Last 5 days)\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "    last_sequence_x = scaled_x[-seq_len:]\n",
        "\n",
        "    # Prepare Training Data\n",
        "    X, y = [], []\n",
        "    # y must be future 5 steps\n",
        "    horizon = CONFIG[\"predict_horizon\"]\n",
        "\n",
        "    # Valid range for training\n",
        "    # Input: i ~ i+seq\n",
        "    # Target: i+seq ~ i+seq+horizon\n",
        "    valid_len = len(scaled_x) - seq_len - horizon + 1\n",
        "\n",
        "    for i in range(valid_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len : i + seq_len + horizon].flatten())\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y, scaler_y, last_sequence_x, len(input_df.columns), raw_y[-1][0]\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, X_train, y_train, config):\n",
        "    # Tensor conversion\n",
        "    X_t = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_t = torch.FloatTensor(y_train).to(config['device'])\n",
        "\n",
        "    dataset = TensorDataset(X_t, y_t)\n",
        "    loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        for X_b, y_b in loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "# --- 5. Individual Plotting Function ---\n",
        "def plot_and_save(model_name, drop_group, plot_dates, plot_values, last_price, last_date_str):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # 1. Start Point (Nov 28)\n",
        "    plt.plot(plot_dates[:1], plot_values[:1], marker='o', color='black', label=f'Actual ({last_date_str})')\n",
        "\n",
        "    # 2. Prediction Line (Nov 28 -> Dec 5)\n",
        "    plt.plot(plot_dates, plot_values, marker='o', linestyle='--', color='red', label='Prediction (Dec 1-5)', linewidth=2)\n",
        "\n",
        "    # [수정] 숫자 어노테이션(plt.text) 제거됨\n",
        "\n",
        "    # Styling\n",
        "    title_str = f\"Future Prediction: {model_name}\\n(Optimized Feature: Drop {drop_group if drop_group else 'None'})\"\n",
        "    plt.title(title_str, fontsize=14)\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.ylabel(\"KOSPI Index\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Save\n",
        "    safe_name = model_name.replace('+', '_').replace('(', '').replace(')', '')\n",
        "    filename = f\"Future_Prediction_{safe_name}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"   [Graph Saved] {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Last Actual Price (Anchor)\n",
        "    last_date = full_df.index[-1] # 2025-11-28\n",
        "    last_price = full_df[\"KOSPI_Close\"].iloc[-1]\n",
        "\n",
        "    print(f\"Anchor Date: {last_date.date()} | Price: {last_price:.2f}\")\n",
        "\n",
        "    # Future Dates (Dec 1 ~ Dec 5, Business Days)\n",
        "    future_dates = pd.date_range(start=CONFIG[\"future_start_date\"], periods=CONFIG[\"future_days\"], freq='B')\n",
        "\n",
        "    # Plotting X-Axis: [Nov 28, Dec 1, Dec 2, ..., Dec 5]\n",
        "    plot_dates = [last_date] + list(future_dates)\n",
        "\n",
        "    # Optimized Scenarios\n",
        "    scenarios = [\n",
        "        (\"CNN\", \"Foreign\", CNNModel),\n",
        "        (\"LSTM\", None, LSTMModel),\n",
        "        (\"CNN+LSTM\", \"KOSPI\", CNNLSTMModel),\n",
        "        (\"LSTM(Attn)\", \"Foreign\", LSTMAttentionModel)\n",
        "    ]\n",
        "\n",
        "    print(\"\\n[Start Training & Generating Separate Graphs]\")\n",
        "\n",
        "    for model_name, drop_group, ModelClass in scenarios:\n",
        "        print(f\"\\n>> Processing {model_name} (Drop: {drop_group})...\")\n",
        "\n",
        "        # 1. Prepare Data (Apply Drop)\n",
        "        X, y, scaler_y, last_seq_x, input_dim, _ = process_features(full_df, drop_group)\n",
        "\n",
        "        # 2. Init Model\n",
        "        if model_name == \"CNN\":\n",
        "            model = ModelClass(input_dim, 5, 32, 5, CONFIG[\"seq_length\"])\n",
        "        elif model_name == \"CNN+LSTM\":\n",
        "            model = ModelClass(input_dim, 256, 1, 5, 32, 5)\n",
        "        else:\n",
        "            model = ModelClass(input_dim, 256, 1, 5)\n",
        "\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. Train\n",
        "        model = train_model(model, X, y, CONFIG)\n",
        "\n",
        "        # 4. Predict\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_tensor = torch.FloatTensor(last_seq_x).unsqueeze(0).to(CONFIG['device'])\n",
        "            pred_scaled = model(input_tensor).cpu().numpy() # (1, 5)\n",
        "\n",
        "        # 5. Inverse Transform (Reshape logic required for scaler)\n",
        "        # Scaler fit on (N, 1). Output is (1, 5).\n",
        "        pred_prices = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # 6. Prepare Plot Data (Connect Nov 28 -> Dec 1)\n",
        "        plot_values = [last_price] + list(pred_prices)\n",
        "\n",
        "        print(f\"   Pred (Dec 1-5): {[int(p) for p in pred_prices]}\")\n",
        "\n",
        "        # 7. Draw & Save Individual Graph\n",
        "        plot_and_save(model_name, drop_group, plot_dates, plot_values, last_price, str(last_date.date()))\n",
        "\n",
        "    print(\"\\nAll tasks completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IVrv_4EJXtn",
        "outputId": "19c60e31-8f6e-4a80-9f7a-3b9402deb7b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n",
            "Loading Data...\n",
            "Anchor Date: 2025-11-28 | Price: 3926.59\n",
            "\n",
            "[Start Training & Generating Separate Graphs]\n",
            "\n",
            ">> Processing CNN (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [3965, 3901, 3976, 3924, 3946]\n",
            "   [Graph Saved] Future_Prediction_CNN.png\n",
            "\n",
            ">> Processing LSTM (Drop: None)...\n",
            "   Pred (Dec 1-5): [3927, 3930, 3932, 3945, 3939]\n",
            "   [Graph Saved] Future_Prediction_LSTM.png\n",
            "\n",
            ">> Processing CNN+LSTM (Drop: KOSPI)...\n",
            "   Pred (Dec 1-5): [4027, 4021, 4022, 4041, 4058]\n",
            "   [Graph Saved] Future_Prediction_CNN_LSTM.png\n",
            "\n",
            ">> Processing LSTM(Attn) (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [3955, 3937, 3960, 3962, 3972]\n",
            "   [Graph Saved] Future_Prediction_LSTMAttn.png\n",
            "\n",
            "All tasks completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정 (코랩/영문 환경 호환)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    # 11월 28일까지 데이터를 모두 학습에 사용\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "\n",
        "    # 예측 대상 (12월 1일 ~ 5일)\n",
        "    \"future_start_date\": \"2025-12-01\",\n",
        "    \"future_days\": 5,\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,     # 5일치 예측\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 5,         # [수정] 출력 차원 5 (5일치 값)\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 100,            # 미래 예측이므로 충분히 학습\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 10,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing Utils ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        # 타겟 컬럼은 y데이터 생성을 위해 필요하므로 X에서만 제거하기 위해 리스트 조정\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    # 1. Target (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input (X)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    # 미래 예측을 위한 마지막 입력 시퀀스 (11/28 기준 과거 5일)\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "    last_sequence_x = scaled_x[-seq_len:]\n",
        "\n",
        "    # 학습 데이터 생성 (Many-to-Many: 5일 입력 -> 5일 출력)\n",
        "    X, y = [], []\n",
        "    horizon = CONFIG[\"predict_horizon\"]\n",
        "\n",
        "    valid_len = len(scaled_x) - seq_len - horizon + 1\n",
        "\n",
        "    for i in range(valid_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        # 타겟은 미래 5일치\n",
        "        y.append(scaled_y[i + seq_len : i + seq_len + horizon].flatten())\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y, scaler_y, last_sequence_x, len(input_df.columns), raw_y[-1][0]\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, X_train, y_train, config):\n",
        "    # Tensor conversion\n",
        "    X_t = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_t = torch.FloatTensor(y_train).to(config['device'])\n",
        "\n",
        "    dataset = TensorDataset(X_t, y_t)\n",
        "    loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        for X_b, y_b in loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "# --- 5. Individual Plotting Function ---\n",
        "def plot_and_save(model_name, drop_group, plot_dates, plot_values):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # 12월 1일 ~ 12월 5일 예측 그래프만 그림 (이전 날짜와 연결 X)\n",
        "    plt.plot(plot_dates, plot_values, marker='o', linestyle='--', color='red', linewidth=2, label='Prediction (Dec 1-5)')\n",
        "\n",
        "    # 숫자 어노테이션 추가\n",
        "    for i, (date, val) in enumerate(zip(plot_dates, plot_values)):\n",
        "        plt.text(date, val, f\"{val:.0f}\", ha='center', va='bottom', color='red', fontsize=9, fontweight='bold')\n",
        "\n",
        "    # Styling\n",
        "    title_str = f\"Future Prediction: {model_name}\\n(Optimized: Drop {drop_group if drop_group else 'None'})\"\n",
        "    plt.title(title_str, fontsize=14)\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.ylabel(\"KOSPI Index\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Save\n",
        "    safe_name = model_name.replace('+', '_').replace('(', '').replace(')', '')\n",
        "    filename = f\"Future_Pred_Dec1_5_{safe_name}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"   [Graph Saved] {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Future Dates (Dec 1 ~ Dec 5, Business Days)\n",
        "    future_dates = pd.date_range(start=CONFIG[\"future_start_date\"], periods=CONFIG[\"future_days\"], freq='B')\n",
        "\n",
        "    # Scenarios (Model, Drop Group, Class)\n",
        "    scenarios = [\n",
        "        (\"CNN\", \"Foreign\", CNNModel),\n",
        "        (\"LSTM\", None, LSTMModel),\n",
        "        (\"CNN+LSTM\", \"KOSPI\", CNNLSTMModel),\n",
        "        (\"LSTM(Attn)\", \"Foreign\", LSTMAttentionModel)\n",
        "    ]\n",
        "\n",
        "    print(\"\\n[Start Training & Generating Separate Graphs (Dec 1 ~ 5 Only)]\")\n",
        "\n",
        "    for model_name, drop_group, ModelClass in scenarios:\n",
        "        print(f\"\\n>> Processing {model_name} (Drop: {drop_group})...\")\n",
        "\n",
        "        # 1. Prepare Data\n",
        "        X, y, scaler_y, last_seq_x, input_dim, _ = process_features(full_df, drop_group)\n",
        "\n",
        "        # 2. Init Model (Output size = 5)\n",
        "        if model_name == \"CNN\":\n",
        "            model = ModelClass(input_dim, CONFIG[\"predict_horizon\"], 32, 5, CONFIG[\"seq_length\"])\n",
        "        elif model_name == \"CNN+LSTM\":\n",
        "            model = ModelClass(input_dim, 256, 1, CONFIG[\"predict_horizon\"], 32, 5)\n",
        "        else:\n",
        "            model = ModelClass(input_dim, 256, 1, CONFIG[\"predict_horizon\"])\n",
        "\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. Train\n",
        "        model = train_model(model, X, y, CONFIG)\n",
        "\n",
        "        # 4. Predict Future (5 days)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_tensor = torch.FloatTensor(last_seq_x).unsqueeze(0).to(CONFIG['device'])\n",
        "            pred_scaled = model(input_tensor).cpu().numpy() # Shape: (1, 5)\n",
        "\n",
        "        # 5. Inverse Transform\n",
        "        pred_prices = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # 6. Prepare Plot Data (ONLY Dec 1 ~ Dec 5)\n",
        "        plot_dates = future_dates\n",
        "        plot_values = pred_prices\n",
        "\n",
        "        print(f\"   Pred (Dec 1-5): {[int(p) for p in pred_prices]}\")\n",
        "\n",
        "        # 7. Draw & Save\n",
        "        plot_and_save(model_name, drop_group, plot_dates, plot_values)\n",
        "\n",
        "    print(\"\\nAll tasks completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8QrVacsPBxg",
        "outputId": "77a9fa7c-d72e-4972-c90f-ac7a1d621799"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n",
            "Loading Data...\n",
            "\n",
            "[Start Training & Generating Separate Graphs (Dec 1 ~ 5 Only)]\n",
            "\n",
            ">> Processing CNN (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [3974, 3932, 3957, 3968, 3926]\n",
            "   [Graph Saved] Future_Pred_Dec1_5_CNN.png\n",
            "\n",
            ">> Processing LSTM (Drop: None)...\n",
            "   Pred (Dec 1-5): [3962, 3962, 3947, 3968, 3969]\n",
            "   [Graph Saved] Future_Pred_Dec1_5_LSTM.png\n",
            "\n",
            ">> Processing CNN+LSTM (Drop: KOSPI)...\n",
            "   Pred (Dec 1-5): [4050, 4041, 4017, 4017, 4035]\n",
            "   [Graph Saved] Future_Pred_Dec1_5_CNN_LSTM.png\n",
            "\n",
            ">> Processing LSTM(Attn) (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [4005, 4008, 4011, 4012, 4027]\n",
            "   [Graph Saved] Future_Pred_Dec1_5_LSTMAttn.png\n",
            "\n",
            "All tasks completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 강제 지정\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\",\n",
        "    \"test_start_date\": \"2025-11-24\",\n",
        "    \"test_end_date\": \"2025-11-28\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups Definition ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        # Target column must not be dropped from df for y generation, but dropped from X if in group\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col) # Keep target in input for now or handle separately?\n",
        "             # Logic: If KOSPI group is dropped, usually Close is part of it.\n",
        "             # If we want to predict Close using other features, we remove Close from X.\n",
        "             # But for time-series, usually past Close is needed.\n",
        "             # Here we assume 'drop_group' means removing EXTRA features in that group.\n",
        "             # If KOSPI group is removed, we might keep Close but remove Open, High, Low etc.\n",
        "             # Let's strictly follow: Drop all columns in the list.\n",
        "             # If target is in list, we must keep it in y, but can drop in X.\n",
        "\n",
        "    # 1. Target Data (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input Features (X)\n",
        "    # If drop_group contains target_col, it will be dropped from X.\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    # Ensure target is not dropped from input if it's the only feature?\n",
        "    # Usually we want past target values. If KOSPI group is dropped, Close is dropped from X.\n",
        "    # This means predicting Close using ONLY other macro features. This is a valid experiment.\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "    train_mask = dates <= train_end\n",
        "\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "    test_end = pd.Timestamp(config[\"test_end_date\"])\n",
        "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
        "    y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
        "    X_test_t = torch.FloatTensor(X_test).to(device)\n",
        "    y_test_t = torch.FloatTensor(y_test).unsqueeze(1).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_test_t, y_test_t, test_dates)\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training & Plotting ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            if torch.isnan(loss): return model\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "def run_experiment(model_name, drop_group, full_df):\n",
        "    print(f\"\\n>> Running {model_name} (Drop: {drop_group if drop_group else 'None'})...\")\n",
        "\n",
        "    # Data Prep\n",
        "    X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group)\n",
        "    train_data, test_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # Model Init\n",
        "    if model_name == \"CNN\":\n",
        "        model = CNNModel(input_dim, 1, 32, 5, CONFIG[\"seq_length\"])\n",
        "    elif model_name == \"LSTM\":\n",
        "        model = LSTMModel(input_dim, 256, 1, 1)\n",
        "    elif model_name == \"CNN+LSTM\":\n",
        "        model = CNNLSTMModel(input_dim, 256, 1, 1, 32, 5)\n",
        "    elif model_name == \"LSTM(Attn)\":\n",
        "        model = LSTMAttentionModel(input_dim, 256, 1, 1)\n",
        "\n",
        "    model.to(CONFIG['device'])\n",
        "    train_model(model, train_loader, CONFIG)\n",
        "\n",
        "    # Predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_scaled = model(test_data[0]).cpu().numpy()\n",
        "        y_true_scaled = test_data[1].cpu().numpy()\n",
        "\n",
        "    pred_inv = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "    y_true_inv = scaler_y.inverse_transform(y_true_scaled).flatten()\n",
        "    test_dates = test_data[2]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(test_dates, y_true_inv, label='Actual', color='blue', marker='o')\n",
        "    plt.plot(test_dates, pred_inv, label=f'Predicted ({model_name})', color='red', linestyle='--', marker='x')\n",
        "\n",
        "    title_str = f\"{model_name} Prediction (Optimized Feature: Drop {drop_group if drop_group else 'None'})\"\n",
        "    plt.title(title_str)\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"KOSPI Index\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Annotate\n",
        "    for i in range(len(test_dates)):\n",
        "        plt.text(test_dates[i], y_true_inv[i], f\"{y_true_inv[i]:.0f}\", ha='center', va='bottom', color='blue', fontsize=8)\n",
        "        plt.text(test_dates[i], pred_inv[i], f\"{pred_inv[i]:.0f}\", ha='center', va='top', color='red', fontsize=8)\n",
        "\n",
        "    filename = f\"Optimized_{model_name.replace('+', '_').replace('(', '').replace(')', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 5. Main ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Define Optimized Scenarios\n",
        "    # (Model Name, Drop Group Name)\n",
        "    experiments = [\n",
        "        (\"CNN\", \"Foreign\"),          # CNN: Drop Foreign\n",
        "        (\"LSTM\", None),              # LSTM: All Features (Drop None)\n",
        "        (\"CNN+LSTM\", \"KOSPI\"),       # CNN+LSTM: Drop KOSPI\n",
        "        (\"LSTM(Attn)\", \"Foreign\")    # LSTM(Attn): Drop Foreign\n",
        "    ]\n",
        "\n",
        "    for model_name, drop_group in experiments:\n",
        "        run_experiment(model_name, drop_group, full_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FssKmSlt8sWm",
        "outputId": "5f3c7bf0-7bd4-4392-e94d-cb3b7a24a471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Loading Data...\n",
            "\n",
            ">> Running CNN (Drop: Foreign)...\n",
            "Graph Saved: Optimized_CNN.png\n",
            "\n",
            ">> Running LSTM (Drop: None)...\n",
            "Graph Saved: Optimized_LSTM.png\n",
            "\n",
            ">> Running CNN+LSTM (Drop: KOSPI)...\n",
            "Graph Saved: Optimized_CNN_LSTM.png\n",
            "\n",
            ">> Running LSTM(Attn) (Drop: Foreign)...\n",
            "Graph Saved: Optimized_LSTMAttn.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11/24~11/28예측"
      ],
      "metadata": {
        "id": "f9ZRHrp9gHl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정: 코랩 기본 폰트(DejaVu Sans) 강제 지정\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "    \"train_cutoff_date\": \"2025-11-21\",\n",
        "    \"test_start_date\": \"2025-11-24\",\n",
        "    \"test_end_date\": \"2025-11-28\",\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups Definition ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings_to_try = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings_to_try:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    # 1. Target Data (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input Features (X)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    dates = df.index[seq_len:]\n",
        "\n",
        "    return X, y, dates, scaler_y, len(input_df.columns)\n",
        "\n",
        "def split_data(X, y, dates, config):\n",
        "    train_end = pd.Timestamp(config[\"train_cutoff_date\"])\n",
        "    train_mask = dates <= train_end\n",
        "\n",
        "    test_start = pd.Timestamp(config[\"test_start_date\"])\n",
        "    test_end = pd.Timestamp(config[\"test_end_date\"])\n",
        "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
        "\n",
        "    X_train, y_train = X[train_mask], y[train_mask]\n",
        "    X_test, y_test = X[test_mask], y[test_mask]\n",
        "    test_dates = dates[test_mask]\n",
        "\n",
        "    device = config['device']\n",
        "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
        "    y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
        "    X_test_t = torch.FloatTensor(X_test).to(device)\n",
        "    y_test_t = torch.FloatTensor(y_test).unsqueeze(1).to(device)\n",
        "\n",
        "    return (X_train_t, y_train_t), (X_test_t, y_test_t, test_dates)\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training & Plotting ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        epoch_loss = 0\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            if torch.isnan(loss): return model\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= config[\"patience\"]: break\n",
        "    return model\n",
        "\n",
        "def run_experiment(model_name, drop_group, full_df):\n",
        "    print(f\"\\n>> Running {model_name} (Drop: {drop_group if drop_group else 'None'})...\")\n",
        "\n",
        "    # Data Prep\n",
        "    X, y, dates, scaler_y, input_dim = process_features(full_df, drop_group)\n",
        "    train_data, test_data = split_data(X, y, dates, CONFIG)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(*train_data), batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # Model Init\n",
        "    if model_name == \"CNN\":\n",
        "        model = CNNModel(input_dim, 1, 32, 5, CONFIG[\"seq_length\"])\n",
        "    elif model_name == \"LSTM\":\n",
        "        model = LSTMModel(input_dim, 256, 1, 1)\n",
        "    elif model_name == \"CNN+LSTM\":\n",
        "        model = CNNLSTMModel(input_dim, 256, 1, 1, 32, 5)\n",
        "    elif model_name == \"LSTM(Attn)\":\n",
        "        model = LSTMAttentionModel(input_dim, 256, 1, 1)\n",
        "\n",
        "    model.to(CONFIG['device'])\n",
        "    train_model(model, train_loader, CONFIG)\n",
        "\n",
        "    # Predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_scaled = model(test_data[0]).cpu().numpy()\n",
        "        y_true_scaled = test_data[1].cpu().numpy()\n",
        "\n",
        "    pred_inv = scaler_y.inverse_transform(pred_scaled).flatten()\n",
        "    y_true_inv = scaler_y.inverse_transform(y_true_scaled).flatten()\n",
        "    test_dates = test_data[2]\n",
        "\n",
        "    # [수정] 5일치(11/24~11/28) RMSE 계산 및 출력\n",
        "    rmse_5days = np.sqrt(mean_squared_error(y_true_inv, pred_inv))\n",
        "    print(f\"   [{model_name}] 5-day RMSE (11/24-11/28): {rmse_5days:.4f}\")\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(test_dates, y_true_inv, label='Actual', color='blue', marker='o')\n",
        "    plt.plot(test_dates, pred_inv, label=f'Predicted ({model_name})', color='red', linestyle='--', marker='x')\n",
        "\n",
        "    # [수정] 그래프 제목에 RMSE 추가\n",
        "    title_str = f\"{model_name} (Drop: {drop_group if drop_group else 'None'}) - RMSE: {rmse_5days:.2f}\"\n",
        "    plt.title(title_str)\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"KOSPI Index\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Annotate\n",
        "    for i in range(len(test_dates)):\n",
        "        plt.text(test_dates[i], y_true_inv[i], f\"{y_true_inv[i]:.0f}\", ha='center', va='bottom', color='blue', fontsize=8)\n",
        "        plt.text(test_dates[i], pred_inv[i], f\"{pred_inv[i]:.0f}\", ha='center', va='top', color='red', fontsize=8)\n",
        "\n",
        "    filename = f\"Optimized_{model_name.replace('+', '_').replace('(', '').replace(')', '')}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Graph Saved: {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 5. Main ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Define Optimized Scenarios\n",
        "    # (Model Name, Drop Group Name)\n",
        "    experiments = [\n",
        "        (\"CNN\", \"Foreign\"),          # CNN: Drop Foreign\n",
        "        (\"LSTM\", None),              # LSTM: All Features (Drop None)\n",
        "        (\"CNN+LSTM\", \"KOSPI\"),       # CNN+LSTM: Drop KOSPI\n",
        "        (\"LSTM(Attn)\", \"Foreign\")    # LSTM(Attn): Drop Foreign\n",
        "    ]\n",
        "\n",
        "    for model_name, drop_group in experiments:\n",
        "        run_experiment(model_name, drop_group, full_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU-3-Ovz-GQ6",
        "outputId": "9b9fd435-1eed-4771-ebba-e5b6995a1f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Loading Data...\n",
            "\n",
            ">> Running CNN (Drop: Foreign)...\n",
            "   [CNN] 5-day RMSE (11/24-11/28): 48.6067\n",
            "Graph Saved: Optimized_CNN.png\n",
            "\n",
            ">> Running LSTM (Drop: None)...\n",
            "   [LSTM] 5-day RMSE (11/24-11/28): 47.7424\n",
            "Graph Saved: Optimized_LSTM.png\n",
            "\n",
            ">> Running CNN+LSTM (Drop: KOSPI)...\n",
            "   [CNN+LSTM] 5-day RMSE (11/24-11/28): 50.9882\n",
            "Graph Saved: Optimized_CNN_LSTM.png\n",
            "\n",
            ">> Running LSTM(Attn) (Drop: Foreign)...\n",
            "   [LSTM(Attn)] 5-day RMSE (11/24-11/28): 65.5131\n",
            "Graph Saved: Optimized_LSTMAttn.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    # 학습 데이터 기간: 시작일부터 11월 28일까지 꽉 채워서 학습\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "\n",
        "    # 예측 대상 기간\n",
        "    \"future_start_date\": \"2025-12-01\",\n",
        "    \"future_days\": 5,\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing Utils ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    # Encoding check\n",
        "    encodings = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Filter Date Range\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "\n",
        "    # Fill NA\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        # X 입력에서 타겟 컬럼이 제거되는 경우 처리 (y는 유지)\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    # 1. Target Data (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input Features (X)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    X, y = [], []\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "\n",
        "    # Train sequences\n",
        "    for i in range(len(scaled_x) - seq_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len, 0]) # Not strictly used here, but needed for loader\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # [중요] 미래 예측을 위한 마지막 입력 시퀀스 추출 (11/28 기준 과거 5일)\n",
        "    last_sequence_x = scaled_x[-seq_len:]\n",
        "\n",
        "    return X, y, scaler_y, last_sequence_x, len(input_df.columns), raw_y[-1][0]\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, train_loader, config):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        for X_b, y_b in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            # 여기서는 학습용이므로 shape 맞추기 (단일값 예측 학습 -> 다중 예측으로 확장 시 구조 변경 필요하지만\n",
        "            # 현재 코드 구조상 모델이 output_size=5를 내뱉도록 설정되어 있음)\n",
        "            # y_b는 (Batch, 1)인데 모델 출력은 (Batch, 5) 이므로,\n",
        "            # 학습 시에는 다음 1 step만 맞추게 할지, 아니면 미래 5일을 타겟으로 할지 결정 필요.\n",
        "            # *기존 로직 유지*: 모델은 5일치를 뱉지만, 학습 데이터 y는 현재 1일치만 있음.\n",
        "            # 이 코드는 \"학습된 모델로 미래 예측\"이므로, y데이터 구성을 (Batch, 5)로 바꿉니다.\n",
        "            pass\n",
        "\n",
        "    # [수정] 학습 루프 재구성: 미래 5일 예측 학습을 위해 DataLoader 재생성 필요\n",
        "    # 그러나 시간 관계상, 여기서는 간략히 '다음 날 예측' 모델을 학습시키고,\n",
        "    # Inference 시 5일치를 한 번에 출력하는 구조로 모델이 초기화되었음(output_size=5).\n",
        "    # 따라서 y데이터도 미래 5일치를 담도록 process_features에서 수정이 필요하나,\n",
        "    # 여기서는 간단히 y_b를 5번 반복(fake target)하거나, 1일 예측 모델을 반복 사용하는 것이 아니라\n",
        "    # 모델 아키텍처가 (seq -> 5)로 되어 있으므로 y도 (seq -> 5)로 맞춰야 함.\n",
        "\n",
        "    # => process_features 함수를 수정하지 않고, 학습 루프에서 y 타겟을 미래 5일치로 다시 매핑하는 것은 복잡함.\n",
        "    # => 해결책: 모델 출력을 1로 바꾸고 5번 반복 예측(Recursive) 하는 방식 대신,\n",
        "    #    사용자 요청에 따라 \"모델이 5일치를 예측\" 하도록 y데이터를 재구성하는 로직을 내부에 구현함.\n",
        "    pass\n",
        "\n",
        "# [재정의] 올바른 학습을 위한 함수\n",
        "def train_model_correctly(model, X_train, y_train_raw_scaled, config):\n",
        "    # y_train_raw_scaled: 전체 타겟 데이터 (scaled)\n",
        "    # X_train: (N, Seq, Feat)\n",
        "\n",
        "    # 미래 5일치 타겟 생성\n",
        "    y_multi_step = []\n",
        "    horizon = config[\"predict_horizon\"]\n",
        "    seq_len = config[\"seq_length\"]\n",
        "\n",
        "    # X_train의 각 샘플에 대해 미래 5일치 y를 매핑\n",
        "    # X[i]는 data[i : i+seq]\n",
        "    # y[i]는 data[i+seq : i+seq+horizon] 이어야 함.\n",
        "\n",
        "    # 데이터 길이 재확인\n",
        "    valid_len = len(X_train) - horizon + 1\n",
        "    if valid_len <= 0: raise ValueError(\"Data too short for horizon\")\n",
        "\n",
        "    X_final = X_train[:valid_len]\n",
        "\n",
        "    # 전체 scaled y에서 추출\n",
        "    # X_train이 생성될 때 index i는 원본 데이터의 i 지점.\n",
        "    # 타겟은 i + seq_len 부터 5개\n",
        "    # scaled_y는 전체 길이.\n",
        "\n",
        "    # X_train 생성 로직: range(len(scaled_x) - seq_len)\n",
        "    # i=0 -> X=0~5, y_target should be 5~10\n",
        "\n",
        "    # Re-generate y for multi-step\n",
        "    y_multi = []\n",
        "    # y_train_raw_scaled shape: (Total, 1)\n",
        "    total_len = len(y_train_raw_scaled)\n",
        "\n",
        "    for i in range(valid_len):\n",
        "        start_idx = i + seq_len\n",
        "        end_idx = start_idx + horizon\n",
        "        if end_idx > total_len: break\n",
        "        y_multi.append(y_train_raw_scaled[start_idx : end_idx].flatten())\n",
        "\n",
        "    y_multi = np.array(y_multi)\n",
        "    # X 길이 맞춤\n",
        "    X_final = X_final[:len(y_multi)]\n",
        "\n",
        "    # Tensor\n",
        "    X_t = torch.FloatTensor(X_final).to(config['device'])\n",
        "    y_t = torch.FloatTensor(y_multi).to(config['device'])\n",
        "\n",
        "    dataset = TensorDataset(X_t, y_t)\n",
        "    loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        for X_b, y_b in loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- 5. Main Prediction Logic ---\n",
        "def run_prediction_pipeline():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "    print(f\"Data Loaded: {full_df.index.min().date()} ~ {full_df.index.max().date()}\")\n",
        "\n",
        "    # Scenarios based on Ablation Study\n",
        "    scenarios = [\n",
        "        (\"CNN\", \"Foreign\", CNNModel),\n",
        "        (\"LSTM\", None, LSTMModel),\n",
        "        (\"CNN+LSTM\", \"KOSPI\", CNNLSTMModel),\n",
        "        (\"LSTM(Attn)\", \"Foreign\", LSTMAttentionModel)\n",
        "    ]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 1. Plot Actual Context (Nov 1 ~ Nov 28)\n",
        "    context_df = full_df.loc[\"2025-11-01\":]\n",
        "    plt.plot(context_df.index, context_df[\"KOSPI_Close\"], label=\"Actual (History)\", color='black', linewidth=2)\n",
        "\n",
        "    # Last Actual Price (Anchor point for plotting)\n",
        "    last_date = full_df.index[-1] # 2025-11-28\n",
        "    last_price = full_df[\"KOSPI_Close\"].iloc[-1]\n",
        "\n",
        "    print(f\"\\nLast Actual Data: {last_date.date()} | Price: {last_price:.2f}\")\n",
        "\n",
        "    # Future Dates (Dec 1 ~ Dec 5, Business Days)\n",
        "    future_dates = pd.date_range(start=CONFIG[\"future_start_date\"], periods=CONFIG[\"future_days\"], freq='B')\n",
        "\n",
        "    # Plotting Dates: [Nov 28, Dec 1, Dec 2, ..., Dec 5]\n",
        "    plot_dates = [last_date] + list(future_dates)\n",
        "\n",
        "    colors = {'CNN': 'green', 'LSTM': 'blue', 'CNN+LSTM': 'red', 'LSTM(Attn)': 'purple'}\n",
        "\n",
        "    print(\"\\n[Start Training & Prediction]\")\n",
        "\n",
        "    for model_name, drop_group, ModelClass in scenarios:\n",
        "        print(f\">> Processing {model_name} (Drop: {drop_group})...\")\n",
        "\n",
        "        # Data Prep\n",
        "        X, _, scaler_y, last_seq_x, input_dim, _ = process_features(full_df, drop_group)\n",
        "\n",
        "        # Need raw scaled y for multi-step target generation\n",
        "        # Recalculate full scaled y\n",
        "        target_col = \"KOSPI_Close\"\n",
        "        raw_y = full_df[[target_col]].values\n",
        "        scaler_y_full = MinMaxScaler()\n",
        "        scaled_y_full = scaler_y_full.fit_transform(raw_y)\n",
        "\n",
        "        # Initialize Model\n",
        "        if model_name == \"CNN\":\n",
        "            model = ModelClass(input_dim, 5, 32, 5, CONFIG[\"seq_length\"]) # output=5\n",
        "        elif model_name == \"CNN+LSTM\":\n",
        "            model = ModelClass(input_dim, 256, 1, 5, 32, 5)\n",
        "        else:\n",
        "            model = ModelClass(input_dim, 256, 1, 5)\n",
        "\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # Train (Multi-step output)\n",
        "        model = train_model_correctly(model, X, scaled_y_full, CONFIG)\n",
        "\n",
        "        # Predict Future\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Input: (1, Seq, Feat)\n",
        "            input_tensor = torch.FloatTensor(last_seq_x).unsqueeze(0).to(CONFIG['device'])\n",
        "            pred_scaled = model(input_tensor).cpu().numpy() # (1, 5)\n",
        "\n",
        "        # Inverse Transform\n",
        "        # Output is (1, 5), inverse needs (N, 1) usually or fit shape.\n",
        "        # Scaler was fit on (N, 1). So reshape pred to (5, 1) then inverse then flatten\n",
        "        pred_prices = scaler_y_full.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Create Plot Data (Connect from Nov 28)\n",
        "        plot_values = [last_price] + list(pred_prices)\n",
        "\n",
        "        # Print Result\n",
        "        print(f\"   Pred (Dec 1-5): {[int(p) for p in pred_prices]}\")\n",
        "\n",
        "        # Plot\n",
        "        plt.plot(plot_dates, plot_values, label=f'{model_name}', color=colors[model_name], marker='o', linestyle='--')\n",
        "\n",
        "    # Graph Styling\n",
        "    plt.title(\"Future KOSPI Prediction (2025-12-01 ~ 2025-12-05)\", fontsize=14)\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"KOSPI Index\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Save\n",
        "    save_path = \"Future_Prediction_Dec1_Dec5.png\"\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    print(f\"\\n[Done] Prediction graph saved to '{save_path}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_prediction_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "Mz5K5QQi_ebn",
        "outputId": "7339cb50-4fdf-45e9-89ac-9ae93568033b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Loading Data...\n",
            "Data Loaded: 2013-08-06 ~ 2025-11-28\n",
            "\n",
            "Last Actual Data: 2025-11-28 | Price: 3926.59\n",
            "\n",
            "[Start Training & Prediction]\n",
            ">> Processing CNN (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [4012, 4015, 3941, 3978, 4008]\n",
            ">> Processing LSTM (Drop: None)...\n",
            "   Pred (Dec 1-5): [3953, 3953, 3959, 3958, 3976]\n",
            ">> Processing CNN+LSTM (Drop: KOSPI)...\n",
            "   Pred (Dec 1-5): [3924, 3926, 3939, 3944, 3952]\n",
            ">> Processing LSTM(Attn) (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [3964, 3976, 3975, 3973, 3969]\n",
            "\n",
            "[Done] Prediction graph saved to 'Future_Prediction_Dec1_Dec5.png'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##12월 데이터 예측"
      ],
      "metadata": {
        "id": "82LAUZsBf47M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 폰트 설정 (코랩/영문 환경 호환)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "CONFIG = {\n",
        "    \"data_file\": \"KOSPI_dataset_final.csv\",\n",
        "    # 11월 28일까지 데이터를 꽉 채워서 학습\n",
        "    \"data_start\": \"2013-08-06\",\n",
        "    \"data_end\": \"2025-11-28\",\n",
        "\n",
        "    # 예측 대상 (12월 1일 ~ 5일)\n",
        "    \"future_start_date\": \"2025-12-01\",\n",
        "    \"future_days\": 5,\n",
        "\n",
        "    \"seq_length\": 5,\n",
        "    \"predict_horizon\": 5,\n",
        "\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 1,\n",
        "    \"num_classes\": 1,\n",
        "\n",
        "    \"cnn_num_layers\": 1,\n",
        "    \"num_filters\": 32,\n",
        "    \"kernel_size\": 5,\n",
        "\n",
        "    \"batch_size\": 256,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"patience\": 5,\n",
        "\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "# --- Feature Groups ---\n",
        "FEATURE_GROUPS = {\n",
        "    \"KOSPI\": ['KOSPI_Close', 'KOSPI_Open', 'KOSPI_High', 'KOSPI_Low', 'KOSPI_Volume', 'KOSPI_Amount', 'KOSPI_Change', 'KOSPI_Fluctuation', 'KOSPI_UpDown'],\n",
        "    \"NASDAQ\": ['NAS_Open', 'NAS_High', 'NAS_Low', 'NAS_Close', 'NAS_Volume', 'NAS_Change'],\n",
        "    \"VKOSPI\": ['VKOSPI_Close', 'VKOSPI_Change'],\n",
        "    \"Rate_FX\": ['USD_KRW', 'EUR_KRW', 'Rate'],\n",
        "    \"Foreign\": ['Foreign_MarketCap_Ratio', 'Foreign_MarketCap', 'Foreign_Rate'],\n",
        "    \"Future\": ['Future_Close', 'Future_Change'],\n",
        "    \"Oil\": ['WTI_Close', 'WTI_Change']\n",
        "}\n",
        "\n",
        "print(f\"Using Device: {CONFIG['device']}\")\n",
        "\n",
        "# --- 2. Data Processing Utils ---\n",
        "def load_data(config):\n",
        "    if not os.path.exists(config[\"data_file\"]):\n",
        "        raise FileNotFoundError(f\"File not found: {config['data_file']}\")\n",
        "\n",
        "    encodings = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']\n",
        "    df = None\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep='\\t', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "            temp_df = pd.read_csv(config[\"data_file\"], sep=',', index_col=\"Date\", parse_dates=True, encoding=enc)\n",
        "            if len(temp_df.columns) > 1: df = temp_df; break\n",
        "        except: continue\n",
        "\n",
        "    if df is None: raise ValueError(\"Failed to read file.\")\n",
        "\n",
        "    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df.loc[config[\"data_start\"]:config[\"data_end\"]]\n",
        "    df = df.ffill().bfill()\n",
        "    df.dropna(inplace=True)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def process_features(df, drop_group_name=None):\n",
        "    target_col = \"KOSPI_Close\"\n",
        "    available_cols = df.columns.tolist()\n",
        "\n",
        "    cols_to_drop = []\n",
        "    if drop_group_name and drop_group_name in FEATURE_GROUPS:\n",
        "        cols_to_drop = FEATURE_GROUPS[drop_group_name]\n",
        "        cols_to_drop = [c for c in cols_to_drop if c in available_cols]\n",
        "        # Target column must be kept for prediction (Autoregression)\n",
        "        if target_col in cols_to_drop:\n",
        "             cols_to_drop.remove(target_col)\n",
        "\n",
        "    # 1. Target (y)\n",
        "    raw_y = df[[target_col]].values\n",
        "\n",
        "    # 2. Input (X)\n",
        "    input_df = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_x = scaler_x.fit_transform(input_df)\n",
        "    scaled_y = scaler_y.fit_transform(raw_y)\n",
        "\n",
        "    # Last sequence for prediction (Last 5 days)\n",
        "    seq_len = CONFIG[\"seq_length\"]\n",
        "    last_sequence_x = scaled_x[-seq_len:]\n",
        "\n",
        "    # Prepare Training Data\n",
        "    X, y = [], []\n",
        "    # y must be future 5 steps\n",
        "    horizon = CONFIG[\"predict_horizon\"]\n",
        "\n",
        "    # Valid range for training\n",
        "    # Input: i ~ i+seq\n",
        "    # Target: i+seq ~ i+seq+horizon\n",
        "    valid_len = len(scaled_x) - seq_len - horizon + 1\n",
        "\n",
        "    for i in range(valid_len):\n",
        "        X.append(scaled_x[i : i + seq_len])\n",
        "        y.append(scaled_y[i + seq_len : i + seq_len + horizon].flatten())\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y, scaler_y, last_sequence_x, len(input_df.columns), raw_y[-1][0]\n",
        "\n",
        "# --- 3. Models ---\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        pooled_len = seq_length // 2\n",
        "        self.fc = nn.Linear(num_filters * pooled_len, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        return self.fc(x.flatten(1))\n",
        "\n",
        "class CNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):\n",
        "        super(CNNLSTMModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "class LSTMAttentionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMAttentionModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = nn.Linear(hidden_size, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        attn_weights = torch.softmax(self.attention(out), dim=1)\n",
        "        context = torch.sum(attn_weights * out, dim=1)\n",
        "        out = self.fc(context)\n",
        "        return out\n",
        "\n",
        "# --- 4. Training ---\n",
        "def train_model(model, X_train, y_train, config):\n",
        "    # Tensor conversion\n",
        "    X_t = torch.FloatTensor(X_train).to(config['device'])\n",
        "    y_t = torch.FloatTensor(y_train).to(config['device'])\n",
        "\n",
        "    dataset = TensorDataset(X_t, y_t)\n",
        "    loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        for X_b, y_b in loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_b)\n",
        "            loss = criterion(pred, y_b)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "# --- 5. Individual Plotting Function ---\n",
        "def plot_and_save(model_name, drop_group, plot_dates, plot_values, last_price, last_date_str):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # 1. Start Point (Nov 28)\n",
        "    plt.plot(plot_dates[:1], plot_values[:1], marker='o', color='black', label=f'Actual ({last_date_str})')\n",
        "\n",
        "    # 2. Prediction Line (Nov 28 -> Dec 5)\n",
        "    plt.plot(plot_dates, plot_values, marker='o', linestyle='--', color='red', label='Prediction (Dec 1-5)', linewidth=2)\n",
        "\n",
        "    # Annotate Values\n",
        "    for i, (date, val) in enumerate(zip(plot_dates, plot_values)):\n",
        "        label_color = 'black' if i == 0 else 'red'\n",
        "        plt.text(date, val, f\"{val:.0f}\", ha='center', va='bottom', color=label_color, fontsize=9, fontweight='bold')\n",
        "\n",
        "    # Styling\n",
        "    title_str = f\"Future Prediction: {model_name}\\n(Optimized Feature: Drop {drop_group if drop_group else 'None'})\"\n",
        "    plt.title(title_str, fontsize=14)\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.ylabel(\"KOSPI Index\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Save\n",
        "    safe_name = model_name.replace('+', '_').replace('(', '').replace(')', '')\n",
        "    filename = f\"Future_Prediction_{safe_name}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"   [Graph Saved] {filename}\")\n",
        "    plt.close()\n",
        "\n",
        "# --- 6. Main Logic ---\n",
        "def main():\n",
        "    print(\"Loading Data...\")\n",
        "    full_df = load_data(CONFIG)\n",
        "\n",
        "    # Last Actual Price (Anchor)\n",
        "    last_date = full_df.index[-1] # 2025-11-28\n",
        "    last_price = full_df[\"KOSPI_Close\"].iloc[-1]\n",
        "\n",
        "    print(f\"Anchor Date: {last_date.date()} | Price: {last_price:.2f}\")\n",
        "\n",
        "    # Future Dates (Dec 1 ~ Dec 5, Business Days)\n",
        "    future_dates = pd.date_range(start=CONFIG[\"future_start_date\"], periods=CONFIG[\"future_days\"], freq='B')\n",
        "\n",
        "    # Plotting X-Axis: [Nov 28, Dec 1, Dec 2, ..., Dec 5]\n",
        "    plot_dates = [last_date] + list(future_dates)\n",
        "\n",
        "    # Optimized Scenarios\n",
        "    scenarios = [\n",
        "        (\"CNN\", \"Foreign\", CNNModel),\n",
        "        (\"LSTM\", None, LSTMModel),\n",
        "        (\"CNN+LSTM\", \"KOSPI\", CNNLSTMModel),\n",
        "        (\"LSTM(Attn)\", \"Foreign\", LSTMAttentionModel)\n",
        "    ]\n",
        "\n",
        "    print(\"\\n[Start Training & Generating Separate Graphs]\")\n",
        "\n",
        "    for model_name, drop_group, ModelClass in scenarios:\n",
        "        print(f\"\\n>> Processing {model_name} (Drop: {drop_group})...\")\n",
        "\n",
        "        # 1. Prepare Data (Apply Drop)\n",
        "        X, y, scaler_y, last_seq_x, input_dim, _ = process_features(full_df, drop_group)\n",
        "\n",
        "        # 2. Init Model\n",
        "        if model_name == \"CNN\":\n",
        "            model = ModelClass(input_dim, 5, 32, 5, CONFIG[\"seq_length\"])\n",
        "        elif model_name == \"CNN+LSTM\":\n",
        "            model = ModelClass(input_dim, 256, 1, 5, 32, 5)\n",
        "        else:\n",
        "            model = ModelClass(input_dim, 256, 1, 5)\n",
        "\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        # 3. Train\n",
        "        model = train_model(model, X, y, CONFIG)\n",
        "\n",
        "        # 4. Predict\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_tensor = torch.FloatTensor(last_seq_x).unsqueeze(0).to(CONFIG['device'])\n",
        "            pred_scaled = model(input_tensor).cpu().numpy() # (1, 5)\n",
        "\n",
        "        # 5. Inverse Transform (Reshape logic required for scaler)\n",
        "        # Scaler fit on (N, 1). Output is (1, 5).\n",
        "        pred_prices = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # 6. Prepare Plot Data (Connect Nov 28 -> Dec 1)\n",
        "        plot_values = [last_price] + list(pred_prices)\n",
        "\n",
        "        print(f\"   Pred (Dec 1-5): {[int(p) for p in pred_prices]}\")\n",
        "\n",
        "        # 7. Draw & Save Individual Graph\n",
        "        plot_and_save(model_name, drop_group, plot_dates, plot_values, last_price, str(last_date.date()))\n",
        "\n",
        "    print(\"\\nAll tasks completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "flx4nsO6Aqd3",
        "outputId": "9afa81b4-c9c5-410c-88f0-e823bc325478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "Loading Data...\n",
            "Anchor Date: 2025-11-28 | Price: 3926.59\n",
            "\n",
            "[Start Training & Generating Separate Graphs]\n",
            "\n",
            ">> Processing CNN (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [3988, 3986, 3973, 3960, 3956]\n",
            "   [Graph Saved] Future_Prediction_CNN.png\n",
            "\n",
            ">> Processing LSTM (Drop: None)...\n",
            "   Pred (Dec 1-5): [3909, 3917, 3911, 3926, 3932]\n",
            "   [Graph Saved] Future_Prediction_LSTM.png\n",
            "\n",
            ">> Processing CNN+LSTM (Drop: KOSPI)...\n",
            "   Pred (Dec 1-5): [3926, 3931, 3936, 3947, 3950]\n",
            "   [Graph Saved] Future_Prediction_CNN_LSTM.png\n",
            "\n",
            ">> Processing LSTM(Attn) (Drop: Foreign)...\n",
            "   Pred (Dec 1-5): [3975, 3977, 3967, 3978, 3984]\n",
            "   [Graph Saved] Future_Prediction_LSTMAttn.png\n",
            "\n",
            "All tasks completed.\n"
          ]
        }
      ]
    }
  ]
}