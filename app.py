import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import io
import os

# --- ì„¤ì • ---
st.set_page_config(page_title="Stock Prediction Inference", layout="wide")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
TIME_STEP = 60
HORIZON = 5

# --- ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•´ì•¼ í•¨) ---
class CNN_LSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(CNN_LSTM, self).__init__()
        self.conv = nn.Conv1d(input_dim, 64, 3, padding=1)
        self.pool = nn.MaxPool1d(2)
        self.lstm = nn.LSTM(64, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = self.pool(self.relu(self.conv(x)))
        x = x.permute(0, 2, 1)
        _, (h_n, _) = self.lstm(x)
        return self.fc(h_n[-1])

class AttentionLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(AttentionLSTM, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)
        self.attention = nn.Linear(hidden_dim * 2, 1)
        self.fc = nn.Linear(hidden_dim * 2, output_dim)

    def forward(self, x):
        outputs, _ = self.lstm(x)
        score = self.attention(outputs)
        weights = F.softmax(score, dim=1)
        context = torch.sum(outputs * weights, dim=1)
        return self.fc(context)

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
class CustomMinMaxScaler:
    def __init__(self):
        self.min_ = None
        self.max_ = None
        self.scale_ = None
    
    def load_params(self, min_val, scale_val):
        self.min_ = min_val
        self.scale_ = scale_val

    def transform(self, data):
        return (data - self.min_) / self.scale_
    
    def inverse_transform_col(self, data, col_index):
        return (data * self.scale_[col_index]) + self.min_[col_index]

@st.cache_data
def load_csv_data(uploaded_file):
    encodings = ['utf-8', 'utf-8-sig', 'utf-16', 'cp949']
    df = pd.DataFrame()
    bytes_data = uploaded_file.getvalue()
    for enc in encodings:
        try:
            df = pd.read_csv(io.BytesIO(bytes_data), sep='\t', index_col='Date', parse_dates=['Date'], encoding=enc)
            if len(df.columns) <= 1:
                df = pd.read_csv(io.BytesIO(bytes_data), sep=',', index_col='Date', parse_dates=['Date'], encoding=enc)
            break
        except: continue
    
    if not df.empty:
        df = df[df.index.notna()].sort_index().ffill().dropna()
    return df

def load_checkpoint(uploaded_file, model_class):
    # ë©”ëª¨ë¦¬ ë²„í¼ì—ì„œ ë¡œë“œ
    checkpoint = torch.load(io.BytesIO(uploaded_file.getvalue()), map_location=DEVICE)
    
    input_dim = checkpoint['input_dim']
    scaler = CustomMinMaxScaler()
    scaler.load_params(checkpoint['scaler_min'], checkpoint['scaler_scale'])
    
    model = model_class(input_dim, 64, HORIZON)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(DEVICE)
    model.eval()
    
    return model, scaler, input_dim, checkpoint.get('feature_names', [])

# --- ë©”ì¸ ì•± ---
def main():
    st.title("âš¡ ë¹ ë¥¸ ì£¼ê°€ ì˜ˆì¸¡ (Inference Mode)")
    st.markdown("ë¯¸ë¦¬ í•™ìŠµëœ `.pth` íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ëŒ€ê¸° ì‹œê°„ ì—†ì´ ì¦‰ì‹œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # ì‚¬ì´ë“œë°”
    st.sidebar.header("1. íŒŒì¼ ì—…ë¡œë“œ")
    
    # 1) ë°ì´í„° íŒŒì¼
    data_file = st.sidebar.file_uploader("KOSPI ë°ì´í„° (csv)", type=['csv', 'txt'])
    
    # 2) ëª¨ë¸ íŒŒë¼ë¯¸í„° íŒŒì¼
    st.sidebar.markdown("---")
    st.sidebar.subheader("í•™ìŠµëœ íŒŒë¼ë¯¸í„° (.pth)")
    model_cnn_file = st.sidebar.file_uploader("ë©”ì¸: CNN+LSTM (.pth)", type=['pth'], key='cnn')
    model_attn_file = st.sidebar.file_uploader("ë³´ì¡°: Attention LSTM (.pth)", type=['pth'], key='attn')

    # ë©”ì¸ ë¡œì§
    if data_file is not None:
        df = load_csv_data(data_file)
        st.sidebar.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(df)} rows)")
        
        # ëª¨ë¸ ì„ íƒ ì²´í¬ë°•ìŠ¤
        st.sidebar.markdown("---")
        st.sidebar.subheader("2. ì˜ˆì¸¡ ëª¨ë¸ ì„ íƒ")
        use_cnn = st.sidebar.checkbox("ë©”ì¸: CNN+LSTM", value=True, disabled=(model_cnn_file is None))
        use_attn = st.sidebar.checkbox("ë³´ì¡°: Attention LSTM", value=False, disabled=(model_attn_file is None))

        if not (use_cnn or use_attn):
            st.warning("ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ íŒŒë¼ë¯¸í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        # ë‚ ì§œ ì„ íƒ
        st.sidebar.markdown("---")
        st.sidebar.subheader("3. ì˜ˆì¸¡ ì‹œì  ì„¤ì •")
        
        # Default 12ì›” 1ì¼ ì„¤ì •
        default_date = pd.Timestamp("2025-12-01").date()
        min_date = df.index.min().date() + pd.Timedelta(days=60)
        max_date = df.index.max().date() + pd.Timedelta(days=1)
        
        # ë²”ìœ„ ë³´ì •
        if default_date > max_date: default_date = max_date
        if default_date < min_date: default_date = min_date

        predict_date = st.date_input("ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œ (ì´ ë‚ ì§œë¶€í„° 5ì¼)", value=default_date, min_value=min_date)

        # ì˜ˆì¸¡ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ”® ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
            
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (ê³¼ê±° 60ì¼)
            cutoff_date = pd.to_datetime(predict_date) - pd.Timedelta(days=1)
            
            # íŒŒë¼ë¯¸í„° íŒŒì¼ì—ì„œ feature namesë¥¼ ê°€ì ¸ì™€ì„œ ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸° (ì¤‘ìš”)
            # CNN ëª¨ë¸ì´ ìˆë‹¤ë©´ CNN ê¸°ì¤€, ì—†ë‹¤ë©´ Attn ê¸°ì¤€
            ref_file = model_cnn_file if model_cnn_file else model_attn_file
            temp_ckpt = torch.load(io.BytesIO(ref_file.getvalue()), map_location=DEVICE)
            feature_cols = temp_ckpt.get('feature_names', df.columns.tolist())
            
            # ì»¬ëŸ¼ í•„í„°ë§ (ì—†ëŠ” ì»¬ëŸ¼ ìˆìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬ í•„ìš”í•˜ì§€ë§Œ ì—¬ê¸°ì„  try)
            try:
                input_df = df.loc[:cutoff_date, feature_cols].tail(TIME_STEP)
            except KeyError:
                st.error(f"CSV íŒŒì¼ì˜ ì»¬ëŸ¼ì´ í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¦…ë‹ˆë‹¤. í•„ìš” ì»¬ëŸ¼: {feature_cols}")
                return

            if len(input_df) < TIME_STEP:
                st.error("ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return

            # ì˜ˆì¸¡ ë¡œì§
            results = {}
            
            # 1. CNN+LSTM ì˜ˆì¸¡
            if use_cnn and model_cnn_file:
                model, scaler, _, _ = load_checkpoint(model_cnn_file, CNN_LSTM)
                
                # ì „ì²˜ë¦¬
                input_raw = input_df.values
                input_scaled = scaler.transform(input_raw)
                input_tensor = torch.tensor(input_scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
                
                # ì¶”ë¡ 
                with torch.no_grad():
                    pred_change = model(input_tensor).cpu().numpy().flatten()
                
                # ë³µì›
                last_val_scaled = input_scaled[-1, 0]
                pred_val_scaled = pred_change + last_val_scaled
                pred_final = scaler.inverse_transform_col(pred_val_scaled, 0)
                results["CNN+LSTM"] = pred_final

            # 2. Attention LSTM ì˜ˆì¸¡
            if use_attn and model_attn_file:
                model, scaler, _, _ = load_checkpoint(model_attn_file, AttentionLSTM)
                
                input_raw = input_df.values
                input_scaled = scaler.transform(input_raw)
                input_tensor = torch.tensor(input_scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
                
                with torch.no_grad():
                    pred_change = model(input_tensor).cpu().numpy().flatten()
                
                last_val_scaled = input_scaled[-1, 0]
                pred_val_scaled = pred_change + last_val_scaled
                pred_final = scaler.inverse_transform_col(pred_val_scaled, 0)
                results["Attention LSTM"] = pred_final

            # --- ê²°ê³¼ ì‹œê°í™” ---
            st.divider()
            st.subheader(f"ğŸ“… ì˜ˆì¸¡ ê²°ê³¼ ({predict_date} ~ 5ì¼ê°„)")
            
            # ë‚ ì§œ ìƒì„±
            target_dates = pd.date_range(start=predict_date, periods=HORIZON, freq='B')
            date_strs = target_dates.strftime('%Y-%m-%d')
            
            res_df = pd.DataFrame({"ë‚ ì§œ": date_strs})
            for name, val in results.items():
                res_df[name] = np.round(val, 2)
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.write("##### ì˜ˆì¸¡ê°’ í…Œì´ë¸”")
                st.dataframe(res_df, hide_index=True)
                
            with col2:
                st.write("##### ì˜ˆì¸¡ ê·¸ë˜í”„")
                fig, ax = plt.subplots(figsize=(10, 5))
                
                colors = {"CNN+LSTM": "red", "Attention LSTM": "blue"}
                styles = {"CNN+LSTM": "-", "Attention LSTM": "--"}
                
                for name, val in results.items():
                    ax.plot(res_df['ë‚ ì§œ'], val, label=name, 
                            color=colors.get(name, "gray"), 
                            linestyle=styles.get(name, "-"), marker='o')
                
                # ê³¼ê±° ë°ì´í„° (ë¬¸ë§¥ìš©)
                past_days = 15
                past_data = df.loc[:cutoff_date, feature_cols[0]].tail(past_days)
                ax.plot(past_data.index.strftime('%Y-%m-%d'), past_data.values, color='gray', alpha=0.3, label='History')
                
                ax.set_title("Prediction Result")
                ax.legend()
                ax.grid(True, alpha=0.3)
                plt.xticks(rotation=45)
                st.pyplot(fig)

    else:
        st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° ë° ëª¨ë¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
