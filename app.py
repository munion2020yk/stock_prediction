import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import os

# --- ì„¤ì • ---
st.set_page_config(page_title="KOSPI Prediction App", layout="wide")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# íŒŒì¼ ê²½ë¡œ (ê°™ì€ í´ë” ê¸°ì¤€)
DATA_FILE = "KOSPI_dataset_final.csv"
MODEL_FILES = {
    "LSTM": "LSTM_params.pth",
    "CNN": "CNN_params.pth",
    "CNN+LSTM": "CNN+LSTM_params.pth",
    "LSTM(Attention)": "LSTM_Attn_params.pth"
}

# --- ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼) ---
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

class CNNModel(nn.Module):
    def __init__(self, input_size, output_size, num_filters, kernel_size, seq_length):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool1d(2)
        pooled_len = seq_length // 2
        self.fc = nn.Linear(num_filters * pooled_len, output_size)
    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = self.pool(self.relu(self.conv1(x)))
        return self.fc(x.flatten(1))

class CNNLSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, num_filters, kernel_size):
        super(CNNLSTMModel, self).__init__()
        self.conv1 = nn.Conv1d(input_size, num_filters, kernel_size, padding='same')
        self.relu = nn.ReLU()
        self.lstm = nn.LSTM(num_filters, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = self.relu(self.conv1(x))
        x = x.permute(0, 2, 1)
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

class LSTMAttentionModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMAttentionModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.attention = nn.Linear(hidden_size, 1)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        out, _ = self.lstm(x)
        attn_weights = torch.softmax(self.attention(out), dim=1) 
        context = torch.sum(attn_weights * out, dim=1) 
        out = self.fc(context)
        return out

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
@st.cache_data
def load_csv_data(filepath):
    if not os.path.exists(filepath): return pd.DataFrame()
    encodings = ['utf-16', 'utf-8', 'utf-8-sig', 'cp949', 'latin1']
    df = None
    for enc in encodings:
        try:
            temp_df = pd.read_csv(filepath, sep='\t', index_col="Date", parse_dates=True, encoding=enc)
            if len(temp_df.columns) > 1: df = temp_df; break
            temp_df = pd.read_csv(filepath, sep=',', index_col="Date", parse_dates=True, encoding=enc)
            if len(temp_df.columns) > 1: df = temp_df; break
        except: continue
    
    if df is not None:
        for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df.ffill().bfill().dropna()
        df.columns = [c.strip() for c in df.columns]
    return df

def load_model_checkpoint(model_name):
    pth_file = MODEL_FILES.get(model_name)
    if not os.path.exists(pth_file): return None
    
    # weights_only=False í•„ìˆ˜ (numpy, dict í¬í•¨)
    checkpoint = torch.load(pth_file, map_location=DEVICE, weights_only=False)
    
    input_dim = checkpoint['input_dim']
    seq_len = 5 # Configured in training
    horizon = 5 # Configured in training
    
    # Init Model
    if model_name == "CNN":
        model = CNNModel(input_dim, horizon, 32, 5, seq_len)
    elif model_name == "CNN+LSTM":
        model = CNNLSTMModel(input_dim, 256, 1, horizon, 32, 5)
    elif model_name == "LSTM(Attention)":
        model = LSTMAttentionModel(input_dim, 256, 1, horizon)
    else: # LSTM
        model = LSTMModel(input_dim, 256, 1, horizon)
        
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(DEVICE)
    model.eval()
    
    return model, checkpoint

# --- ë©”ì¸ ì•± ---
def main():
    st.title("ğŸ“ˆ KOSPI Stock Prediction Service")
    st.markdown("ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í™œìš©í•œ **KOSPI í–¥í›„ 5ì¼ ì£¼ê°€ ì˜ˆì¸¡** ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.")

    # 1. ë°ì´í„° ë¡œë“œ í™•ì¸
    df = load_csv_data(DATA_FILE)
    if df.empty:
        st.error(f"ë°ì´í„° íŒŒì¼({DATA_FILE})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # --- ì‚¬ì´ë“œë°” ì„¤ì • ---
    st.sidebar.header("ì„¤ì • (Configuration)")
    
    # 2. ëª¨ë¸ ì„ íƒ (Radio Box)
    model_options = ["LSTM", "CNN", "CNN+LSTM", "LSTM(Attention)"]
    selected_model_name = st.sidebar.radio("ì˜ˆì¸¡ ëª¨ë¸ ì„ íƒ", model_options, index=0) # ì´ˆê¸°ê°’ LSTM
    
    # ëª¨ë¸ ë¡œë“œ
    loaded_data = load_model_checkpoint(selected_model_name)
    if loaded_data is None:
        st.sidebar.error(f"ëª¨ë¸ íŒŒì¼({MODEL_FILES.get(selected_model_name)})ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
        
    model, checkpoint = loaded_data
    feature_names = checkpoint['feature_names']
    
    # 3. ë‚ ì§œ ì„ íƒ
    last_date = df.index[-1]
    default_date = pd.Timestamp("2025-12-01").date()
    min_date = df.index.min().date() + pd.Timedelta(days=10)
    
    predict_date = st.sidebar.date_input("ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œ", value=default_date, min_value=min_date)
    
    # --- ì˜ˆì¸¡ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ ---
    
    # ë°ì´í„° ì¤€ë¹„ (cutoff date ê¸°ì¤€ ê³¼ê±° 5ì¼)
    cutoff_date = pd.to_datetime(predict_date) - pd.Timedelta(days=1)
    
    # í•™ìŠµ ë•Œ ì‚¬ìš©í•œ Featureë§Œ ì„ íƒ
    try:
        input_df = df.loc[:cutoff_date, feature_names].tail(5)
    except KeyError:
        st.error("ë°ì´í„° ì»¬ëŸ¼ì´ ëª¨ë¸ í•™ìŠµ ì‹œì™€ ë‹¤ë¦…ë‹ˆë‹¤.")
        st.stop()
        
    if len(input_df) < 5:
        st.error("ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
        
    # Scaling (X) - ì €ì¥ëœ scaler íŒŒë¼ë¯¸í„° ì‚¬ìš©
    x_min = checkpoint['scaler_x_min']
    x_scale = checkpoint['scaler_x_scale']
    
    input_raw = input_df.values
    input_scaled = (input_raw - x_min) / x_scale
    
    # Predict
    input_tensor = torch.FloatTensor(input_scaled).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        pred_scaled = model(input_tensor).cpu().numpy().flatten()
        
    # Inverse Scaling (y)
    y_params = checkpoint['scaler_y_params']
    y_min = y_params['min'][0]
    y_scale = y_params['scale'][0]
    
    pred_prices = (pred_scaled * y_scale) + y_params['data_min'][0] # min_ + data_min ì£¼ì˜ (sklearn êµ¬ì¡°ì— ë”°ë¦„)
    # sklearn minmax: X_std = (X - X.min) / (X.max - X.min)
    # X_scaled = X_std * (max - min) + min
    # Inverse: X = X_scaled * scale_ + min_ 
    # checkpoint ì €ì¥ì‹œ scaler.min_ ê³¼ scale_ ì €ì¥í–ˆìŒ.
    # ì •í™•í•œ ì—­ë³€í™˜: (val - min_) / scale_  (X) -> val * scale + min? (X)
    # sklearn ê³µì‹: X = (X_scaled - min_) / scale_  (X)
    # -> X_scaled = X * scale_ + min_
    # -> X = (X_scaled - min_) / scale_
    pred_prices = (pred_scaled - y_params['min'][0]) / y_params['scale'][0]

    # --- í™”ë©´ êµ¬ì„± ---
    
    # ë‚ ì§œ ìƒì„±
    target_dates = pd.date_range(start=predict_date, periods=5, freq='B')
    date_strs = target_dates.strftime('%Y-%m-%d')
    
    # 1. ìˆ«ì í…Œì´ë¸” (í¬ê²Œ)
    st.subheader(f"ğŸ“Š {selected_model_name} ì˜ˆì¸¡ ê²°ê³¼ ({predict_date} ~)")
    
    res_df = pd.DataFrame({
        "ë‚ ì§œ": date_strs,
        "ì˜ˆì¸¡ ì£¼ê°€ (KRW)": [f"{p:,.0f}" for p in pred_prices],
        "ë“±ë½": ["-" for _ in range(5)] # ì „ì¼ëŒ€ë¹„ ê³„ì‚° ê°€ëŠ¥í•˜ë©´ ì¶”ê°€
    })
    
    # ì „ì¼ ëŒ€ë¹„ ê³„ì‚°
    last_real_price = input_df["KOSPI_Close"].iloc[-1]
    diffs = []
    prev = last_real_price
    for p in pred_prices:
        d = p - prev
        sign = "ğŸ”º" if d > 0 else "ğŸ”»" if d < 0 else "-"
        diffs.append(f"{sign} {abs(d):.0f}")
        prev = p
    res_df["ë“±ë½"] = diffs
    
    # í…Œì´ë¸” ìŠ¤íƒ€ì¼ë§ (ê¸€ì í¬ê¸° í‚¤ìš°ê¸°)
    st.dataframe(res_df, use_container_width=True, hide_index=True)
    
    # 2. ì°¸ì¡°ìš© ê·¸ë˜í”„ (ì‘ê²Œ)
    st.markdown("---")
    st.caption("ğŸ“‰ ì˜ˆì¸¡ ì¶”ì„¸ ê·¸ë˜í”„ (ì°¸ì¡°ìš©)")
    
    col1, col2, col3 = st.columns([1, 2, 1]) # ê°€ìš´ë° ì •ë ¬ íš¨ê³¼
    with col2:
        fig, ax = plt.subplots(figsize=(6, 3)) # ì‘ì€ ì‚¬ì´ì¦ˆ
        
        # ì‹œì‘ì  (ê³¼ê±° 1ì¼) ì—°ê²°
        plot_dates = [input_df.index[-1]] + list(target_dates)
        plot_values = [last_real_price] + list(pred_prices)
        
        ax.plot(plot_dates, plot_values, marker='o', color='red', linestyle='--', linewidth=1.5, label='Prediction')
        ax.axhline(y=last_real_price, color='gray', linestyle=':', linewidth=1, label='Ref Price')
        
        ax.set_title("5-Day Forecast Trend", fontsize=10)
        ax.tick_params(axis='x', labelsize=8, rotation=45)
        ax.tick_params(axis='y', labelsize=8)
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=8)
        
        st.pyplot(fig)

if __name__ == "__main__":
    main()
