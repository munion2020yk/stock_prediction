import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import io
import os

# --- ì„¤ì • ---
st.set_page_config(page_title="Stock Prediction Inference", layout="wide")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
TIME_STEP = 60
HORIZON = 5

# ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •)
DATA_FILE_PATH = "KOSPI_base.csv"
CNN_MODEL_PATH = "cnn_lstm_model.pth"
ATTN_MODEL_PATH = "attn_lstm_model.pth"

# --- ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•´ì•¼ í•¨) ---
class CNN_LSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(CNN_LSTM, self).__init__()
        self.conv = nn.Conv1d(input_dim, 64, 3, padding=1)
        self.pool = nn.MaxPool1d(2)
        self.lstm = nn.LSTM(64, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = self.pool(self.relu(self.conv(x)))
        x = x.permute(0, 2, 1)
        _, (h_n, _) = self.lstm(x)
        return self.fc(h_n[-1])

class AttentionLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(AttentionLSTM, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)
        self.attention = nn.Linear(hidden_dim * 2, 1)
        self.fc = nn.Linear(hidden_dim * 2, output_dim)

    def forward(self, x):
        outputs, _ = self.lstm(x)
        score = self.attention(outputs)
        weights = F.softmax(score, dim=1)
        context = torch.sum(outputs * weights, dim=1)
        return self.fc(context)

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
class CustomMinMaxScaler:
    def __init__(self):
        self.min_ = None
        self.max_ = None
        self.scale_ = None
    
    def load_params(self, min_val, scale_val):
        self.min_ = min_val
        self.scale_ = scale_val

    def transform(self, data):
        return (data - self.min_) / self.scale_
    
    def inverse_transform_col(self, data, col_index):
        return (data * self.scale_[col_index]) + self.min_[col_index]

@st.cache_data
def load_csv_data(file_path):
    encodings = ['utf-8', 'utf-8-sig', 'utf-16', 'cp949']
    df = pd.DataFrame()
    
    if not os.path.exists(file_path):
        return df

    for enc in encodings:
        try:
            df = pd.read_csv(file_path, sep='\t', index_col='Date', parse_dates=['Date'], encoding=enc)
            if len(df.columns) <= 1:
                df = pd.read_csv(file_path, sep=',', index_col='Date', parse_dates=['Date'], encoding=enc)
            break
        except: continue
    
    if not df.empty:
        df = df[df.index.notna()].sort_index().ffill().dropna()
    return df

def load_checkpoint(file_path, model_class):
    # íŒŒì¼ ê²½ë¡œì—ì„œ ì§ì ‘ ë¡œë“œ
    try:
        checkpoint = torch.load(file_path, map_location=DEVICE)
    except Exception as e:
        st.error(f"ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path}")
        st.warning("íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ Git LFS í¬ì¸í„°ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        raise e
    
    input_dim = checkpoint['input_dim']
    scaler = CustomMinMaxScaler()
    scaler.load_params(checkpoint['scaler_min'], checkpoint['scaler_scale'])
    
    model = model_class(input_dim, 64, HORIZON)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(DEVICE)
    model.eval()
    
    return model, scaler, input_dim, checkpoint.get('feature_names', [])

# --- ë©”ì¸ ì•± ---
def main():
    st.title("âš¡ ì£¼ê°€ ì˜ˆì¸¡ ìë™ ë¶„ì„ (Inference Mode)")
    st.markdown("ì„œë²„ì— ì €ì¥ëœ ë°ì´í„°ì™€ í•™ìŠµëœ ëª¨ë¸ì„ **ìë™ìœ¼ë¡œ ë¡œë“œ**í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")

    # ì‚¬ì´ë“œë°” ìƒíƒœ í‘œì‹œ
    st.sidebar.header("ì‹œìŠ¤í…œ ìƒíƒœ (ìë™ ë¡œë“œ)")

    # 1. ë°ì´í„° ë¡œë“œ í™•ì¸
    if os.path.exists(DATA_FILE_PATH):
        df = load_csv_data(DATA_FILE_PATH)
        if not df.empty:
            st.sidebar.success(f"âœ… ë°ì´í„° ë¡œë“œë¨ ({len(df)}ì¼)")
        else:
            st.sidebar.error("âŒ ë°ì´í„° íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")
            st.stop()
    else:
        st.sidebar.error(f"âŒ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {DATA_FILE_PATH}")
        st.info(f"ì‹¤í–‰ ê²½ë¡œì— '{DATA_FILE_PATH}' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # 2. ëª¨ë¸ íŒŒì¼ í™•ì¸
    cnn_exists = os.path.exists(CNN_MODEL_PATH)
    attn_exists = os.path.exists(ATTN_MODEL_PATH)
    
    if cnn_exists:
        st.sidebar.success(f"âœ… CNN+LSTM ëª¨ë¸ ë°œê²¬")
    else:
        st.sidebar.warning(f"âš ï¸ CNN+LSTM ëª¨ë¸ ì—†ìŒ ({CNN_MODEL_PATH})")

    if attn_exists:
        st.sidebar.success(f"âœ… Attention LSTM ëª¨ë¸ ë°œê²¬")
    else:
        st.sidebar.warning(f"âš ï¸ Attention LSTM ëª¨ë¸ ì—†ìŒ ({ATTN_MODEL_PATH})")

    if not (cnn_exists or attn_exists):
        st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ íŒŒì¼(.pth)ì´ ì—†ìŠµë‹ˆë‹¤. 'train_and_save.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        st.stop()

    # 3. ëª¨ë¸ ì„ íƒ
    st.sidebar.markdown("---")
    st.sidebar.subheader("ì˜ˆì¸¡ ëª¨ë¸ ì„¤ì •")
    use_cnn = st.sidebar.checkbox("ë©”ì¸: CNN+LSTM", value=cnn_exists, disabled=not cnn_exists)
    use_attn = st.sidebar.checkbox("ë³´ì¡°: Attention LSTM", value=attn_exists, disabled=not attn_exists)

    if not (use_cnn or use_attn):
        st.warning("ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    # 4. ë‚ ì§œ ì„ íƒ
    st.sidebar.markdown("---")
    st.sidebar.subheader("ì˜ˆì¸¡ ì‹œì  ì„¤ì •")
    
    # Default 12ì›” 1ì¼ ì„¤ì •
    default_date = pd.Timestamp("2025-12-01").date()
    min_date = df.index.min().date() + pd.Timedelta(days=60)
    max_date = df.index.max().date() + pd.Timedelta(days=1)
    
    if default_date > max_date: default_date = max_date
    if default_date < min_date: default_date = min_date

    predict_date = st.date_input("ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œ (ì´ ë‚ ì§œë¶€í„° 5ì¼)", value=default_date, min_value=min_date)

    # ë©”ì¸ í™”ë©´ êµ¬ì„±
    st.markdown("---")
    
    col_btn, col_info = st.columns([1, 3])
    with col_btn:
        run_btn = st.button("ğŸ”® ì˜ˆì¸¡ ì‹¤í–‰", type="primary")
    with col_info:
        st.write(f"ì„ íƒëœ ê¸°ì¤€ì¼: **{predict_date}** (ë°ì´í„° ë§ˆì§€ë§‰ ë‚ ì§œ: {df.index.max().date()})")

    # ì˜ˆì¸¡ ì‹¤í–‰ ë¡œì§
    if run_btn:
        # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
        cutoff_date = pd.to_datetime(predict_date) - pd.Timedelta(days=1)
        
        # ì°¸ì¡° ëª¨ë¸ íŒŒì¼ ê²°ì • (ì»¬ëŸ¼ ë§¤í•‘ìš©)
        ref_path = CNN_MODEL_PATH if cnn_exists else ATTN_MODEL_PATH
        
        try:
            temp_ckpt = torch.load(ref_path, map_location=DEVICE)
        except Exception as e:
            st.error(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨: {ref_path}")
            st.error(f"Error Details: {e}")
            st.warning("Tip: .pth íŒŒì¼ì´ ì •ìƒì ì¸ ë°”ì´ë„ˆë¦¬ íŒŒì¼ì¸ì§€ í™•ì¸í•˜ì„¸ìš”. (Git LFS Pointerì¼ ê°€ëŠ¥ì„± ìˆìŒ)")
            return

        feature_cols = temp_ckpt.get('feature_names', df.columns.tolist())
        
        # ë°ì´í„° ìŠ¬ë¼ì´ì‹±
        try:
            # cutoff_dateê¹Œì§€ì˜ ë°ì´í„° ì¤‘ ë§ˆì§€ë§‰ 60ê°œ
            input_df = df.loc[:cutoff_date, feature_cols].tail(TIME_STEP)
        except KeyError:
            st.error(f"ë°ì´í„° ì»¬ëŸ¼ ë¶ˆì¼ì¹˜. ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì»¬ëŸ¼: {feature_cols}")
            return

        if len(input_df) < TIME_STEP:
            st.error(f"ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í•„ìš”: 60ì¼, ì‹¤ì œ: {len(input_df)}ì¼)")
            return

        # ì˜ˆì¸¡ ìˆ˜í–‰
        results = {}
        
        # 1. CNN+LSTM
        if use_cnn and cnn_exists:
            try:
                model, scaler, _, _ = load_checkpoint(CNN_MODEL_PATH, CNN_LSTM)
                input_raw = input_df.values
                input_scaled = scaler.transform(input_raw)
                input_tensor = torch.tensor(input_scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
                
                with torch.no_grad():
                    pred_change = model(input_tensor).cpu().numpy().flatten()
                
                last_val_scaled = input_scaled[-1, 0] # 0ë²ˆ ì»¬ëŸ¼ Target ê°€ì •
                pred_val_scaled = pred_change + last_val_scaled
                pred_final = scaler.inverse_transform_col(pred_val_scaled, 0)
                results["CNN+LSTM"] = pred_final
            except Exception as e:
                st.error(f"CNN+LSTM ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # 2. Attention LSTM
        if use_attn and attn_exists:
            try:
                model, scaler, _, _ = load_checkpoint(ATTN_MODEL_PATH, AttentionLSTM)
                input_raw = input_df.values
                input_scaled = scaler.transform(input_raw)
                input_tensor = torch.tensor(input_scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
                
                with torch.no_grad():
                    pred_change = model(input_tensor).cpu().numpy().flatten()
                
                last_val_scaled = input_scaled[-1, 0]
                pred_val_scaled = pred_change + last_val_scaled
                pred_final = scaler.inverse_transform_col(pred_val_scaled, 0)
                results["Attention LSTM"] = pred_final
            except Exception as e:
                st.error(f"Attention LSTM ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ê²°ê³¼ ì‹œê°í™”
        st.subheader(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ({predict_date} ~ +5ì¼)")
        
        target_dates = pd.date_range(start=predict_date, periods=HORIZON, freq='B')
        date_strs = target_dates.strftime('%Y-%m-%d')
        
        res_df = pd.DataFrame({"ë‚ ì§œ": date_strs})
        for name, val in results.items():
            res_df[name] = np.round(val, 2)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("##### ğŸ“‹ ì˜ˆì¸¡ ê°€ê²© í…Œì´ë¸”")
            st.dataframe(res_df, hide_index=True, use_container_width=True)
            
        with col2:
            st.markdown("##### ğŸ“ˆ ì£¼ê°€ ì¶”ì„¸ ê·¸ë˜í”„")
            fig, ax = plt.subplots(figsize=(10, 5))
            
            colors = {"CNN+LSTM": "#ff4b4b", "Attention LSTM": "#1c83e1"}
            styles = {"CNN+LSTM": "-", "Attention LSTM": "--"}
            
            # ì˜ˆì¸¡ê°’ Plot
            for name, val in results.items():
                ax.plot(res_df['ë‚ ì§œ'], val, label=name, 
                        color=colors.get(name, "gray"), 
                        linestyle=styles.get(name, "-"), marker='o', linewidth=2)
            
            # ê³¼ê±° ë°ì´í„° (Context)
            past_days = 20
            past_data = df.loc[:cutoff_date, feature_cols[0]].tail(past_days)
            ax.plot(past_data.index.strftime('%Y-%m-%d'), past_data.values, color='gray', alpha=0.4, label='History')
            
            # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
            ax.set_title("KOSPI Forecast Trend")
            ax.set_ylabel("Index Price")
            ax.legend()
            ax.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
            st.pyplot(fig)

if __name__ == "__main__":
    main()
