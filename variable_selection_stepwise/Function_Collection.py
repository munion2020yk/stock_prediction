# Function_Collection.py

import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
import gc
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error
import FinanceDataReader as fdr
import pandas as pd
from copy import deepcopy
import os
import time

from Model import LSTM, CNN_LSTM, CNNModel

pd.set_option('display.max_columns', None)

class function_collection():
    
    def __init__(self):
        self.raw_df = None
        self.results_cache = {}
        self.stepwise_log = []
        self.save_time = []
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    
    # ======================================================
    # ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
    # ======================================================
    
    def create_sequences(self, X_data, y_data, seq_length):
        X_seq, y_seq = [], []
        for i in range(len(X_data) - seq_length):
            X_seq.append(X_data[i:i+seq_length])
            y_seq.append(y_data[i+seq_length])
        return np.array(X_seq), np.array(y_seq)
        
        
    
    def make_df(self, start, end):
        # KOSPI ê¸°ë³¸ ë°ì´í„°
        df = fdr.DataReader('KS11', start, end)


        # ==========================================================================
        # VKOSPI ë°ì´í„° ì¶”ê°€
        df_usdkrw = fdr.DataReader('USD/KRW', start, end)[['Close']].rename(columns={'Close':'USD_KRW'})
        df_eurkrw = fdr.DataReader('EUR/KRW', start, end)[['Close']].rename(columns={'Close':'EUR_KRW'})
        df_nasdaq = fdr.DataReader('IXIC', start, end)[['Close']].rename(columns={'Close':'NASDAQ'})

        # VKOSPI CSV íŒŒì¼ ë¡œë“œ
        df_vkospi = pd.read_csv("./Data/KOSPI Volatility.csv")
        df_vkospi = df_vkospi.rename(columns={'ë‚ ì§œ':'Date', 
                                              'ì¢…ê°€':'VKOSPI_Close',
                                              'ì‹œê°€':'VKOSPI_Open',
                                              'ê³ ê°€':'VKOSPI_High',
                                              'ì €ê°€':'VKOSPI_Low',
                                              'ë³€ë™ %':'VKOSPI_Change'})

        # ì›í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ (ì˜ˆ: ì¢…ê°€ + ë³€ë™ë¥ ë§Œ)
        df_vkospi = df_vkospi[['Date', 'VKOSPI_Close', 'VKOSPI_Open', 'VKOSPI_High', 'VKOSPI_Low','VKOSPI_Change']]
        df_vkospi['VKOSPI_Change'] = (df_vkospi['VKOSPI_Change'].str.replace('%', '', regex=False).astype(float))

        # ë‚ ì§œ í˜•ì‹ í†µì¼
        df_vkospi['Date'] = pd.to_datetime(df_vkospi['Date'])
        df_vkospi = df_vkospi.set_index('Date').sort_index()
        
        
        # # ==========================================================================
        # # ê¸ˆë¦¬ ë°ì´í„° ì¶”ê°€
        # df_market_interest_rate = pd.read_csv("./Data/market interest rate.csv", encoding='EUC-KR')
        # df_market_interest_rate = df_market_interest_rate.rename(columns={'êµ­ê³ ì±„3ë…„(í‰ê· )':'Treasury_Bond_3years',
        #                                                                   'êµ­ê³ ì±„5ë…„(í‰ê· )':'Treasury_Bond_5years',
        #                                                                   'êµ­ê³ ì±„10ë…„(í‰ê· )':'Treasury_Bond_10years',
        #                                                                   'ê¸°ì¤€ê¸ˆë¦¬':'Benchmark_Interest_Rate'})
        
        # # ë‚ ì§œí˜• ë³€í™˜ ë° ì¸ë±ìŠ¤ ì„¤ì •
        # df_market_interest_rate['Date'] = pd.to_datetime(df_market_interest_rate['Date'])
        # df_market_interest_rate = df_market_interest_rate.set_index('Date').sort_index()

        # df_market_interest_rate = df_market_interest_rate.loc[start:end, ['Treasury_Bond_3years', 'Treasury_Bond_5years', 'Treasury_Bond_10years', 'Benchmark_Interest_Rate']]
        
        
        # ==========================================================================
        # ì„ ë¬¼ ë°ì´í„° ì¶”ê°€ 
        df_future = pd.read_csv("./Data/KOSPI_Future.csv", encoding="EUC-KR")
        df_future = df_future.drop(columns=['ê±°ë˜ëŸ‰'])
        df_future = df_future.rename(columns={
                                        'ë‚ ì§œ':'Date', 
                                        'ì¢…ê°€':'KOSPI_Future_Close',
                                        'ì‹œê°€':'KOSPI_Future_Open',
                                        'ê³ ê°€':'KOSPI_Future_High',
                                        'ì €ê°€':'KOSPI_Future_Low',
                                        'ë³€ë™ %':'KOSPI_Future_Change'})
        
        # ë‚ ì§œí˜• ë³€í™˜ ë° ì¸ë±ìŠ¤ ì„¤ì •
        # df_future['Date'] = pd.to_datetime(df_future['Date'])
        def parse_date(x):
            x = str(x)
            if '/' in x:
                # "11/21/2025" ê°™ì€ í˜•ì‹
                return pd.to_datetime(x, format='%m/%d/%Y')
            else:
                # "2025-11-21" ê°™ì€ í˜•ì‹
                return pd.to_datetime(x, format='%Y-%m-%d')

        df_future['Date'] = df_future['Date'].apply(parse_date)
        df_future = df_future.set_index('Date').sort_index()
        df_future = df_future.loc[start:end]
        
        
        # ==========================================================================
        # WTI ìœ ê°€ ë°ì´í„° ì¶”ê°€ 
        df_WTI = pd.read_csv("./Data/WTI_Oil.csv", encoding="EUC-KR")
        df_WTI = df_WTI.drop(columns=['ê±°ë˜ëŸ‰'])
        df_WTI = df_WTI.rename(columns={
                                        'ë‚ ì§œ':'Date', 
                                        'ì¢…ê°€':'WTI_Close',
                                        'ì‹œê°€':'WTI_Open',
                                        'ê³ ê°€':'WTI_High',
                                        'ì €ê°€':'WTI_Low',
                                        'ë³€ë™ %':'WTI_Change'})
        
        # ë‚ ì§œí˜• ë³€í™˜ ë° ì¸ë±ìŠ¤ ì„¤ì •
        df_WTI['Date'] = pd.to_datetime(df_WTI['Date'])
        df_WTI = df_WTI.set_index('Date').sort_index()
        df_WTI = df_WTI.loc[start:end]
        
        
        # ==========================================================================
        # ì™¸êµ­ì¸ ë³´ìœ ëŸ‰ ë°ì´í„° ì¶”ê°€
        df_Foreign = pd.read_csv("./Data/Foreign Holdings.csv", encoding="EUC-KR")
        df_Foreign = df_Foreign.drop(columns=['ì‹œê°€ì´ì•¡_ì „ì²´','ì‹œê°€ì´ì•¡_ì™¸êµ­ì¸ë³´ìœ ', 'ì£¼ì‹ìˆ˜_ì „ì²´', 'ì£¼ì‹ìˆ˜_ì™¸êµ­ì¸ë³´ìœ ', 'ì£¼ì‹ìˆ˜_ë¹„ìœ¨'])
        df_Foreign = df_Foreign.rename(columns={'ì‹œê°€ì´ì•¡_ë¹„ìœ¨':'Foreign_Holdings_ratio'})
        
        # ë‚ ì§œí˜• ë³€í™˜ ë° ì¸ë±ìŠ¤ ì„¤ì •
        df_Foreign['Date'] = pd.to_datetime(df_Foreign['Date'])
        df_Foreign = df_Foreign.set_index('Date').sort_index()
        df_Foreign = df_Foreign.loc[start:end]


        # ==========================================================================
        # ë‚ ì§œ ê¸°ì¤€ ë³‘í•©
        # print(df.shape)
        # print(df_usdkrw.shape)
        # print(df_eurkrw.shape)
        # print(df_nasdaq.shape)
        # print(df_vkospi.shape)
        # print(df_market_interest_rate.shape)
        # print(df_future.shape)
        # print(df_WTI.shape)
        # print(df_Foreign.shape)
        
        df = df.join([df_usdkrw, df_eurkrw, df_nasdaq, df_vkospi, df_future, df_WTI, df_Foreign], how='left')

        for column in df.columns:
            df[column] = (
                df[column].astype(str).str.replace(',', '', regex=False).str.replace('%', '', regex=False).astype(float)
            )

        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').dropna()
        
        # print(df.shape)
        
        return df
    
    
    def df_to_Xy(self, df, use_columns):
        df_copy = df.copy()
        df_copy = df_copy[use_columns]
        X = df_copy.drop('Close', axis=1)
        y = df_copy[['Close']]
        return df_copy, X, y
        
        
    def load_data(self, df_index, X, y, seq_length=60, train_ratio=0.7, val_ratio=0.1, test_start_date=None):

        # â‘¥ ìŠ¤ì¼€ì¼ë§ ë° ì‹œí€€ìŠ¤ ìƒì„± (ê¸°ì¡´ ë™ì¼)
        ss = StandardScaler()
        ms = MinMaxScaler()
        X_ss = ss.fit_transform(X)
        y_ms = ms.fit_transform(y)

        X_seq, y_seq = self.create_sequences(X_ss, y_ms, seq_length)

        # â‘¦ Train / Val / Test ë¶„ë¦¬
        total_len = len(X_seq)
        
        # â­ï¸ ë¶„í•  ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        split_point_found = False
        train_val_end_idx = 0
        
        if test_start_date:
            test_start_date = pd.to_datetime(test_start_date)
            
            # 1. ì›ë³¸ DF ì¸ë±ìŠ¤ì—ì„œ Test ì‹œì‘ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ì²« ë²ˆì§¸ ì¸ë±ìŠ¤ ì°¾ê¸°
            # (try-except ì œê±°)
            # ì¡°ê±´ì— ë§ëŠ” ì²« ë²ˆì§¸ ë‚ ì§œë¥¼ ì°¾ê³ , ê·¸ ë‚ ì§œì˜ DF ë‚´ ìœ„ì¹˜(index location)ë¥¼ ì°¾ìŒ.
            
            # ì£¼ì˜: .iloc[0]ì„ ì‚¬ìš©í•˜ë ¤ë©´, ë‚ ì§œê°€ ë°ì´í„°í”„ë ˆì„ ë‚´ì— ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ëŠ” ëŒ€ì‹ , ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ë³´ë‹¤ í¬ê²Œ ì„¤ì •í•˜ëŠ” ë“±ì˜ ì²˜ë¦¬ í•„ìš”.
            
            temp_index = df_index[df_index >= test_start_date]

            if len(temp_index) > 0: # ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                original_test_start_date = temp_index[0]
                idx_in_original_df = df_index.get_loc(original_test_start_date)
            
                if idx_in_original_df >= seq_length:
                    # 2. ì‹œí€€ìŠ¤ ë°°ì—´(X_seq)ì—ì„œì˜ ë¶„í•  ì¸ë±ìŠ¤ ê³„ì‚°
                    train_val_end_idx = idx_in_original_df - seq_length
                    split_point_found = True
                else:
                    print(f"[Warning] Test start date is too early (index: {idx_in_original_df} < seq_length: {seq_length}). Using ratio split.")
            else:
                 print(f"[Warning] Test start date '{test_start_date.strftime('%Y-%m-%d')}' is outside the data range. Using ratio split.")


        if split_point_found:
            # â­ï¸ ë‚ ì§œ ê¸°ë°˜ ë¶„í•  ì¸ë±ìŠ¤ê°€ ìœ íš¨í•  ë•Œ (Test ê¸°ê°„ í™•ì •)
            
            train_val_len = min(train_val_end_idx, total_len)
            ratio_sum = train_ratio + val_ratio
            
            # Train/Val ë¹„ìœ¨ì€ ê¸°ì¡´ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ì „ì²´ Train/Val ì„¹ì…˜ì„ ë‚˜ëˆ•ë‹ˆë‹¤.
            train_size = int(train_val_len * (train_ratio / ratio_sum)) if ratio_sum > 0 else 0
            val_size = train_val_len - train_size
            
        else:
            # â­ï¸ ë¹„ìœ¨ ê¸°ë°˜ ë¶„í•  ë¡œì§ (test_start_dateê°€ ì—†ê±°ë‚˜, ë‚ ì§œ ê¸°ë°˜ ë¶„í•  ì‹¤íŒ¨ ì‹œ)
            
            train_size = int(total_len * train_ratio)
            val_size = int(total_len * val_ratio)


        # ìµœì¢… ë¶„í•  ì ìš©
        X_train = X_seq[:train_size]
        y_train = y_seq[:train_size]

        X_val = X_seq[train_size:train_size+val_size]
        y_val = y_seq[train_size:train_size+val_size]

        X_test = X_seq[train_size+val_size:]
        y_test = y_seq[train_size+val_size:]

        # â‘§ Tensor ë³€í™˜ (ê¸°ì¡´ê³¼ ë™ì¼)
        X_train_tensors = torch.tensor(X_train, dtype=torch.float32).to(self.device)
        X_val_tensors = torch.tensor(X_val, dtype=torch.float32).to(self.device)
        X_test_tensors = torch.tensor(X_test, dtype=torch.float32).to(self.device)
        y_train_tensors = torch.tensor(y_train, dtype=torch.float32).to(self.device)
        y_val_tensors = torch.tensor(y_val, dtype=torch.float32).to(self.device)
        y_test_tensors = torch.tensor(y_test, dtype=torch.float32).to(self.device)

        return X_train_tensors, X_val_tensors, X_test_tensors, \
            y_train_tensors, y_val_tensors, y_test_tensors, ss, ms, train_size, val_size
    


    # ======================================================
    # í•™ìŠµ/í‰ê°€ í•¨ìˆ˜ 
    # ======================================================
    
    def train_model(self, model, train_loader, val_loader, epochs, lr, patience):
        """ â­ï¸ [ìˆ˜ì •] OOM ë°©ì§€ìš© ë¯¸ë‹ˆë°°ì¹˜ + Early Stopping ë¡œì§ ì¶”ê°€ """
        
        criterion = nn.MSELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr)
        
        train_losses, val_losses = [], []

        # â­ï¸ Early Stoppingì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
        best_val_loss = float('inf')
        epochs_no_improve = 0
        best_model_state = None

        for epoch in range(1, epochs+1):
            
            # === [Train Step] ===
            model.train()
            epoch_train_loss = 0.0
            
            # â­ï¸ [ìˆ˜ì •] ë¯¸ë‹ˆë°°ì¹˜ ë£¨í”„
            for X_batch, y_batch in train_loader:
                optimizer.zero_grad()
                outputs = model(X_batch)
                loss = criterion(outputs, y_batch)
                loss.backward()
                optimizer.step()
                epoch_train_loss += loss.item()
            
            train_losses.append(epoch_train_loss / len(train_loader))

            # === [Validation Step] ===
            model.eval()
            epoch_val_loss = 0.0
            with torch.no_grad():
                # â­ï¸ [ìˆ˜ì •] Validationë„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ
                for X_val_batch, y_val_batch in val_loader:
                    val_outputs = model(X_val_batch)
                    val_loss = criterion(val_outputs, y_val_batch)
                    epoch_val_loss += val_loss.item()
            
            current_val_loss = epoch_val_loss / len(val_loader)
            val_losses.append(current_val_loss)

            # === [ë¡œê·¸ ì¶œë ¥] ===
            if epoch % 10 == 0 or epoch == 1:
                print(f"[Epoch {epoch}/{epochs}] Train Loss: {train_losses[-1]:.6f}, Val Loss: {val_losses[-1]:.6f}")

            # â­ï¸ === [Early Stopping ì²´í¬] ===
            if current_val_loss < best_val_loss:
                best_val_loss = current_val_loss
                epochs_no_improve = 0
                # ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ CPU ë©”ëª¨ë¦¬ì— ì €ì¥
                best_model_state = deepcopy(model.state_dict())
            else:
                epochs_no_improve += 1
            
            if epochs_no_improve >= patience:
                break # í•™ìŠµ ë£¨í”„ íƒˆì¶œ
        
        # â­ï¸ [ìˆ˜ì •] í•™ìŠµì´ ëë‚œ í›„, ê°€ì¥ ì¢‹ì•˜ë˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜´
        if best_model_state:
            print("Loading best model weights...")
            model.load_state_dict(best_model_state)

        return train_losses, val_losses
    
    def evaluate_model(self, model, X_test, y_test, scaler):
        model.eval()
        with torch.no_grad():
            # â­ï¸ [ìˆ˜ì •] .cpu() ì¶”ê°€ (GPU->CPU)
            preds = model(X_test).detach().cpu().numpy()
            actual = y_test.detach().cpu().numpy()
            
        preds_inv = scaler.inverse_transform(preds)
        actual_inv = scaler.inverse_transform(actual)
        mse = mean_squared_error(actual_inv, preds_inv)
        rmse = np.sqrt(mse)
        return preds_inv, actual_inv, rmse

    # ======================================================
    # ì‹¤ì œ í•™ìŠµ/ìºì‹± í•¨ìˆ˜
    # ======================================================
    
    def _train_and_eval(self, columns, current_params, set_seeds_func):
        """ì‹¤ì œ í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜ (ë¯¸ë‹ˆë°°ì¹˜ ì ìš©)"""
        
        set_seeds_func(100)
        df, X, y = self.df_to_Xy(self.raw_df, columns)
        
        X_train, X_val, X_test, y_train, y_val, y_test, ss, ms, train_size, val_size = self.load_data(
            df.index, X, y,
            seq_length=current_params['seq_length'],
            train_ratio=current_params['train_ratio'],
            val_ratio=current_params['val_ratio'],
            test_start_date=current_params.get('test_start_date')
        )

        input_size = X_train.shape[2]
        device = self.device

        if current_params['use_LSTM']:
            model = LSTM(current_params['num_classes'], 
                         input_size, 
                         current_params['hidden_size'],
                         current_params['num_layers'],
                         current_params['seq_length']).to(device)
        
        elif current_params['use_CNN']:
            model = CNNModel(current_params['num_classes'], 
                             input_size, 
                             current_params['hidden_size'],
                             current_params['num_layers'],
                             current_params['seq_length'],
                             cnn_num_layers=current_params['cnn_num_layers'],
                             num_filters=current_params['num_filters'],
                             kernel_size=current_params['kernel_size']).to(device)
        
        else:
            model = CNN_LSTM(current_params['num_classes'], 
                             input_size, 
                             current_params['hidden_size'],
                             current_params['num_layers'],
                             current_params['seq_length'],
                             cnn_num_layers=current_params['cnn_num_layers'],
                             num_filters=current_params['num_filters'],
                             kernel_size=current_params['kernel_size']).to(device)

        # ==================================
        # â­ï¸ DataLoader ìƒì„±
        # ==================================
        BATCH_SIZE = current_params['batch_size']
        
        train_dataset = TensorDataset(X_train, y_train)
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
        
        val_dataset = TensorDataset(X_val, y_val)
        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
        # ==================================
        
        start = time.time()
        
        # â­ï¸ train_modelì— loader ì „ë‹¬
        train_losses, val_losses = self.train_model(
            model, train_loader, val_loader, 
            current_params['epochs'], 
            current_params['learning_rate'],
            current_params['patience']
        )

        end = time.time()
        train_time = float(f"{end - start:.3f}")
        
        self.save_time.append(train_time)
        
        print(f"\nâœ… Training Time: {train_time} sec")

        preds_inv, actual_inv, rmse = self.evaluate_model(model, X_test, y_test, ms)
        rmse = round(rmse, 4)
        print(f"âœ… Test RMSE: {rmse}")

        return {
            "df": df, "rmse": rmse, 
            # â­ï¸ OOM ë°©ì§€ë¥¼ ìœ„í•´ ëª¨ë¸ì„ CPUë¡œ ì´ë™ì‹œì¼œ ì €ì¥
            "model": deepcopy(model.cpu()), 
            "features" : columns,
            "train_losses": train_losses, "val_losses": val_losses,
            "preds_inv": preds_inv, "actual_inv": actual_inv,
            "train_size": train_size, "val_size": val_size,
            "params_used": deepcopy(current_params)
        }

    def train_and_eval(self, columns, current_params, set_seeds_func):
        """ìºì‹œë¥¼ í™•ì¸í•˜ëŠ” ë˜í¼ í•¨ìˆ˜ (main.pyì—ì„œ ì´ë™)"""
        
        # â­ï¸ [ìˆ˜ì •] ìºì‹œ 'í‚¤'ì— batch_size ì¶”ê°€
        params_tuple = (
            current_params['batch_size'],
            current_params['seq_length'],
            current_params['hidden_size'],
            current_params['num_layers'],
            current_params['cnn_num_layers'] if not current_params['use_LSTM'] else -1,
            current_params['num_filters'] if not current_params['use_LSTM'] else -1,
            current_params['kernel_size'] if not current_params['use_LSTM'] else -1,
        )
        cache_key = (tuple(sorted(columns)), params_tuple)
        
        if cache_key in self.results_cache:
            print(f"\n[CACHE] Using cached result for {columns}")
            cached_result = self.results_cache[cache_key]
            self.save_time.append(0.000)
            print(f"âœ… (Cached) Test RMSE: {cached_result['rmse']}")
            return cached_result
        else:
            print(f"\n[TRAIN] Training new combination {columns}")
            new_result = self._train_and_eval(columns, current_params, set_seeds_func)
            self.results_cache[cache_key] = new_result
            return new_result

    # ======================================================
    # Stepwise ë¡œì§ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
    # ======================================================
    def run_stepwise_selection(self, current_params, model_name, set_seeds_func):
        # ( ... ê¸°ì¡´ run_stepwise_selection ë¡œì§ê³¼ ë™ì¼ ... )
        # ( ... ì´ í•¨ìˆ˜ëŠ” ê° Gridì˜ "1ë“±"ì„ ë°˜í™˜ ... )
        
        BASE_FEATURES = current_params['BASE_FEATURES']
        CANDIDATES = current_params['CANDIDATES']
        MIN_IMPROVE = 0.001
        MAX_FEATURES = 15
        
        best_of_all_runs = {"rmse": float("inf"), "model": None, "features": None}
        
        starting_points = []
        starting_points.append( (deepcopy(BASE_FEATURES), deepcopy(CANDIDATES)) )
        for cand in CANDIDATES:
            new_start_features = deepcopy(BASE_FEATURES) + [cand]
            new_candidates = [c for c in CANDIDATES if c != cand]
            starting_points.append( (new_start_features, new_candidates) )

        print(f"\nğŸ”¥ ì´ {len(starting_points)}ê°œì˜ ë‹¤ë¥¸ ì‹œì‘ì ì—ì„œ Stepwise íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        total_runs = len(starting_points)
        for run_count, (start_features, start_candidates) in enumerate(starting_points, 1):
            
            print(f"\n\n{'='*60}")
            print(f"ğŸš€ [Run {run_count}/{total_runs}] Start Features: {start_features}")
            print(f"{'='*60}")
            
            selected = deepcopy(start_features)
            candidates = deepcopy(start_candidates)
            best_for_this_run = {"rmse": float("inf"), "model": None, "features": None}

            print(f"\n[Stepwise ì‹œì‘] ì´ˆê¸° ë³€ìˆ˜:\n{selected}\n")
            result = self.train_and_eval(selected, current_params, set_seeds_func)
            best_rmse = result["rmse"]
            print(f"âœ… ì´ˆê¸° RMSE = {best_rmse:.6f}")
            # self.stepwise_log.append(f"ì´ˆê¸° RMSE: {best_rmse:.6f}")
            # self.stepwise_log.append(f"        (Features: {selected})\n")
            
            best_for_this_run = deepcopy(result)
            
            while True:
                improved = False
                print("\nğŸ“Œ [Forward Step]")
                best_forward_var = None
                best_forward_rmse = best_rmse

                for var in candidates:
                    trial_cols = selected + [var]
                    result = self.train_and_eval(trial_cols, current_params, set_seeds_func)
                    rmse = result["rmse"]
                    # self.stepwise_log.append(f"        {self.save_time[-1]:.3f} sec")
                    # self.stepwise_log.append(f"        [Forward] + {var:<10} â†’ RMSE = {rmse:.6f}")
                    # self.stepwise_log.append(f"        {trial_cols}\n")
                    if rmse < best_for_this_run["rmse"]:
                        best_for_this_run = deepcopy(result)
                    if rmse < best_forward_rmse:
                        best_forward_var = var
                        best_forward_rmse = rmse

                if best_forward_var is not None and (best_rmse - best_forward_rmse) > MIN_IMPROVE:
                    selected.append(best_forward_var)
                    candidates.remove(best_forward_var)
                    best_rmse = best_forward_rmse
                    improved = True
                    print(f"â˜… Forward ì„ íƒ: {best_forward_var}  â†’ RMSE = {best_rmse:.6f}")
                else:
                    print("\nForward ê°œì„  ì—†ìŒ")

                if len(selected) >= MAX_FEATURES:
                    print("ìµœëŒ€ ë³€ìˆ˜ ê°œìˆ˜ ë„ë‹¬ â†’ ì¢…ë£Œ")
                    break

                print("\nğŸ“Œ [Backward Step]")
                removable = [v for v in selected if v not in BASE_FEATURES]
                best_backward_var = None
                best_backward_rmse = best_rmse

                for var in removable:
                    trial_cols = [v for v in selected if v != var]
                    result = self.train_and_eval(trial_cols, current_params, set_seeds_func)
                    rmse = result["rmse"]
                    # self.stepwise_log.append(f"        {self.save_time[-1]:.3f} sec")
                    # self.stepwise_log.append(f"        [Backward] - {var:<10} â†’ RMSE = {rmse:.6f}")
                    # self.stepwise_log.append(f"        {trial_cols}\n")
                    if rmse < best_for_this_run["rmse"]:
                        best_for_this_run = deepcopy(result)
                    if rmse < best_backward_rmse:
                        best_backward_var = var
                        best_backward_rmse = rmse

                if best_backward_var is not None and (best_rmse - best_backward_rmse) > MIN_IMPROVE:
                    selected.remove(best_backward_var)
                    candidates.append(best_backward_var)
                    best_rmse = best_backward_rmse
                    improved = True
                    print(f"â˜… Backward ì œê±°: {best_backward_var} â†’ RMSE = {best_rmse:.6f}")
                else:
                    print("Backward ì—†ìŒ")

                if not improved:
                    print("\nğŸš« ê°œì„  ì—†ìŒ â†’ Stepwise ì¢…ë£Œ")
                    break
            
            print(f"\n[Run {run_count} ì¢…ë£Œ] ì´ ê²½ë¡œì˜ ìµœì  RMSE: {best_for_this_run['rmse']:.6f}")

            if best_for_this_run["rmse"] < best_of_all_runs["rmse"]:
                print(f"ğŸ‰ [Grid Best ê°±ì‹ ] ì‹ ê·œ RMSE: {best_for_this_run['rmse']:.6f}")
                best_of_all_runs = deepcopy(best_for_this_run)
        
        return best_of_all_runs

    # ======================================================
    # â­ï¸ ì „ì²´ ì‹¤í—˜ ì»¨íŠ¸ë¡¤ íƒ€ì›Œ (ì €ì¥ ë¡œì§ ì´ë™)
    # ======================================================
    def run_grid_search_experiment(self, hyper_parameters, set_seeds_func):
        
        if hyper_parameters['use_LSTM']:
            model_name = "LSTM"
        elif hyper_parameters['use_CNN_LSTM']:
            model_name = "CNN_LSTM"
        elif hyper_parameters['use_CNN']:
            model_name = "CNN"
        
        self.save_time = []
        self.results_cache = {}
        
        self.raw_df = self.make_df(hyper_parameters['data_start'], hyper_parameters['data_end'])
        print(f"\nì›ë³¸ DF ë¡œë”© ì™„ë£Œ: {self.raw_df.shape}\n")
        
        global_best_of_all_runs = {"rmse": float("inf"), "model": None, "features": None, "params_used": None}

        # --- â­ï¸ [ìˆ˜ì •] 1. ê·¸ë¦¬ë“œ ì„œì¹˜ ë£¨í”„ (patience ë£¨í”„ ì œê±°) ---
        for batch_size in hyper_parameters['batch_size']:
            for seq_length in hyper_parameters['seq_length']:
                for hidden_size in hyper_parameters['hidden_size']:
                    for num_layers in hyper_parameters['num_layers']:
                        
                        # â­ï¸ 'patience' ë£¨í”„ ì œê±°
                            
                        current_params = deepcopy(hyper_parameters)
                        current_params['batch_size'] = batch_size
                        current_params['seq_length'] = seq_length
                        current_params['hidden_size'] = hidden_size
                        current_params['num_layers'] = num_layers
                        # â­ï¸ 'patience: 10'ì€ deepcopyë¡œ ìë™ ë³µì‚¬ë¨
                        
                        if hyper_parameters['use_LSTM']:
                            print(f"\n\n{'='*80}")
                            # â­ï¸ [ìˆ˜ì •] current_params['patience'] ì‚¬ìš©
                            print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [GRID SEARCH] batch: {batch_size}, seq: {seq_length}, hidden: {hidden_size}, layers: {num_layers}, patience: {current_params['patience']} ğŸ”¥ğŸ”¥ğŸ”¥")
                            print(f"{'='*80}")
                            
                            self.stepwise_log = []
                            grid_run_times = []
                            # â­ï¸ [ìˆ˜ì •] current_params['patience'] ì‚¬ìš©
                            log_header = f"GRID: batch:{batch_size}, seq:{seq_length}, hidden:{hidden_size}, layers:{num_layers}, patience:{current_params['patience']}\n"
                            self.stepwise_log.append(log_header)
                            
                            # ( ... ë‚˜ë¨¸ì§€ ë¡œì§ ë™ì¼ ... )
                            full_save_time_backup = deepcopy(self.save_time)
                            self.save_time = []
                            best_run_for_this_grid = self.run_stepwise_selection(current_params, model_name, set_seeds_func)
                            grid_run_times = deepcopy(self.save_time)
                            self.save_time = full_save_time_backup + grid_run_times
                            if best_run_for_this_grid["rmse"] < global_best_of_all_runs["rmse"]:
                                global_best_of_all_runs = deepcopy(best_run_for_this_grid)

                            print(f"\n... [GRID batch:{batch_size}, seq:{seq_length}...] ê²°ê³¼ ì €ì¥ ì¤‘ ...")

                            self.plot_train_val_loss(best_run_for_this_grid, model_name)
                            self.plot_predictions(best_run_for_this_grid, model_name)
                            self.save_txt(best_run_for_this_grid["params_used"], self.stepwise_log, model_name, best_run_for_this_grid, grid_run_times)

                            del best_run_for_this_grid

                            gc.collect()

                            if self.device.type == 'cuda':
                                torch.cuda.empty_cache()

                            
                        elif hyper_parameters['use_CNN_LSTM'] or hyper_parameters['use_CNN']:
                            for cnn_num_layers in hyper_parameters['cnn_num_layers']:
                                for num_filters in hyper_parameters['num_filters']:
                                    for kernel_size in hyper_parameters['kernel_size']:
                                        
                                        current_params['cnn_num_layers'] = cnn_num_layers
                                        current_params['num_filters'] = num_filters
                                        current_params['kernel_size'] = kernel_size
    
                                        print(f"\n\n{'='*80}")
                                        # â­ï¸ [ìˆ˜ì •] current_params['patience'] ì‚¬ìš©
                                        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ [GRID SEARCH] batch: {batch_size}, seq: {seq_length}, hidden: {hidden_size}, lstm_layers: {num_layers}, patience: {current_params['patience']}")
                                        print(f"                  cnn_layers: {cnn_num_layers}, filters: {num_filters}, kernel: {kernel_size} ğŸ”¥ğŸ”¥ğŸ”¥")
                                        print(f"{'='*80}")
    
                                        self.stepwise_log = []
                                        grid_run_times = []
                                        # â­ï¸ [ìˆ˜ì •] current_params['patience'] ì‚¬ìš©
                                        log_header = f"GRID: batch:{batch_size}, seq:{seq_length}, hidden:{hidden_size}, lstm_layers:{num_layers}, patience:{current_params['patience']}, cnn_layers:{cnn_num_layers}, filters:{num_filters}, kernel:{kernel_size}\n"
                                        self.stepwise_log.append(log_header)
                                        
                                        # ( ... ë‚˜ë¨¸ì§€ ë¡œì§ ë™ì¼ ... )
                                        full_save_time_backup = deepcopy(self.save_time)
                                        self.save_time = []
                                        best_run_for_this_grid = self.run_stepwise_selection(current_params, model_name, set_seeds_func)
                                        grid_run_times = deepcopy(self.save_time)
                                        self.save_time = full_save_time_backup + grid_run_times
                                        if best_run_for_this_grid["rmse"] < global_best_of_all_runs["rmse"]:
                                            global_best_of_all_runs = deepcopy(best_run_for_this_grid)
                                        print(f"\n... [GRID batch:{batch_size}, seq:{seq_length}...] ê²°ê³¼ ì €ì¥ ì¤‘ ...")
                                        self.plot_train_val_loss(best_run_for_this_grid, model_name)
                                        self.plot_predictions(best_run_for_this_grid, model_name)
                                        self.save_txt(best_run_for_this_grid["params_used"], self.stepwise_log, model_name, best_run_for_this_grid, grid_run_times)
                                        del best_run_for_this_grid
                                        gc.collect()
                                        if self.device.type == 'cuda':
                                            torch.cuda.empty_cache()

        # --- 3. ìµœì¢… ìš”ì•½ ì¶œë ¥ ---
        # ( ... ë™ì¼ ... )
        print("\n\n==============================")
        print("ğŸ”¥ğŸ”¥ğŸ”¥ ëª¨ë“  íƒìƒ‰ ì¢…ë£Œ ğŸ”¥ğŸ”¥ğŸ”¥")
        print(f"ğŸ‰ 'Global' 1ë“± Feature Set =", global_best_of_all_runs.get("features"))
        print(f"ğŸ‰ 'Global' 1ë“± RMSE =", global_best_of_all_runs.get("rmse"))
        print(f"ğŸ‰ 'Global' 1ë“± Params =", global_best_of_all_runs.get("params_used"))

        total_time_sec = sum(self.save_time)
        total_min, total_sec = divmod(total_time_sec, 60)
        print(f"ğŸ•’ ì´ í•™ìŠµ ì‹œê°„: {int(total_min)}ë¶„ {total_sec:.2f}ì´ˆ ({total_time_sec:.2f} sec)")
        print(f"(ìºì‹œ ì œì™¸ ì‹¤ì œ í•™ìŠµ íšŸìˆ˜: {len([t for t in self.save_time if t > 0])}íšŒ)")
        print("==============================")
        print("\nëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    
    # ======================================================
    # ì‹œê°í™” / ì €ì¥ í•¨ìˆ˜ (â­ï¸ save_txt ìˆ˜ì •)
    # ======================================================

    def plot_train_val_loss(self, best_overall, model_name):
        """ â­ï¸ [ìˆ˜ì •] best_overall ë”•ì…”ë„ˆë¦¬ë¥¼ í†µì§¸ë¡œ ë°›ìŒ """
        
        train_losses = best_overall["train_losses"]
        val_losses = best_overall["val_losses"]
        rmse = best_overall["rmse"]
            
        plt.figure(figsize=(10,5))
        plt.plot(train_losses, label='Train Loss', linewidth=2)
        plt.plot(val_losses, label='Validation Loss', linewidth=2)
        plt.title('Train vs Validation Loss')
        plt.xlabel('Epochs')
        plt.ylabel('MSE Loss')
        plt.legend()
        plt.grid(alpha=0.3)
        plt.savefig(f"./Output/{model_name}/(RMSE {rmse}) {model_name}_Result__Comparison with Loss.png")
        # plt.show()
        plt.close()


    # def plot_predictions(self, best_overall, model_name):
    #     """ â­ï¸ [ìˆ˜ì •] best_overall ë”•ì…”ë„ˆë¦¬ë¥¼ í†µì§¸ë¡œ ë°›ìŒ """
        
    #     df = best_overall["df"]
    #     preds_inv = best_overall["preds_inv"]
    #     actual_inv = best_overall["actual_inv"]
    #     rmse = best_overall["rmse"]
    #     params = best_overall.get("params_used", {})
    #     seq_length = params.get('seq_length', 5) # paramsì—ì„œ seq_length ì¶”ì¶œ
    #     train_size = best_overall["train_size"]
    #     val_size = best_overall["val_size"]

    #     test_start = seq_length + train_size + val_size
    #     test_end = test_start + len(preds_inv)

    #     # â­ï¸ ë‚ ì§œ ì¸ë±ì‹± ì˜¤ë¥˜ ë°©ì§€
    #     if test_start >= len(df.index):
    #          print(f"[Warning] plot_predictions: test_start index ({test_start}) out of bounds.")
    #          test_start = len(df.index) - len(preds_inv)
    #          test_end = test_start + len(preds_inv)
    #          if test_start < 0:
    #              print("[Error] plot_predictions: Not enough data to plot.")
    #              return

    #     dates = df.index[test_start:test_end]
    #     plt.figure(figsize=(12,6))
    #     plt.plot(dates, actual_inv.ravel(), label='Actual (Test)', linewidth=1.5)
    #     plt.plot(dates, preds_inv.ravel(), label='Predicted (Test)', linewidth=1.5, alpha=0.8)
    #     plt.title(f'KOSPI Prediction using {model_name} (RMSE: {rmse})')
    #     plt.xlabel('Date')
    #     plt.ylabel('KOSPI Index')
    #     plt.legend()
    #     plt.grid(alpha=0.3)
    #     plt.gcf().autofmt_xdate()
    #     plt.savefig(f"./Output/{model_name}/(RMSE {rmse}) {model_name}_Result__KOSPI Prediction.png")
    #     # plt.show()
    #     plt.close()
    

    def plot_predictions(self, best_overall, model_name):
        """ â­ï¸ [ìˆ˜ì •] best_overall ë”•ì…”ë„ˆë¦¬ë¥¼ í†µì§¸ë¡œ ë°›ìŒ """
        
        df = best_overall["df"]
        preds_inv = best_overall["preds_inv"]
        actual_inv = best_overall["actual_inv"]
        rmse = best_overall["rmse"]
        params = best_overall.get("params_used", {})
        seq_length = params.get('seq_length', 5) # paramsì—ì„œ seq_length ì¶”ì¶œ
        train_size = best_overall["train_size"]
        val_size = best_overall["val_size"]

        test_start = seq_length + train_size + val_size
        test_end = test_start + len(preds_inv)

        # â­ï¸ ë‚ ì§œ ì¸ë±ì‹± ì˜¤ë¥˜ ë°©ì§€ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if test_start >= len(df.index):
            print(f"[Warning] plot_predictions: test_start index ({test_start}) out of bounds.")
            test_start = len(df.index) - len(preds_inv)
            test_end = test_start + len(preds_inv)
            if test_start < 0:
                print("[Error] plot_predictions: Not enough data to plot.")
                return

        dates = df.index[test_start:test_end]
        
        # â­ï¸ 1. ì‹œê°í™” ë°ì´í„° ì¶”ì¶œ (ê°€ì¥ ë§ˆì§€ë§‰ ë‚ ì§œì™€ ê°’)
        actual_last = actual_inv[-1][0] 
        preds_last = preds_inv[-1][0]   
        
        plt.figure(figsize=(12,6))
        
        # â­ï¸ [ìˆ˜ì •] ëª¨ë“  ë°ì´í„° í¬ì¸íŠ¸ì— ë§ˆì»¤ë¥¼ ì¶”ê°€í•˜ì—¬ ê°œë³„ í¬ì¸íŠ¸ë¥¼ ì‹ë³„ ê°€ëŠ¥í•˜ê²Œ í•¨
        plt.plot(dates, actual_inv.ravel(), label='Actual (Test)', linewidth=1.5, color='blue', marker='o', markersize=3) 
        plt.plot(dates, preds_inv.ravel(), label='Predicted (Test)', linewidth=1.5, alpha=0.8, color='red', marker='x', markersize=3) 
        
        for date, actual, predicted in zip(dates, actual_inv.ravel(), preds_inv.ravel()):
            # ì‹¤ì œê°’ ë ˆì´ë¸”
            plt.text(date, actual, f'{actual:.2f}', color='blue', fontsize=6, ha='right', va='center')
            # ì˜ˆì¸¡ê°’ ë ˆì´ë¸”
            plt.text(date, predicted, f'{predicted:.2f}', color='red', fontsize=6, ha='left', va='center')
        
        # â­ï¸ 2. í…ìŠ¤íŠ¸ ì£¼ì„ ì¶”ê°€ (ê°€ì¥ ìµœê·¼ ì§€ì ì˜ ê°’ë§Œ í‘œì‹œ - ê°€ë…ì„± ìœ ì§€)
        # ì‹¤ì œê°’ (Actual) ìµœì¢… ì§€ì  í‘œì‹œ
        plt.text(
            dates[-1], 
            actual_last, 
            f'{actual_last:.2f}', 
            color='blue', 
            fontsize=10, 
            ha='left', 
            va='bottom'
        )
        
        # ì˜ˆì¸¡ê°’ (Predicted) ìµœì¢… ì§€ì  í‘œì‹œ
        plt.text(
            dates[-1], 
            preds_last, 
            f'{preds_last:.2f}', 
            color='red', 
            fontsize=10, 
            ha='left', 
            va='top' if preds_last > actual_last else 'bottom' # ê²¹ì¹˜ì§€ ì•Šë„ë¡ ìœ„ì¹˜ ì¡°ì •
        )
        
        # â­ï¸ 3. íƒ€ì´í‹€ ìˆ˜ì • (RMSE í¬ë§·íŒ…)
        plt.title(f'KOSPI Prediction using {model_name} (RMSE: {rmse:.4f})')
        plt.xlabel('Date')
        plt.ylabel('KOSPI Index')
        plt.legend()
        plt.grid(alpha=0.3)
        
        plt.gcf().autofmt_xdate()
        # plt.tight_layout() 
        plt.savefig(f"./Output/{model_name}/(RMSE {rmse}) {model_name}_Result__KOSPI Prediction.png")
        # plt.show()
        plt.close()
        
    
    def save_txt(self, current_params_log, stepwise_log, model_name, best_overall, grid_save_time):
        """
        â­ï¸ [ìˆ˜ì •]
        - hyper_parameters -> current_params_log (ë‹¨ì¼ ê°’ ë”•ì…”ë„ˆë¦¬)
        - save_time -> grid_save_time (ì´ ê·¸ë¦¬ë“œì˜ ì‹œê°„ ë¦¬ìŠ¤íŠ¸)
        """
        
        total_seconds = sum(grid_save_time) # â­ï¸ ì´ ê·¸ë¦¬ë“œì˜ ì‹œê°„
        minutes, seconds = divmod(total_seconds, 60)



        # # â­ï¸ ìƒˆë¡œ ì¶”ê°€ëœ ì˜ˆì¸¡ CSV ì €ì¥ ë¡œì§
        # df = best_overall["df"]
        # preds_inv = best_overall["preds_inv"]
        # actual_inv = best_overall["actual_inv"]
        # params = best_overall.get("params_used", {})
        # seq_length = params.get('seq_length', 5) 
        # train_size = best_overall["train_size"]
        # val_size = best_overall["val_size"]
        # rmse = best_overall["rmse"]
        
        # test_start = seq_length + train_size + val_size
        # test_end = test_start + len(preds_inv)
        
        # # # ë‚ ì§œ ì¸ë±ì‹± ì•ˆì „ ì²˜ë¦¬ (plot_predictionsì™€ ë™ì¼)
        # # if test_start >= len(df.index):
        # #      test_start = len(df.index) - len(preds_inv)
        # #      test_end = test_start + len(preds_inv)
        # #      if test_start < 0:
        # #          # CSV ì €ì¥ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°, í…ìŠ¤íŠ¸ íŒŒì¼ë§Œ ì €ì¥í•©ë‹ˆë‹¤.
        # #          csv_save_path = "N/A (Not enough data to plot/save)"
        # #      else:
        # #          dates = df.index[test_start:test_end]
        # #          df_results = pd.DataFrame({'Actual': actual_inv.ravel(), 'Predicted': preds_inv.ravel()}, index=dates)
        # #          csv_save_path = f"./Output/{model_name}/(RMSE {rmse}) {model_name}_Result__Predictions.csv"
        # #          df_results.to_csv(csv_save_path)
        # #          print(f"âœ… Prediction results saved to {csv_save_path}")
        # # else:
        # dates = df.index[test_start:test_end]
        # df_results = pd.DataFrame({'Actual': actual_inv.ravel(), 'Predicted': preds_inv.ravel()}, index=dates)
        # csv_save_path = f"./Output/{model_name}/(RMSE {rmse}) {model_name}_Result__Predictions.csv"
        # df_results.to_csv(csv_save_path, encoding='EUC-KR')
        # print(f"âœ… Prediction results saved to {csv_save_path}")



        save_path = f"./Output/{model_name}/(RMSE {best_overall['rmse']}) {model_name}_Result__HyperParameters.txt"
        
        config_text = """"""
        
        # if current_params_log['step_wise']:
        #     config_text += f"""
        #     # ============================
        #     # Stepwise Feature Selection Log
        #     # ============================
        #     (Base/CandidatesëŠ” Experiment Configuration ì„¹ì…˜ ì°¸ì¡°)
        #     """
            
        config_text += f"""
        # ============================
        # Experiment Result (For This Grid)
        # ============================
        
        ğŸ‘ This Grid Process Time:
        -> {total_seconds} sec
        -> {int(minutes)}ë¶„ {seconds:.2f}ì´ˆ
        
        ğŸ“‹ Final Data Columns:
        {best_overall["features"]}

        âœ… Final RMSE: {best_overall["rmse"]}


        # ============================
        # Experiment Configuration
        # ============================
        
        ğŸ§© Model Used: **{model_name}**
        
        ğŸ“… Data Range
        - Start Date: {current_params_log['data_start']}
        - End Date  : {current_params_log['data_end']}
        - test_start_date: {current_params_log['test_start_date']}
        - Sequence Length: {current_params_log['seq_length']}

        ğŸ“Š Data Split
        - Train Ratio: {current_params_log['train_ratio']}
        - Validation Ratio: {current_params_log['val_ratio']}

        ğŸ§  Model Parameters
        - Hidden Size: {current_params_log['hidden_size']}
        - Num Layers : {current_params_log['num_layers']}
        - Num Classes: {current_params_log['num_classes']}
        """

        if current_params_log['use_CNN_LSTM']:
             config_text += f"""
        ğŸ§  CNN Parameters
        - CNN Num Layers: {current_params_log['cnn_num_layers']}
        - Num Filters   : {current_params_log['num_filters']}
        - Kernel Size   : {current_params_log['kernel_size']}
        """
        
        config_text += f"""
        âš™ï¸ Training Setup
        - Batch Size   : {current_params_log['batch_size']}
        - Epochs       : {current_params_log['epochs']}
        - Learning Rate: {current_params_log['learning_rate']}
        
        # ============================
        # Base/Candidate Features
        # ============================
        - BASE_FEATURES: {current_params_log['BASE_FEATURES']}
        - CANDIDATES   : {current_params_log['CANDIDATES']}
        """

        # if current_params_log['step_wise']:
        #     config_text += """
            
        # # ============================
        # # Log Data (For This Grid)
        # # ============================
        # """
        #     for l in stepwise_log:
        #         config_text += "  " + l + "\n"
                
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(config_text)